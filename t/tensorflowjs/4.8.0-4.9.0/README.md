# Comparing `tmp/tensorflowjs-4.8.0-py3-none-any.whl.zip` & `tmp/tensorflowjs-4.9.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,47 +1,49 @@
-Zip file size: 85069 bytes, number of entries: 45
--rw-r--r--  2.0 unx      937 b- defN 23-Jun-20 16:53 tensorflowjs/__init__.py
--rw-r--r--  2.0 unx     1240 b- defN 23-Jun-20 16:53 tensorflowjs/converters/__init__.py
--rw-r--r--  2.0 unx     2579 b- defN 23-Jun-20 16:53 tensorflowjs/converters/common.py
--r-xr-xr-x  2.0 unx    17618 b- defN 23-Jun-20 20:25 tensorflowjs/converters/converter
--rw-r--r--  2.0 unx    33823 b- defN 23-Jun-20 16:53 tensorflowjs/converters/converter.py
--rw-r--r--  2.0 unx    11841 b- defN 23-Jun-20 16:53 tensorflowjs/converters/fold_batch_norms.py
--rw-r--r--  2.0 unx     5632 b- defN 23-Jun-20 16:53 tensorflowjs/converters/fuse_depthwise_conv2d.py
--rw-r--r--  2.0 unx     6568 b- defN 23-Jun-20 16:53 tensorflowjs/converters/fuse_prelu.py
--rw-r--r--  2.0 unx     4330 b- defN 23-Jun-20 16:53 tensorflowjs/converters/graph_rewrite_util.py
--rw-r--r--  2.0 unx     6196 b- defN 23-Jun-20 16:53 tensorflowjs/converters/jax_conversion.py
--rw-r--r--  2.0 unx    12457 b- defN 23-Jun-20 16:53 tensorflowjs/converters/keras_h5_conversion.py
--rw-r--r--  2.0 unx     9539 b- defN 23-Jun-20 16:53 tensorflowjs/converters/keras_tfjs_loader.py
--rw-r--r--  2.0 unx    52392 b- defN 23-Jun-20 16:53 tensorflowjs/converters/tf_saved_model_conversion_v2.py
--r-xr-xr-x  2.0 unx    17838 b- defN 23-Jun-20 20:25 tensorflowjs/converters/wizard
--rw-r--r--  2.0 unx    24284 b- defN 23-Jun-20 16:53 tensorflowjs/converters/wizard.py
--rw-r--r--  2.0 unx     6211 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/arithmetic.json
--rw-r--r--  2.0 unx    14379 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/basic_math.json
--rw-r--r--  2.0 unx    15173 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/control.json
--rw-r--r--  2.0 unx    13113 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/convolution.json
--rw-r--r--  2.0 unx     7037 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/creation.json
--rw-r--r--  2.0 unx     3323 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/dynamic.json
--rw-r--r--  2.0 unx     1344 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/evaluation.json
--rw-r--r--  2.0 unx     3164 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/graph.json
--rw-r--r--  2.0 unx     4693 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/hash_table.json
--rw-r--r--  2.0 unx     2644 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/image.json
--rw-r--r--  2.0 unx     4656 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/logical.json
--rw-r--r--  2.0 unx     4504 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/matrices.json
--rw-r--r--  2.0 unx     3902 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/normalization.json
--rw-r--r--  2.0 unx     1519 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/ragged.json
--rw-r--r--  2.0 unx     5009 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/reduction.json
--rw-r--r--  2.0 unx     7284 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/slice_join.json
--rw-r--r--  2.0 unx     1684 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/sparse.json
--rw-r--r--  2.0 unx      906 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/spectral.json
--rw-r--r--  2.0 unx     2266 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/string.json
--rw-r--r--  2.0 unx      178 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/tfdf.json
--rw-r--r--  2.0 unx     4426 b- defN 23-Jun-20 16:53 tensorflowjs/op_list/transformation.json
--rw-r--r--  2.0 unx     8514 b- defN 23-Jun-20 16:53 tensorflowjs/quantization.py
--rw-r--r--  2.0 unx     7438 b- defN 23-Jun-20 16:53 tensorflowjs/read_weights.py
--rw-r--r--  2.0 unx     1627 b- defN 23-Jun-20 16:53 tensorflowjs/resource_loader.py
--rw-r--r--  2.0 unx      108 b- defN 23-Jun-20 20:24 tensorflowjs/version.py
--rw-r--r--  2.0 unx    14284 b- defN 23-Jun-20 16:53 tensorflowjs/write_weights.py
-?rw-------  2.0 unx       91 b- defN 23-Jun-20 20:25 tensorflowjs-4.8.0.dist-info/WHEEL
-?rw-------  2.0 unx     3147 b- defN 23-Jun-20 20:25 tensorflowjs-4.8.0.dist-info/METADATA
--r-xr-xr-x  2.0 unx      147 b- defN 23-Jun-20 20:25 tensorflowjs-4.8.0.dist-info/entry_points.txt
-?rw-------  2.0 unx     4108 b- defN 23-Jun-20 20:25 tensorflowjs-4.8.0.dist-info/RECORD
-45 files, 354153 bytes uncompressed, 78441 bytes compressed:  77.9%
+Zip file size: 89020 bytes, number of entries: 47
+-rw-r--r--  2.0 unx      937 b- defN 23-Jul-18 16:42 tensorflowjs/__init__.py
+-rw-r--r--  2.0 unx     1240 b- defN 23-Jul-18 16:42 tensorflowjs/converters/__init__.py
+-rw-r--r--  2.0 unx     2613 b- defN 23-Jul-18 16:42 tensorflowjs/converters/common.py
+-r-xr-xr-x  2.0 unx    17618 b- defN 23-Jul-18 19:52 tensorflowjs/converters/converter
+-rw-r--r--  2.0 unx    39392 b- defN 23-Jul-18 16:42 tensorflowjs/converters/converter.py
+-rw-r--r--  2.0 unx    11841 b- defN 23-Jul-18 16:42 tensorflowjs/converters/fold_batch_norms.py
+-rw-r--r--  2.0 unx     5632 b- defN 23-Jul-18 16:42 tensorflowjs/converters/fuse_depthwise_conv2d.py
+-rw-r--r--  2.0 unx     6568 b- defN 23-Jul-18 16:42 tensorflowjs/converters/fuse_prelu.py
+-rw-r--r--  2.0 unx     4600 b- defN 23-Jul-18 16:42 tensorflowjs/converters/graph_rewrite_util.py
+-rw-r--r--  2.0 unx     6196 b- defN 23-Jul-18 16:42 tensorflowjs/converters/jax_conversion.py
+-rw-r--r--  2.0 unx    15596 b- defN 23-Jul-18 16:42 tensorflowjs/converters/keras_h5_conversion.py
+-rw-r--r--  2.0 unx    15676 b- defN 23-Jul-18 16:42 tensorflowjs/converters/keras_tfjs_loader.py
+-rw-r--r--  2.0 unx     2694 b- defN 23-Jul-18 16:42 tensorflowjs/converters/normalize_bias_add.py
+-rw-r--r--  2.0 unx     1888 b- defN 23-Jul-18 16:42 tensorflowjs/converters/tf_module_mapper.py
+-rw-r--r--  2.0 unx    52526 b- defN 23-Jul-18 16:42 tensorflowjs/converters/tf_saved_model_conversion_v2.py
+-r-xr-xr-x  2.0 unx    17838 b- defN 23-Jul-18 19:52 tensorflowjs/converters/wizard
+-rw-r--r--  2.0 unx    24284 b- defN 23-Jul-18 16:42 tensorflowjs/converters/wizard.py
+-rw-r--r--  2.0 unx     6211 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/arithmetic.json
+-rw-r--r--  2.0 unx    14379 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/basic_math.json
+-rw-r--r--  2.0 unx    15173 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/control.json
+-rw-r--r--  2.0 unx    13113 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/convolution.json
+-rw-r--r--  2.0 unx     7037 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/creation.json
+-rw-r--r--  2.0 unx     3323 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/dynamic.json
+-rw-r--r--  2.0 unx     1344 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/evaluation.json
+-rw-r--r--  2.0 unx     3164 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/graph.json
+-rw-r--r--  2.0 unx     4693 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/hash_table.json
+-rw-r--r--  2.0 unx     2644 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/image.json
+-rw-r--r--  2.0 unx     4656 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/logical.json
+-rw-r--r--  2.0 unx     4504 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/matrices.json
+-rw-r--r--  2.0 unx     3902 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/normalization.json
+-rw-r--r--  2.0 unx     1519 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/ragged.json
+-rw-r--r--  2.0 unx     5009 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/reduction.json
+-rw-r--r--  2.0 unx     7284 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/slice_join.json
+-rw-r--r--  2.0 unx     1684 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/sparse.json
+-rw-r--r--  2.0 unx      906 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/spectral.json
+-rw-r--r--  2.0 unx     2266 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/string.json
+-rw-r--r--  2.0 unx      178 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/tfdf.json
+-rw-r--r--  2.0 unx     4426 b- defN 23-Jul-18 16:42 tensorflowjs/op_list/transformation.json
+-rw-r--r--  2.0 unx     8514 b- defN 23-Jul-18 16:42 tensorflowjs/quantization.py
+-rw-r--r--  2.0 unx     7438 b- defN 23-Jul-18 16:42 tensorflowjs/read_weights.py
+-rw-r--r--  2.0 unx     1627 b- defN 23-Jul-18 16:42 tensorflowjs/resource_loader.py
+-rw-r--r--  2.0 unx      108 b- defN 23-Jul-18 19:51 tensorflowjs/version.py
+-rw-r--r--  2.0 unx    14284 b- defN 23-Jul-18 16:42 tensorflowjs/write_weights.py
+?rw-------  2.0 unx       91 b- defN 23-Jul-18 19:52 tensorflowjs-4.9.0.dist-info/WHEEL
+?rw-------  2.0 unx     3147 b- defN 23-Jul-18 19:52 tensorflowjs-4.9.0.dist-info/METADATA
+-r-xr-xr-x  2.0 unx      147 b- defN 23-Jul-18 19:52 tensorflowjs-4.9.0.dist-info/entry_points.txt
+?rw-------  2.0 unx     4311 b- defN 23-Jul-18 19:52 tensorflowjs-4.9.0.dist-info/RECORD
+47 files, 374221 bytes uncompressed, 82064 bytes compressed:  78.1%
```

## zipnote {}

```diff
@@ -30,14 +30,20 @@
 
 Filename: tensorflowjs/converters/keras_h5_conversion.py
 Comment: 
 
 Filename: tensorflowjs/converters/keras_tfjs_loader.py
 Comment: 
 
+Filename: tensorflowjs/converters/normalize_bias_add.py
+Comment: 
+
+Filename: tensorflowjs/converters/tf_module_mapper.py
+Comment: 
+
 Filename: tensorflowjs/converters/tf_saved_model_conversion_v2.py
 Comment: 
 
 Filename: tensorflowjs/converters/wizard
 Comment: 
 
 Filename: tensorflowjs/converters/wizard.py
@@ -117,20 +123,20 @@
 
 Filename: tensorflowjs/version.py
 Comment: 
 
 Filename: tensorflowjs/write_weights.py
 Comment: 
 
-Filename: tensorflowjs-4.8.0.dist-info/WHEEL
+Filename: tensorflowjs-4.9.0.dist-info/WHEEL
 Comment: 
 
-Filename: tensorflowjs-4.8.0.dist-info/METADATA
+Filename: tensorflowjs-4.9.0.dist-info/METADATA
 Comment: 
 
-Filename: tensorflowjs-4.8.0.dist-info/entry_points.txt
+Filename: tensorflowjs-4.9.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: tensorflowjs-4.8.0.dist-info/RECORD
+Filename: tensorflowjs-4.9.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## tensorflowjs/converters/common.py

```diff
@@ -36,14 +36,15 @@
 USER_DEFINED_METADATA_KEY = 'userDefinedMetadata'
 STRUCTURED_OUTPUTS_KEYS_KEY = 'structuredOutputKeys'
 RESOURCE_ID_KEY = 'resourceId'
 
 # Model formats.
 KERAS_SAVED_MODEL = 'keras_saved_model'
 KERAS_MODEL = 'keras'
+KERAS_KERAS_MODEL = 'keras_keras'
 TF_SAVED_MODEL = 'tf_saved_model'
 TF_HUB_MODEL = 'tf_hub'
 TFJS_GRAPH_MODEL = 'tfjs_graph_model'
 TFJS_LAYERS_MODEL = 'tfjs_layers_model'
 TF_FROZEN_MODEL = 'tf_frozen_model'
 
 # CLI argument strings.
```

## tensorflowjs/converters/converter.py

```diff
@@ -31,14 +31,15 @@
 
 from tensorflowjs import quantization
 from tensorflowjs import version
 from tensorflowjs.converters import common
 from tensorflowjs.converters import keras_h5_conversion as conversion
 from tensorflowjs.converters import keras_tfjs_loader
 from tensorflowjs.converters import tf_saved_model_conversion_v2
+from zipfile import ZipFile, is_zipfile
 
 
 def dispatch_keras_h5_to_tfjs_layers_model_conversion(
     h5_path, output_dir=None, quantization_dtype_map=None,
     split_weights_by_layer=False,
     weight_shard_size_bytes=1024 * 1024 * 4,
     metadata=None):
@@ -96,14 +97,96 @@
       os.makedirs(output_dir)
     conversion.write_artifacts(
         model_json, groups, output_dir, quantization_dtype_map,
         weight_shard_size_bytes=weight_shard_size_bytes, metadata=metadata)
 
   return model_json, groups
 
+def dispatch_keras_keras_to_tfjs_layers_model_conversion(
+    v3_path,
+    output_dir=None,
+    quantization_dtype_map=None,
+    split_weights_by_layer=False,
+    weight_shard_size_bytes=1024 * 1024 * 4,
+    metadata=None,
+):
+  """Converts a Keras v3 .keras file to TensorFlow.js format.
+
+  Args:
+    v3_path: path to an .keras file containing keras model data as a `str`.
+    output_dir: Output directory to which the TensorFlow.js-format model JSON
+      file and weights files will be written. If the directory does not exist,
+      it will be created.
+    quantization_dtype_map: A mapping from dtype (`uint8`, `uint16`, `float16`)
+      to weights. The weight mapping supports wildcard substitution.
+    split_weights_by_layer: Whether to split the weights into separate weight
+      groups (corresponding to separate binary weight files) layer by layer
+      (Default: `False`).
+    weight_shard_size_bytes: Shard size (in bytes) of the weight files.
+      The size of each weight file will be <= this value.
+    metadata: User defined metadata map.
+
+  Returns:
+    (model_json, groups)
+      model_json: a json dictionary (empty if unused) for model topology.
+      groups: an array of weight_groups as defined in tfjs weights_writer.
+  """
+  if not os.path.exists(v3_path):
+      raise ValueError("Nonexistent path to .keras file: %s" % v3_path)
+  if os.path.isdir(v3_path):
+      raise ValueError(
+          "Expected path to point to an .keras file, but it points to a "
+          "directory: %s" % v3_path
+      )
+  file_path = str(v3_path)
+  if not file_path.endswith(".keras"):
+      raise ValueError(
+          "Invalid `filepath` argument: expected a `.keras` extension. "
+          f"Received: filepath={file_path}"
+      )
+  with ZipFile(v3_path, "r") as zip_file:
+      zip_file.extractall(path=os.path.dirname(v3_path))
+  dir_path = os.path.dirname(file_path)
+  meta_data_json_path = os.path.join(dir_path, "metadata.json")
+  config_json_path = os.path.join(dir_path, "config.json")
+  model_weights_path = os.path.join(dir_path, "model.weights.h5")
+  h5_file = h5py.File(model_weights_path, "r")
+  with open(config_json_path, "rt") as conf:
+      try:
+          config_file = json.load(conf)
+      except (ValueError, IOError):
+          raise ValueError(
+              "The input path is expected to contain valid JSON content, "
+              "but cannot read valid JSON content from %s." % config_json_path
+          )
+
+  with open(meta_data_json_path, "rt") as meta_json:
+      try:
+          meta_file = json.load(meta_json)
+      except (ValueError, IOError):
+          raise ValueError(
+              "The input path is expected to contain valid JSON content, "
+              "but cannot read valid JSON content from %s." % meta_data_json_path
+          )
+
+  model_json, groups = conversion.h5_v3_merged_saved_model_to_tfjs_format(
+      h5_file, meta_file, config_file, split_by_layer=split_weights_by_layer
+  )
+
+  if output_dir:
+    if os.path.isfile(output_dir):
+      raise ValueError(
+          'Output path "%s" already exists as a file' % output_dir)
+    if not os.path.isdir(output_dir):
+      os.makedirs(output_dir)
+    conversion.write_artifacts(
+      model_json, groups, output_dir, quantization_dtype_map,
+      weight_shard_size_bytes=weight_shard_size_bytes, metadata=metadata)
+
+  return model_json, groups
 
 def dispatch_keras_h5_to_tfjs_graph_model_conversion(
     h5_path, output_dir=None,
     quantization_dtype_map=None,
     skip_op_check=False,
     strip_debug_ops=False,
     use_structured_outputs_names=False,
@@ -205,15 +288,14 @@
         split_weights_by_layer=split_weights_by_layer,
         weight_shard_size_bytes=weight_shard_size_bytes,
         metadata=metadata)
 
     # Delete temporary .h5 file.
     os.remove(temp_h5_path)
 
-
 def dispatch_tensorflowjs_to_keras_h5_conversion(config_json_path, h5_path):
   """Converts a TensorFlow.js Layers model format to Keras H5.
 
   Args:
     config_json_path: Path to the JSON file that includes the model's
       topology and weights manifest, in tensorflowjs format.
     h5_path: Path for the to-be-created Keras HDF5 model file.
@@ -243,14 +325,50 @@
           'the input path is expected to contain valid JSON content, '
           'but cannot read valid JSON content from %s.' % config_json_path)
 
   with tf.Graph().as_default(), tf.compat.v1.Session():
     model = keras_tfjs_loader.load_keras_model(config_json_path)
     model.save(h5_path)
 
+def dispatch_tensorflowjs_to_keras_keras_conversion(config_json_path, v3_path):
+  """Converts a TensorFlow.js Layers model format to Keras V3 format.
+
+  Args:
+    config_json_path: Path to the JSON file that includes the model's
+      topology and weights manifest, in tensorflowjs format.
+    v3_path: Path for the to-be-created Keras V3 model file.
+
+  Raises:
+    ValueError, if `config_json_path` is not a path to a valid JSON
+      file.
+  """
+  if os.path.isdir(config_json_path):
+    raise ValueError(
+        'For input_type=tfjs_layers_model & output_format=keras_keras, '
+        'the input path should be a model.json '
+        'file, but received a directory.')
+  if os.path.isdir(v3_path):
+    raise ValueError(
+        'For input_type=tfjs_layers_model & output_format=keras_keras, '
+        'the output path should be the path to a .keras file, '
+        'but received an existing directory (%s).' % v3_path)
+
+  # Verify that config_json_path points to a JSON file.
+  with open(config_json_path, 'rt') as f:
+    try:
+      json.load(f)
+    except (ValueError, IOError):
+      raise ValueError(
+          'For input_type=tfjs_layers_model & output_format=keras_keras, '
+          'the input path is expected to contain valid JSON content, '
+          'but cannot read valid JSON content from %s.' % config_json_path)
+
+  model = keras_tfjs_loader.load_keras_keras_model(config_json_path)
+  tf.keras.saving.save_model(model, v3_path, save_format="keras")
+
 
 def dispatch_tensorflowjs_to_keras_saved_model_conversion(
     config_json_path, keras_saved_model_path):
   """Converts a TensorFlow.js Layers model format to a tf.keras SavedModel.
 
   Args:
     config_json_path: Path to the JSON file that includes the model's
@@ -499,14 +617,22 @@
       output_format == common.TFJS_LAYERS_MODEL):
     dispatch_keras_h5_to_tfjs_layers_model_conversion(
         args.input_path, output_dir=args.output_path,
         quantization_dtype_map=quantization_dtype_map,
         split_weights_by_layer=args.split_weights_by_layer,
         weight_shard_size_bytes=weight_shard_size_bytes,
         metadata=metadata_map)
+  elif (input_format == common.KERAS_KERAS_MODEL and
+        output_format == common.TFJS_LAYERS_MODEL):
+    dispatch_keras_keras_to_tfjs_layers_model_conversion(
+        args.input_path, output_dir=args.output_path,
+        quantization_dtype_map=quantization_dtype_map,
+        split_weights_by_layer=args.split_weights_by_layer,
+        weight_shard_size_bytes=weight_shard_size_bytes,
+        metadata=metadata_map)
   elif (input_format == common.KERAS_MODEL and
         output_format == common.TFJS_GRAPH_MODEL):
     dispatch_keras_h5_to_tfjs_graph_model_conversion(
         args.input_path, output_dir=args.output_path,
         quantization_dtype_map=quantization_dtype_map,
         skip_op_check=args.skip_op_check,
         strip_debug_ops=args.strip_debug_ops,
@@ -552,14 +678,18 @@
         experiments=args.experiments,
         metadata=metadata_map)
   elif (input_format == common.TFJS_LAYERS_MODEL and
         output_format == common.KERAS_MODEL):
     dispatch_tensorflowjs_to_keras_h5_conversion(args.input_path,
                                                  args.output_path)
   elif (input_format == common.TFJS_LAYERS_MODEL and
+        output_format == common.KERAS_KERAS_MODEL):
+    dispatch_tensorflowjs_to_keras_keras_conversion(args.input_path,
+                                                 args.output_path)
+  elif (input_format == common.TFJS_LAYERS_MODEL and
         output_format == common.KERAS_SAVED_MODEL):
     dispatch_tensorflowjs_to_keras_saved_model_conversion(args.input_path,
                                                           args.output_path)
   elif (input_format == common.TFJS_LAYERS_MODEL and
         output_format == common.TFJS_LAYERS_MODEL):
     dispatch_tensorflowjs_to_tensorflowjs_conversion(
         args.input_path, args.output_path,
@@ -611,15 +741,15 @@
       type=str,
       help='Path for all output artifacts.')
   parser.add_argument(
       '--%s' % common.INPUT_FORMAT,
       type=str,
       required=False,
       default=common.TF_SAVED_MODEL,
-      choices=set([common.KERAS_MODEL, common.KERAS_SAVED_MODEL,
+      choices=set([common.KERAS_MODEL, common.KERAS_SAVED_MODEL, common.KERAS_KERAS_MODEL,
                    common.TF_SAVED_MODEL, common.TF_HUB_MODEL,
                    common.TFJS_LAYERS_MODEL, common.TF_FROZEN_MODEL]),
       help='Input format. '
       'For "keras", the input path can be one of the two following formats:\n'
       '  - A topology+weights combined HDF5 (e.g., generated with'
       '    `tf.keras.model.save_model()` method).\n'
       '  - A weights-only HDF5 (e.g., generated with Keras Model\'s '
@@ -633,15 +763,15 @@
       'For "tf" formats, a SavedModel, frozen model, '
       ' or TF-Hub module is expected.')
   parser.add_argument(
       '--%s' % common.OUTPUT_FORMAT,
       type=str,
       required=False,
       choices=set([common.KERAS_MODEL, common.KERAS_SAVED_MODEL,
-                   common.TFJS_LAYERS_MODEL, common.TFJS_GRAPH_MODEL]),
+                   common.TFJS_LAYERS_MODEL, common.TFJS_GRAPH_MODEL, common.KERAS_KERAS_MODEL]),
       help='Output format. Default: tfjs_graph_model.')
   parser.add_argument(
       '--%s' % common.SIGNATURE_NAME,
       type=str,
       default=None,
       help='Signature of the SavedModel Graph or TF-Hub module to load. '
       'Applicable only if input format is "tf_hub" or "tf_saved_model".')
@@ -747,14 +877,15 @@
       help='Attach user defined metadata in format key:path/metadata.json '
       'Separate multiple metadata files by comma.'
   )
   return parser
 
 def convert(arguments):
   args = get_arg_parser().parse_args(arguments)
+
   if args.show_version:
     print('\ntensorflowjs %s\n' % version.version)
     print('Dependency versions:')
     print('  keras %s' % tf.keras.__version__)
     print('  tensorflow %s' % tf.__version__)
     return
```

## tensorflowjs/converters/graph_rewrite_util.py

```diff
@@ -18,14 +18,15 @@
 from tensorflow.core.framework import node_def_pb2
 from tensorflow.python.framework import tensor_util
 
 # Custom op name for fused depthwise conv2d
 FUSED_DEPTHWISE_CONV2D = 'FusedDepthwiseConv2dNative'
 # The grappler op name for fused MatMul which starts with '_'
 FUSED_MATMUL = '_FusedMatMul'
+FUSED_CONV2D = '_FusedConv2D'
 
 def node_from_map(node_map, name):
   """Pulls a node def from a dictionary for a given name.
 
   Args:
     node_map: Dictionary containing an entry indexed by name for every node.
     name: Identifies the node we want to find.
@@ -124,7 +125,15 @@
       new_node.name = prefix + '/' + node.name
     else:
       for i, input_node in enumerate(new_node.input):
         for name in constant_names:
           if input_node.startswith(name):
             new_node.input[i] = prefix + '/' + input_node
   return nodes
+
+def get_output_node_names(node_map, target):
+  output_node_names = []
+  for name, node in node_map.items():
+    for input_name in node.input:
+      if target == input_name:
+        output_node_names.append(name)
+  return output_node_names
```

## tensorflowjs/converters/keras_h5_conversion.py

```diff
@@ -83,14 +83,41 @@
     # 'foo/bar/Dense').
     for key in group.keys():
       # Call this method recursively.
       group_out += _convert_h5_group(group[key])
 
   return group_out
 
+def _convert_v3_group(group, actual_layer_name):
+  """Construct a weights group entry.
+
+  Args:
+    group: The HDF5 group data, possibly nested.
+
+  Returns:
+    An array of weight groups (see `write_weights` in TensorFlow.js).
+  """
+  group_out = []
+  list_of_folder = [as_text(name) for name in group]
+  if 'vars' in list_of_folder:
+    names = group['vars']
+    if not names:
+      return group_out
+    name_list = [as_text(name) for name in names]
+    weight_values = [np.array(names[weight_name]) for weight_name in name_list]
+    name_list = [os.path.join(actual_layer_name, item) for item in name_list]
+    group_out += [{
+    'name': normalize_weight_name(weight_name),
+    'data': weight_value
+    } for (weight_name, weight_value) in zip(name_list, weight_values)]
+  else:
+    for key in list_of_folder:
+      group_out += _convert_v3_group(group[key], actual_layer_name)
+  return group_out
+
 
 def _check_version(h5file):
   """Check version compatiility.
 
   Args:
     h5file: An h5file object.
 
@@ -124,14 +151,26 @@
   else:
     return h5file
 
 
 def _ensure_json_dict(item):
   return item if isinstance(item, dict) else json.loads(as_text(item))
 
+def _discard_v3_keys(json_dict, keys_to_delete):
+  if isinstance(json_dict, dict):
+    keys = list(json_dict.keys())
+    for key in keys:
+      if key in keys_to_delete:
+        del json_dict[key]
+      else:
+        _discard_v3_keys(json_dict[key], keys_to_delete)
+  elif isinstance(json_dict, list):
+    for item in json_dict:
+      _discard_v3_keys(item, keys_to_delete)
+
 
 # https://github.com/tensorflow/tfjs/issues/1255, b/124791387
 # In tensorflow version 1.13 and some alpha and nightly-preview versions,
 # the following layers have different class names in their serialization.
 # This issue should be fixed in later releases. But we include the logic
 # to translate them anyway, for users who use those versions of tensorflow.
 _CLASS_NAME_MAP = {
@@ -207,14 +246,64 @@
     if group:
       if split_by_layer:
         groups.append(group)
       else:
         groups[0] += group
   return model_json, groups
 
+def h5_v3_merged_saved_model_to_tfjs_format(h5file, meta_file, config_file,split_by_layer=False):
+  """Load topology & weight values from HDF5 file and convert.
+
+  The HDF5 weights file is one generated by Keras's save_model method or model.save()
+
+  N.B.:
+  1) This function works only on HDF5 values from Keras version 3.
+  2) This function does not perform conversion for special weights including
+      ConvLSTM2D and CuDNNLSTM.
+
+  Args:
+    h5file: An instance of h5py.File, or the path to an h5py file.
+    split_by_layer: (Optional) whether the weights of different layers are
+      to be stored in separate weight groups (Default: `False`).
+
+  Returns:
+    (model_json, groups)
+      model_json: a JSON dictionary holding topology and system metadata.
+      group: an array of group_weights as defined in tfjs write_weights.
+
+  Raises:
+    ValueError: If the Keras version of the HDF5 file is not supported.
+  """
+  h5file = _ensure_h5file(h5file)
+  model_json = dict()
+  model_json['keras_version'] = meta_file['keras_version']
+
+  keys_to_remove = ["module", "registered_name", "date_saved"]
+  config = _ensure_json_dict(config_file)
+  _discard_v3_keys(config, keys_to_remove)
+  model_json['model_config'] = config
+  translate_class_names(model_json['model_config'])
+  if 'training_config' in h5file.attrs:
+    model_json['training_config'] = _ensure_json_dict(
+        h5file.attrs['training_config'])
+
+  groups = [] if split_by_layer else [[]]
+
+  model_weights = h5file['_layer_checkpoint_dependencies']
+  layer_names = [as_text(n) for n in model_weights]
+
+  for index, layer_name in enumerate(layer_names):
+    group_of_weights = model_weights[layer_name]
+    group = _convert_v3_group(group_of_weights, layer_name)
+    if group:
+      if split_by_layer:
+        groups.append(group)
+      else:
+        groups[0] += group
+  return model_json, groups
 
 def h5_weights_to_tfjs_format(h5file, split_by_layer=False):
   """Load weight values from a Keras HDF5 file and to a binary format.
 
   The HDF5 file is one generated by Keras' Model.save_weights() method.
 
   N.B.:
```

## tensorflowjs/converters/keras_tfjs_loader.py

```diff
@@ -17,20 +17,26 @@
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 import json
 import os
 import uuid
-
+import zipfile
+import datetime
 import six
 import tensorflow.compat.v2 as tf
-
-from tensorflowjs import read_weights
+from tensorflowjs.converters import tf_module_mapper
 from tensorflowjs.converters import keras_h5_conversion
+from tensorflowjs.converters.tf_module_mapper import TFCLASS_MODULE_MAP
+from tensorflowjs import read_weights
+
+_CONFIG_FILENAME = "config.json"
+_METADATA_FILENAME = "metadata.json"
+_VARS_FNAME = "model.weights"
 
 
 def _deserialize_keras_model(model_topology_json,
                              weight_entries=None,
                              use_unique_name_scope=False):
   """Internal helper method for deserializing a Keras Model.
 
@@ -88,14 +94,70 @@
         shorten_name = '/'.join(tokens[0:-2] + [tokens[-1]])
         weights_list.append(weights_dict[shorten_name])
 
     model.set_weights(weights_list)
 
   return model
 
+def _deserialize_keras_keras_model(model_topology_json,
+                             weight_entries=None,
+                             use_unique_name_scope=False):
+  """Internal helper method for deserializing a Keras V3 Model.
+
+  Args:
+    model_topology_json: content of the JSON containing model topology, in
+      Keras (i.e., tfjs-layers) format. It can be any of the following types:
+      - A JSON object, i.e., a `dict`.
+      - A `str` or `buffer`, in which case it will be parsed as a JSON object.
+      - A `file` object or `file`-like object containing the JSON, in which
+        case it will be read with the `read()` method and the content parsed
+        as a JSON object.
+    weight_entries: Weight entries, in tensorflow.js format, as a `list`.
+    use_unique_name_scope: Use a unique ID as the name scope for the loaded
+      model. This may facilitate loading of multiple Keras models in the
+      same TensorFlow Graph or Session context. Default: `False`.
+  """
+  if isinstance(model_topology_json, (six.string_types, bytes)):
+    model_topology_json = json.loads(tf.compat.as_text(model_topology_json))
+  elif not isinstance(model_topology_json, dict):
+    model_topology_json = json.load(model_topology_json)
+
+  if 'model_config' in model_topology_json:
+    # Build the map between class and its corresponding module in TF.
+    _generate_v3_keys(model_topology_json['model_config'])
+    model_topology_json = model_topology_json['model_config']
+
+  model = tf.keras.models.model_from_json(json.dumps(model_topology_json))
+
+  if weight_entries:
+    weights_dict = dict()
+    for weight_entry in weight_entries:
+      weights_dict[weight_entry['name']] = weight_entry['data']
+
+    # Collect weight names from the model, in the same order as the internal
+    # ordering of model.set_weights() used below.
+
+    weight_names = []
+    for layer in model.layers:
+      for index, w in enumerate(layer.weights):
+        weight_names.append(layer.name + '/' + str(index))
+
+
+    # Prepare list of weight values for calling set_weights().
+    weights_list = []
+
+    for name in weight_names:
+      if name in weights_dict:
+        weights_list.append(weights_dict[name])
+      else:
+        raise Exception(f"${name} does not exist in weights entries.")
+
+    model.set_weights(weights_list)
+
+  return model
 
 def _check_config_json(config_json):
   if not isinstance(config_json, dict):
     raise TypeError(
         'The JSON content is required to be a `dict`, but found %s.' %
         type(config_json))
   if 'modelTopology' not in config_json:
@@ -104,14 +166,29 @@
 
 def _get_weights_manifest_from_config_json(config_json):
   if 'weightsManifest' not in config_json:
     raise KeyError(
         'Field "weightsManifest" is missing from the JSON content.')
   return config_json['weightsManifest']
 
+def _generate_v3_keys(config):
+  if isinstance(config, dict):
+    list_of_keys = list(config.keys())
+    for key in list_of_keys:
+      _generate_v3_keys(config[key])
+    if 'class_name' in list_of_keys:
+      config['module'] = tf_module_mapper.get_module_path(config['class_name'])
+      # Put registred name as None since we do not support
+      # custom object saving when we save the model.
+      config['registered_name'] = None
+
+  elif isinstance(config, list):
+    for item in config:
+      _generate_v3_keys(item)
+
 
 def deserialize_keras_model(config_json,
                             weight_data=None,
                             use_unique_name_scope=False):
   """Deserialize a Keras Model from buffers or file-like objects.
 
   Args:
@@ -218,7 +295,74 @@
       weight_entries = read_weights.decode_weights(weights_manifest,
                                                    weights_data_buffers,
                                                    flatten=True)
 
   return _deserialize_keras_model(config_json['modelTopology'],
                                   weight_entries=weight_entries,
                                   use_unique_name_scope=use_unique_name_scope)
+
+def load_keras_keras_model(config_json_path,
+                     weights_path_prefix=None,
+                     weights_data_buffers=None,
+                     load_weights=True,
+                     use_unique_name_scope=False):
+  """Load a Keras Model from TensorFlow.js-format artifacts from file system
+
+  Args:
+    config_json_path: Path to the TensorFlow.js-format JSON file that includes
+      the model topology and weights manifest.
+    weights_path_prefix: Optional path prefix for the weights files.
+      If not specified (`None`), will assume the prefix is the same directory
+      as the dirname of `config_json_path`.
+    weights_data_buffers: A buffer of a `list` of buffers containing the weight
+      values concatenated and sharded in the order as specified by the
+      weights manifest at `config_json_path`. This argument is mutually
+      exclusive with `weights_path_prefix`.
+    load_weights: Whether the weights are to be loaded according
+      to the weights manifest at `config_json_path`. Default: `True`.
+    use_unique_name_scope: Use a unique ID as the name scope for the loaded
+      model. This may facilitate loading of multiple Keras models in the
+      same TensorFlow Graph or Session context. Default: `False`.
+
+  Returns:
+    The loaded instance of `tf.keras.Model`.
+
+  Raises:
+    TypeError, if the format of the JSON content of `config_json_path` has an
+      invalid format.
+    KeyError, if required keys do not exist in the JSON content of
+      `config_json_path`.
+    ValueError, if both `weights_data_buffers` and `weights_path_prefix` are
+      provided.
+  """
+  if weights_data_buffers and weights_path_prefix:
+    raise ValueError(
+        'The arguments weights_data_buffers and weights_path_prefix are '
+        'mutually exclusive and should not be both specified.')
+
+  with open(config_json_path, 'rt') as f:
+    config_json = json.load(f)
+    _check_config_json(config_json)
+
+  weight_entries = None
+  if load_weights:
+    weights_manifest = _get_weights_manifest_from_config_json(config_json)
+
+    if not weights_data_buffers and not weights_path_prefix:
+      weights_path_prefix = os.path.dirname(
+          os.path.realpath(config_json_path))
+    if not os.path.isdir(weights_path_prefix):
+      raise ValueError(
+          'Weights path prefix is not an existing directory: %s' %
+          weights_path_prefix)
+    if weights_path_prefix:
+      weight_entries = read_weights.read_weights(weights_manifest,
+                                                 weights_path_prefix,
+                                                 flatten=True)
+    else:
+      weight_entries = read_weights.decode_weights(weights_manifest,
+                                                   weights_data_buffers,
+                                                   flatten=True)
+
+  return _deserialize_keras_keras_model(config_json['modelTopology'],
+                                     weight_entries=weight_entries,
+                                     use_unique_name_scope=use_unique_name_scope)
```

## tensorflowjs/converters/tf_saved_model_conversion_v2.py

```diff
@@ -48,14 +48,15 @@
 from tensorflow.saved_model.experimental import TrackableResource
 from google.protobuf.json_format import MessageToDict
 import tensorflow_hub as hub
 from packaging import version
 
 from tensorflowjs import write_weights
 from tensorflowjs.converters import common
+from tensorflowjs.converters import normalize_bias_add
 from tensorflowjs.converters import fold_batch_norms
 from tensorflowjs.converters import fuse_prelu
 from tensorflowjs.converters import fuse_depthwise_conv2d
 from tensorflowjs.converters import graph_rewrite_util
 from tensorflowjs import resource_loader
 
 CLEARED_TENSOR_FIELDS = (
@@ -165,14 +166,16 @@
     rewriter_config.optimizers.insert(0, 'debug_stripper')
 
   optimized_graph = _run_grappler(config, graph_def, graph, signature_def)
 
   # batch norm folding
   optimized_graph = fold_batch_norms.fold_batch_norms(optimized_graph)
 
+  optimized_graph = normalize_bias_add.normalize_bias_add_op(optimized_graph)
+
   # set the device to CPU for all Conv2d and MatMul nodes, since grappler
   # remap optimizer only support FusedConv2D and FusedMatMul for CPU.
   for node in optimized_graph.node:
     if node.op == 'Conv2D' or node.op == 'MatMul':
       node.device = '/device:CPU:0'
 
   # rerun grappler to fuse conv2d/matmul
```

## tensorflowjs/version.py

```diff
@@ -1,4 +1,4 @@
 # @license See the LICENSE file.
 
 # This code is auto-generated, do not modify this file!
-version = '4.8.0'
+version = '4.9.0'
```

## Comparing `tensorflowjs-4.8.0.dist-info/METADATA` & `tensorflowjs-4.9.0.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -28,15 +28,15 @@
 Requires-Dist: packaging~=20.9
 Provides-Extra: PyInquirer
 Requires-Dist: PyInquirer==1.0.3; extra == 'PyInquirer'
 Provides-Extra: all
 Requires-Dist: PyInquirer==1.0.3; extra == 'all'
 Provides-Extra: wizard
 Requires-Dist: PyInquirer==1.0.3; extra == 'wizard'
-Version: 4.8.0
+Version: 4.9.0
 
 # tensorflowjs: The Python Package for TensorFlow.js
 
 The **tensorflowjs** pip package contains libraries and tools for
 [TensorFlow.js](https://js.tensorflow.org).
 
 Use following command to install the library with support of interactive CLI:
```

## Comparing `tensorflowjs-4.8.0.dist-info/RECORD` & `tensorflowjs-4.9.0.dist-info/RECORD`

 * *Files 5% similar despite different names*

```diff
@@ -1,20 +1,22 @@
 tensorflowjs/__init__.py,sha256=EjGoDSb_mMbMPD5C1z5-AOzNxpwroNGAH_MXnjyspwE,937
 tensorflowjs/converters/__init__.py,sha256=b2hEmCOHFJptYBiYMVqV1LKsRKHlqC7VVPMaJSBKaH0,1240
-tensorflowjs/converters/common.py,sha256=aZ1_sWyzx3384ExAvJ3clSskXVpgDwE2civJpy8Fkkg,2579
+tensorflowjs/converters/common.py,sha256=MV8Hf3dWD_wrjGjcs_rwrEas-jM0QDk1o7OYUeGpO2g,2613
 tensorflowjs/converters/converter,sha256=oeBHY2ZFqOsI0-jC_2gj9hu7g8Oy3EEe7FRkhhmMc_A,17618
-tensorflowjs/converters/converter.py,sha256=OwCJDFQ1EfVq-tVXcqil2Bkp1nxdGnvyWRTNKez_nI4,33823
+tensorflowjs/converters/converter.py,sha256=tRbmbkhrbcXRUC4QMLN0cgewizW-ub1c6nFTnPY4LIo,39392
 tensorflowjs/converters/fold_batch_norms.py,sha256=1KJyRe3RTh0kEDwBaOg5l6TzbdWBpPl5-bylT15nE_E,11841
 tensorflowjs/converters/fuse_depthwise_conv2d.py,sha256=NaFcqAA7a-1v8WGic-Fe4gpnzB2igAXhljf1EeiZ5HI,5632
 tensorflowjs/converters/fuse_prelu.py,sha256=NerR7SJW_YXXAPIF4lSvs8MLqOeuRLaAAXEyCfEpw_Q,6568
-tensorflowjs/converters/graph_rewrite_util.py,sha256=2mnOktgui6Nh4IrarHzgNSbc99vJnRmDdOak5l2itXk,4330
+tensorflowjs/converters/graph_rewrite_util.py,sha256=k_jDJutJ9uVhrPw_TEqXhQwDgfPZfsJAzoo4n7k7jG0,4600
 tensorflowjs/converters/jax_conversion.py,sha256=-NQVdfm_q7hVEbvMifQog6Ma8aDq0y3KWVRkx-PMRzU,6196
-tensorflowjs/converters/keras_h5_conversion.py,sha256=JAP-aVGN_pbn50wixQNtxz2taOLsjyDRDIOv4D52pYM,12457
-tensorflowjs/converters/keras_tfjs_loader.py,sha256=-RNbAEkPVE8T57elzkKvEuZqHd6KnnVZgnOlebCEWxA,9539
-tensorflowjs/converters/tf_saved_model_conversion_v2.py,sha256=dIOhZER6BU09LLM2v1GwGVUBgosRhjbLkhKzf1YPKUc,52392
+tensorflowjs/converters/keras_h5_conversion.py,sha256=vOYwq3eCfjAIkwduatA0MPDDfbHPq7qXXr1MBsl8Pxc,15596
+tensorflowjs/converters/keras_tfjs_loader.py,sha256=1kNLRV_8OQPilnswQIEKOKL9mvk9wWN0vlMa40uE1U4,15676
+tensorflowjs/converters/normalize_bias_add.py,sha256=hxO3S5D9xiIJf1cJ4uHSBTKUeg06rm-wnNiregWm39k,2694
+tensorflowjs/converters/tf_module_mapper.py,sha256=MCIW0ISygAFLsfZ5nwMfPAKNoEOEZNBbJEtPsUVFdvU,1888
+tensorflowjs/converters/tf_saved_model_conversion_v2.py,sha256=YhpDb_Dl7BAIt_-XcCcvjl-Cu6WyA7kcH311eEgUuno,52526
 tensorflowjs/converters/wizard,sha256=wt0MLgmu2sP7q_V8JMCQgqpmu9sQG2z7VnOjhnZxvXQ,17838
 tensorflowjs/converters/wizard.py,sha256=AveM8pHkJmaxjOhyYhMHqQqsyCXcDdgw98Bqow2fjEs,24284
 tensorflowjs/op_list/arithmetic.json,sha256=0W2wz_JfonmEVw3eXibvqMKNT5kMLRSKdoPHvUruI38,6211
 tensorflowjs/op_list/basic_math.json,sha256=22aS3xvhqCKPD2DDjKu_3VY-4HMBjPVwfPrigFMxLhs,14379
 tensorflowjs/op_list/control.json,sha256=vr6wJY0UcAvz2Ot5erZBpjikiT3vBFe_E2q1n2imGc4,15173
 tensorflowjs/op_list/convolution.json,sha256=G0DhajSQyyMEQj3-B-kd2VqcW08SxLMGW0IJxRgngw0,13113
 tensorflowjs/op_list/creation.json,sha256=l6t991fBdD5MuB9ZnVGZVQ5_XWT4fmGS5RMZYGXMs30,7037
@@ -33,13 +35,13 @@
 tensorflowjs/op_list/spectral.json,sha256=eZQc9AoQk236woVSgtVfNI9OFQrOgeO2Rt_ek6RLBEk,906
 tensorflowjs/op_list/string.json,sha256=q5LSTvTRW0WRCJpjXHlJJx5STrnSua_Eq-ryfJdBz34,2266
 tensorflowjs/op_list/tfdf.json,sha256=XX8XE9OSvkwQrYSY7GtAvB28gj4vX-L4t3f14WCSB30,178
 tensorflowjs/op_list/transformation.json,sha256=rzTpWRh5L304tWQmsT8hl9FOEXc9t8VMDgLX2IZ-qrY,4426
 tensorflowjs/quantization.py,sha256=uYoDMZnYdx3FxCVXOc9cvs8pPnO_dLvNAh19-rNtI2A,8514
 tensorflowjs/read_weights.py,sha256=Tn8XaLiXP5ojX7HmuonzTq_VoUhUCrHJqUFdsfjcIk0,7438
 tensorflowjs/resource_loader.py,sha256=d-MLMXXGU-2I90z6kTTako6OO0wn3F2kYHDJjotim_w,1627
-tensorflowjs/version.py,sha256=w5ow2aM9JRjZ0sogxBon5ddChNfbSUlxyLcvUWaIHPw,108
+tensorflowjs/version.py,sha256=0rVZGv0szkmI6UqzMhaTmBv7wm0S5xF6SUqBUaxjpjA,108
 tensorflowjs/write_weights.py,sha256=Pn_zuY7p0NU0szTRqXXXsl6-Xwk9JIicZWlHMLbQk3Y,14284
-tensorflowjs-4.8.0.dist-info/METADATA,sha256=HvQo2YJ0jXJseYoZMnGQzeZe8LhlqbwFa2a_-TwFsXI,3147
-tensorflowjs-4.8.0.dist-info/RECORD,,
-tensorflowjs-4.8.0.dist-info/WHEEL,sha256=sobxWSyDDkdg_rinUth-jxhXHqoNqlmNMJY3aTZn2Us,91
-tensorflowjs-4.8.0.dist-info/entry_points.txt,sha256=6CS11-EMuW5-_g9oqEkrA0LpK_GfKlwFR-Zp661TrB8,147
+tensorflowjs-4.9.0.dist-info/METADATA,sha256=bPhN02t6pAZo3J5PRUG42QhyxiK8zo5_OUi4yuBusEA,3147
+tensorflowjs-4.9.0.dist-info/RECORD,,
+tensorflowjs-4.9.0.dist-info/WHEEL,sha256=sobxWSyDDkdg_rinUth-jxhXHqoNqlmNMJY3aTZn2Us,91
+tensorflowjs-4.9.0.dist-info/entry_points.txt,sha256=6CS11-EMuW5-_g9oqEkrA0LpK_GfKlwFR-Zp661TrB8,147
```

