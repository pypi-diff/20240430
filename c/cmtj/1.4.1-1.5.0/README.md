# Comparing `tmp/cmtj-1.4.1-cp39-cp39-win_amd64.whl.zip` & `tmp/cmtj-1.5.0-cp312-cp312-macosx_10_9_universal2.whl.zip`

## zipinfo {}

```diff
@@ -1,27 +1,30 @@
-Zip file size: 224099 bytes, number of entries: 25
--rw-rw-rw-  2.0 fat      530 b- defN 24-Jan-05 21:16 cmtj-1.4.1-py3.9-nspkg.pth
--rw-rw-rw-  2.0 fat   437248 b- defN 24-Jan-05 21:16 cmtj.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat      154 b- defN 24-Jan-05 21:15 cmtj/models/__init__.py
--rw-rw-rw-  2.0 fat    11366 b- defN 24-Jan-05 21:15 cmtj/models/domain_dynamics.py
--rw-rw-rw-  2.0 fat      357 b- defN 24-Jan-05 21:15 cmtj/models/drivers.py
--rw-rw-rw-  2.0 fat     1613 b- defN 24-Jan-05 21:15 cmtj/models/ensemble.py
--rw-rw-rw-  2.0 fat    29249 b- defN 24-Jan-05 21:15 cmtj/models/general_sb.py
--rw-rw-rw-  2.0 fat     8040 b- defN 24-Jan-05 21:15 cmtj/models/oersted.py
--rw-rw-rw-  2.0 fat      739 b- defN 24-Jan-05 21:15 cmtj/utils/__init__.py
--rw-rw-rw-  2.0 fat     2726 b- defN 24-Jan-05 21:15 cmtj/utils/energy.py
--rw-rw-rw-  2.0 fat     2396 b- defN 24-Jan-05 21:15 cmtj/utils/filters.py
--rw-rw-rw-  2.0 fat     3768 b- defN 24-Jan-05 21:15 cmtj/utils/general.py
--rw-rw-rw-  2.0 fat     4689 b- defN 24-Jan-05 21:15 cmtj/utils/linear.py
--rw-rw-rw-  2.0 fat     3688 b- defN 24-Jan-05 21:15 cmtj/utils/optimization.py
--rw-rw-rw-  2.0 fat     1608 b- defN 24-Jan-05 21:15 cmtj/utils/parallel.py
--rw-rw-rw-  2.0 fat    11365 b- defN 24-Jan-05 21:15 cmtj/utils/plotting.py
--rw-rw-rw-  2.0 fat    13671 b- defN 24-Jan-05 21:15 cmtj/utils/procedures.py
--rw-rw-rw-  2.0 fat     3391 b- defN 24-Jan-05 21:15 cmtj/utils/resistance.py
--rw-rw-rw-  2.0 fat     1402 b- defN 24-Jan-05 21:15 cmtj/utils/solvers.py
--rw-rw-rw-  2.0 fat    18431 b- defN 24-Jan-05 21:16 cmtj-1.4.1.dist-info/LICENSE
--rw-rw-rw-  2.0 fat     6565 b- defN 24-Jan-05 21:16 cmtj-1.4.1.dist-info/METADATA
--rw-rw-rw-  2.0 fat      100 b- defN 24-Jan-05 21:16 cmtj-1.4.1.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        5 b- defN 24-Jan-05 21:15 cmtj-1.4.1.dist-info/namespace_packages.txt
--rw-rw-rw-  2.0 fat        5 b- defN 24-Jan-05 21:15 cmtj-1.4.1.dist-info/top_level.txt
--rw-rw-r--  2.0 fat     1991 b- defN 24-Jan-05 21:16 cmtj-1.4.1.dist-info/RECORD
-25 files, 565097 bytes uncompressed, 220929 bytes compressed:  60.9%
+Zip file size: 637621 bytes, number of entries: 28
+-rw-r--r--  2.0 unx      457 b- defN 24-Apr-30 15:34 cmtj-1.5.0-py3.12-nspkg.pth
+-rwxr-xr-x  2.0 unx  2118512 b- defN 24-Apr-30 15:34 cmtj.cpython-312-darwin.so
+-rw-r--r--  2.0 unx      146 b- defN 24-Apr-30 15:33 cmtj/models/__init__.py
+-rw-r--r--  2.0 unx    11041 b- defN 24-Apr-30 15:33 cmtj/models/domain_dynamics.py
+-rw-r--r--  2.0 unx      335 b- defN 24-Apr-30 15:33 cmtj/models/drivers.py
+-rw-r--r--  2.0 unx     1562 b- defN 24-Apr-30 15:33 cmtj/models/ensemble.py
+-rw-r--r--  2.0 unx    30154 b- defN 24-Apr-30 15:33 cmtj/models/general_sb.py
+-rw-r--r--  2.0 unx    11343 b- defN 24-Apr-30 15:33 cmtj/models/noise.py
+-rw-r--r--  2.0 unx     7819 b- defN 24-Apr-30 15:33 cmtj/models/oersted.py
+-rw-r--r--  2.0 unx     1104 b- defN 24-Apr-30 15:33 cmtj/noise/__init__.pyi
+-rw-r--r--  2.0 unx     5408 b- defN 24-Apr-30 15:33 cmtj/stack/__init__.pyi
+-rw-r--r--  2.0 unx      711 b- defN 24-Apr-30 15:33 cmtj/utils/__init__.py
+-rw-r--r--  2.0 unx     2655 b- defN 24-Apr-30 15:33 cmtj/utils/energy.py
+-rw-r--r--  2.0 unx     2332 b- defN 24-Apr-30 15:33 cmtj/utils/filters.py
+-rw-r--r--  2.0 unx     3660 b- defN 24-Apr-30 15:33 cmtj/utils/general.py
+-rw-r--r--  2.0 unx     4565 b- defN 24-Apr-30 15:33 cmtj/utils/linear.py
+-rw-r--r--  2.0 unx     3581 b- defN 24-Apr-30 15:33 cmtj/utils/optimization.py
+-rw-r--r--  2.0 unx     1560 b- defN 24-Apr-30 15:33 cmtj/utils/parallel.py
+-rw-r--r--  2.0 unx    11067 b- defN 24-Apr-30 15:33 cmtj/utils/plotting.py
+-rw-r--r--  2.0 unx    13342 b- defN 24-Apr-30 15:33 cmtj/utils/procedures.py
+-rw-r--r--  2.0 unx     3309 b- defN 24-Apr-30 15:33 cmtj/utils/resistance.py
+-rw-r--r--  2.0 unx     1356 b- defN 24-Apr-30 15:33 cmtj/utils/solvers.py
+-rw-r--r--  2.0 unx    18092 b- defN 24-Apr-30 15:34 cmtj-1.5.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     7169 b- defN 24-Apr-30 15:34 cmtj-1.5.0.dist-info/METADATA
+-rw-r--r--  2.0 unx      115 b- defN 24-Apr-30 15:34 cmtj-1.5.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx        5 b- defN 24-Apr-30 15:33 cmtj-1.5.0.dist-info/namespace_packages.txt
+-rw-r--r--  2.0 unx        5 b- defN 24-Apr-30 15:33 cmtj-1.5.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     2234 b- defN 24-Apr-30 15:34 cmtj-1.5.0.dist-info/RECORD
+28 files, 2263639 bytes uncompressed, 634083 bytes compressed:  72.0%
```

## zipnote {}

```diff
@@ -1,11 +1,11 @@
-Filename: cmtj-1.4.1-py3.9-nspkg.pth
+Filename: cmtj-1.5.0-py3.12-nspkg.pth
 Comment: 
 
-Filename: cmtj.cp39-win_amd64.pyd
+Filename: cmtj.cpython-312-darwin.so
 Comment: 
 
 Filename: cmtj/models/__init__.py
 Comment: 
 
 Filename: cmtj/models/domain_dynamics.py
 Comment: 
@@ -15,17 +15,26 @@
 
 Filename: cmtj/models/ensemble.py
 Comment: 
 
 Filename: cmtj/models/general_sb.py
 Comment: 
 
+Filename: cmtj/models/noise.py
+Comment: 
+
 Filename: cmtj/models/oersted.py
 Comment: 
 
+Filename: cmtj/noise/__init__.pyi
+Comment: 
+
+Filename: cmtj/stack/__init__.pyi
+Comment: 
+
 Filename: cmtj/utils/__init__.py
 Comment: 
 
 Filename: cmtj/utils/energy.py
 Comment: 
 
 Filename: cmtj/utils/filters.py
@@ -51,26 +60,26 @@
 
 Filename: cmtj/utils/resistance.py
 Comment: 
 
 Filename: cmtj/utils/solvers.py
 Comment: 
 
-Filename: cmtj-1.4.1.dist-info/LICENSE
+Filename: cmtj-1.5.0.dist-info/LICENSE
 Comment: 
 
-Filename: cmtj-1.4.1.dist-info/METADATA
+Filename: cmtj-1.5.0.dist-info/METADATA
 Comment: 
 
-Filename: cmtj-1.4.1.dist-info/WHEEL
+Filename: cmtj-1.5.0.dist-info/WHEEL
 Comment: 
 
-Filename: cmtj-1.4.1.dist-info/namespace_packages.txt
+Filename: cmtj-1.5.0.dist-info/namespace_packages.txt
 Comment: 
 
-Filename: cmtj-1.4.1.dist-info/top_level.txt
+Filename: cmtj-1.5.0.dist-info/top_level.txt
 Comment: 
 
-Filename: cmtj-1.4.1.dist-info/RECORD
+Filename: cmtj-1.5.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## cmtj/models/__init__.py

 * *Ordering differences only*

```diff
@@ -1,8 +1,8 @@
-from .general_sb import LayerDynamic, LayerSB, Solver, VectorObj
-
-__all__ = [
-    "LayerSB",
-    "LayerDynamic",
-    "Solver",
-    "VectorObj",
-]
+from .general_sb import LayerDynamic, LayerSB, Solver, VectorObj
+
+__all__ = [
+    "LayerSB",
+    "LayerDynamic",
+    "Solver",
+    "VectorObj",
+]
```

## cmtj/models/domain_dynamics.py

```diff
@@ -1,305 +1,304 @@
-import math
-from abc import ABC
-from collections import defaultdict
-from dataclasses import dataclass, field
-from typing import Callable, List, Literal
-
-from numba import njit
-from scipy.integrate import RK45
-
-from ..utils import bohr_magneton, echarge, gyromagnetic_ratio, hbar, mu0
-from ..utils.general import VectorObj
-
-gyro = gyromagnetic_ratio
-pi2 = math.pi / 2.
-
-
-class DW:
-    """Initial conditions for the phi of DW equation."""
-    NEEL_RIGHT = 0
-    NEEL_LEFT = math.pi
-    BLOCH_UP = math.pi / 2.
-    BLOCH_DOWN = 3. * math.pi / 2.
-
-
-class DWRelax:
-    NO_RELAX = 0
-    STATIC = 1
-    DYNAMIC = 2
-
-
-@njit
-def get_pinning_field(X, Ms, pinning, Ly, Lz, V0_pin):
-    arg = X * math.pi / pinning
-    dVdx = 2 * math.pi * V0_pin * math.sin(arg) * math.cos(arg)
-    denom = 2 * mu0 * Ms * Lz * Ly
-    return -(1. / denom) * dVdx
-
-
-@njit
-def get_edge_field(X, Lx, V0_edge):
-    c = Lx / 2
-    arg = (X - (Lx / 2)) / c
-    p = 6
-    return -p * V0_edge * (math.sinh(arg) * math.cosh(arg)**(p - 1) / c)
-
-
-@njit
-def get_field_contribution(X, phi, hx, hy, hz, alpha, dw, Ms, V0_pin, pinning,
-                           Ly, Lz):
-
-    pinning = get_pinning_field(X,
-                                Ms=Ms,
-                                pinning=pinning,
-                                Ly=Ly,
-                                Lz=Lz,
-                                V0_pin=V0_pin)
-    dxdt = alpha * gyro * dw * (hz + pinning) + gyro * dw * pi2 * (
-        -hy * math.cos(phi) + hx * math.sin(phi))
-    dphidt = gyro * (hz + pinning) + alpha * gyro * pi2 * (hy * math.cos(phi) -
-                                                           hx * math.sin(phi))
-    return dxdt, dphidt
-
-
-@njit
-def compute_gamma_a(X, phi, Q, dw, hk, hx, hy, hdmi, bj, IECterm):
-    pi2 = math.pi / 2.
-    fact_gamma = -0.5 * hk * math.sin(
-        2 * phi) - pi2 * hy * math.cos(phi) + pi2 * hx * math.sin(
-            phi) + Q * pi2 * hdmi * math.sin(phi) + IECterm
-    fact_stt = bj / dw
-    return gyro * fact_gamma + fact_stt
-
-
-@njit
-def compute_gamma_b(X, phi, Q, dw, hshe, hz, hr, beta, bj, Ms, Lx, Ly, Lz,
-                    V0_pin, V0_edge, pinning):
-    pi2 = math.pi / 2
-    hp = get_pinning_field(X,
-                           Ms=Ms,
-                           pinning=pinning,
-                           Ly=Ly,
-                           Lz=Lz,
-                           V0_pin=V0_pin)
-    he = get_edge_field(X, Lx, V0_edge)
-    fact_gamma = Q * (he + hz + hp + pi2 * hshe *
-                      math.cos(phi)) - beta * pi2 * hr * math.cos(phi)
-    fact_stt = beta * bj / dw
-    return gyro * fact_gamma + fact_stt
-
-
-@njit
-def compute_dynamics(X, phi, delta, alpha, Q, hx, hy, hz, hk, hdmi, hr, hshe,
-                     beta, bj, Ms, Lx, Ly, Lz, V0_pin, V0_edge, pinning,
-                     IECterm, thickness, A, Ku, Kp):
-    gamma_a = compute_gamma_a(X, phi, Q, delta, hk, hx, hy, hdmi, bj, IECterm)
-    gamma_b = compute_gamma_b(X, phi, Q, delta, hshe, hz, hr, beta, bj, Ms, Lx,
-                              Ly, Lz, V0_pin, V0_edge, pinning)
-    dXdt = delta * (gamma_a + alpha * gamma_b)
-    dPhidt = -alpha * gamma_a + gamma_b
-    pref = gyro / (alpha * mu0 * Ms * thickness)
-    # domain width relaxation from Thiaville
-    dDeltadt = pref * (A / delta - delta * (Ku + Kp * math.sin(phi)**2))
-    # dDeltadt  = 0
-    return dXdt, dPhidt, dDeltadt
-
-
-@dataclass
-class DomainWallDynamics:
-    """Domain Wall dynamics class.
-    :param H: applied magnetic field vector.
-    :param alpha: Gilbert damping.
-    :param Ms: magnetisation saturation [A/m].
-    :param thickness: thickness of the FM material.
-    :param SHE_angle: Spin Hall Effect angle.
-    :param D: DMI constant.
-    :param Ku: perpendicular anisotropy constant.
-    :param Kp: inplane anisotropy constant.
-    :param A: exchange constant.
-    :param beta: STT beta parameter.
-    :param p: STT polarisation efficiency.
-    :param V0_pin: pinning voltage constant.
-    :param V0_edge: edge voltage constant.
-    :param pinning: the pinning period.
-    :param Lx: z-dimension of the FM block.
-    :param Ly: y-dimension of the FM block.
-    :param Lz: z-dimension of the FM block.
-    :param Q: up-down or down-up wall parameter (either 1 or -1).
-    :param Hr: Rashba field [A/m].
-    :param moving_field: whether the anisotropy field is perpendicular or parallel
-    :param relax_dw: whether to relax the domain width. See DWRelax class.
-    For classical formulation see:
-    Current-driven dynamics of chiral ferromagnetic domain walls, Emori et al, 2013
-    """
-    H: VectorObj
-    alpha: float
-    Ms: float
-    thickness: float
-    SHE_angle: float
-    D: float
-    Ku: float  # The out-of-plane anisotropy constant
-    Kp: float  # The in-plane anisotropy constant
-    A: float = 1e-11  # J/m
-    beta: float = 1
-    p: float = 1
-    V0_pin: float = 1.65e-20
-    V0_edge: float = 0
-    pinning: float = 30e-9
-    Lx: float = 120e-9
-    Ly: float = 120e-9
-    Lz: float = 3e-9
-    Q: int = 1
-    Hr: float = 0
-    moving_field: Literal["perpendicular", "inplane"] = "perpendicular"
-    relax_dw: DWRelax = DWRelax.STATIC
-    dw0: float = field(init=False)
-
-    def __post_init__(self):
-        # in post init we already have p
-        self.bj = bohr_magneton * self.p / (echarge * self.Ms)
-        self.je_driver = lambda t: 0
-        denom = (2 * self.Ms * mu0 * echarge * self.thickness)
-        self.Hshe = hbar * self.SHE_angle / denom
-        self.hx, self.hy, self.hz = self.H.get_cartesian()
-        self.dw0 = self.get_unrelaxed_domain_width()
-
-        if self.moving_field == "perpendicular":
-            self.Hk = self.get_perpendicular_anisotropy_field()
-        elif self.moving_field == "inplane":
-            self.Hk = self.get_inplane_anisotropy_field()
-
-    def get_unrelaxed_domain_width(self, effective=False):
-        """Domain width is based off the effective perpendicular anisotropy.
-        We reduce the perpendicular anisotropy by demagnetising field"""
-        # Keff = self.Ku - 0.5*mu0*(self.Ms)**2
-        Keff = self.Ku - (0.5 * mu0) * (self.Ms**2) if effective else self.Ku
-        return math.sqrt(self.A / Keff)
-
-    def set_current_function(self, driver: Callable):
-        """
-        :param driver: A function of time that returns the current density
-        """
-        self.je_driver = driver
-
-    def get_Hdmi(self, domain_width):
-        """Returns the DMI field"""
-        return self.D / (mu0 * self.Ms * domain_width)
-
-    def get_perpendicular_anisotropy_field(self):
-        """Returns the perpeanisotropy field"""
-        return 2 * self.Ku / (mu0 * self.Ms)
-
-    def get_inplane_anisotropy_field(self):
-        """Returns the in-plane anisotropy field"""
-        return 2 * self.Kp / (mu0 * self.Ms)
-
-
-@dataclass
-class MultilayerWallDynamics:
-    layers: List[DomainWallDynamics]
-    J: float = 0
-    vector_size: int = 3  # 3 for X, phi, delta
-
-    def __post_init__(self):
-        if len(self.layers) > 2:
-            raise ValueError("Wall dynamics supported up to 2 layers")
-
-    def multilayer_dw_llg(self, t, vec):
-        """Solve the Thiaville llg equation for LLG.
-        :param t: current simulation time.
-        :param vec: contains [X, phi, delta], current DW position, its angle and domain width.
-        :returns (dXdt, dPhidt, dDeltad): velocity and change of angle and domain width.
-        """
-        # vector is X1, phi1, Delta1, X2, phi2, Delta2...
-        layer: DomainWallDynamics
-        new_vec = []
-        for i, layer in enumerate(self.layers):
-            je_at_t = layer.je_driver(t=t)
-            reduced_alpha = (1. + layer.alpha**2)
-            lx = vec[self.vector_size * i]
-            lphi = vec[(self.vector_size * i) + 1]
-            ldomain_width = vec[(self.vector_size * i) + 2]
-            if len(self.layers) == 1:
-                Jterm = 0
-            else:
-                Jterm = 2 * self.J / (layer.Ms * mu0 * layer.thickness)
-                otherphi = vec[self.vector_size * (i - 1) + 1]
-                Jterm *= math.sin(lphi - otherphi)
-
-            hdmi = layer.get_Hdmi(ldomain_width)
-            dXdt, dPhidt, dDeltadt = compute_dynamics(
-                X=lx,
-                phi=lphi,
-                delta=ldomain_width,
-                Q=layer.Q,
-                hx=layer.hx,
-                hy=layer.hy,
-                hz=layer.hz,
-                alpha=layer.alpha,
-                bj=layer.bj * je_at_t,
-                hr=layer.Hr,
-                beta=layer.beta,
-                hshe=layer.Hshe * je_at_t,
-                hdmi=hdmi,
-                hk=layer.Hk,
-                Ms=layer.Ms,
-                IECterm=Jterm,
-                V0_pin=layer.V0_pin,
-                V0_edge=layer.V0_edge,
-                pinning=layer.pinning,
-                Lx=layer.Lx,
-                Ly=layer.Ly,
-                Lz=layer.Lz,
-                A=layer.A,
-                Ku=layer.Ku,
-                Kp=layer.Kp,
-                thickness=layer.thickness)
-            dXdt = dXdt / reduced_alpha
-            dPhidt = dPhidt / reduced_alpha
-            if layer.relax_dw != DWRelax.DYNAMIC:
-                dDeltadt = 0  # no relaxation in the ODE
-            new_vec.extend([dXdt, dPhidt, dDeltadt])
-        return new_vec
-
-    def run(self,
-            sim_time: float,
-            starting_conditions: List[float],
-            max_step: float = 1e-10):
-        """Run simulation of DW dynamics.
-        :param sim_time: total simulation time (simulation units).
-        :param starting_conditions: starting position and angle of the DW.
-        :param max_step: maximum allowed step of the RK45 method.
-        """
-        integrator = RK45(fun=self.multilayer_dw_llg,
-                          t0=0.,
-                          first_step=1e-16,
-                          max_step=max_step,
-                          y0=starting_conditions,
-                          rtol=1e-12,
-                          t_bound=sim_time)
-        result = defaultdict(list)
-        while True:
-            integrator.step()
-            if integrator.status == 'failed':
-                print("Failed to converge")
-                break
-            layer_vecs = integrator.y
-            result['t'].append(integrator.t)
-            for i, layer in enumerate(self.layers):
-                x, phi, dw = layer_vecs[self.vector_size * i], layer_vecs[
-                    self.vector_size * i +
-                    1], layer_vecs[self.vector_size * i + 2]
-                # static relaxation Thiaville
-                if layer.relax_dw == DWRelax.STATIC:
-                    ratio = layer.Kp / layer.Ku
-                    dw = layer.dw0 / math.sqrt(1 + ratio * math.sin(phi)**2)
-                vel = (x - integrator.y_old[2 * i]) / integrator.step_size
-                result[f'dw_{i}'].append(dw)
-                result[f'v_{i}'].append(vel)
-                result[f'x_{i}'].append(x)
-                result[f'phi_{i}'].append(phi)
-                result[f'je_{i}'].append(layer.je_driver(t=integrator.t))
-            if integrator.status == 'finished':
-                break
-
-        return result
+import math
+from collections import defaultdict
+from dataclasses import dataclass, field
+from typing import Callable, List, Literal
+
+from numba import njit
+from scipy.integrate import RK45
+
+from ..utils import bohr_magneton, echarge, gyromagnetic_ratio, hbar, mu0
+from ..utils.general import VectorObj
+
+gyro = gyromagnetic_ratio
+pi2 = math.pi / 2.
+
+
+class DW:
+    """Initial conditions for the phi of DW equation."""
+    NEEL_RIGHT = 0
+    NEEL_LEFT = math.pi
+    BLOCH_UP = math.pi / 2.
+    BLOCH_DOWN = 3. * math.pi / 2.
+
+
+class DWRelax:
+    NO_RELAX = 0
+    STATIC = 1
+    DYNAMIC = 2
+
+
+@njit
+def get_pinning_field(X, Ms, pinning, Ly, Lz, V0_pin):
+    arg = X * math.pi / pinning
+    dVdx = 2 * math.pi * V0_pin * math.sin(arg) * math.cos(arg)
+    denom = 2 * mu0 * Ms * Lz * Ly
+    return -(1. / denom) * dVdx
+
+
+@njit
+def get_edge_field(X, Lx, V0_edge):
+    c = Lx / 2
+    arg = (X - (Lx / 2)) / c
+    p = 6
+    return -p * V0_edge * (math.sinh(arg) * math.cosh(arg)**(p - 1) / c)
+
+
+@njit
+def get_field_contribution(X, phi, hx, hy, hz, alpha, dw, Ms, V0_pin, pinning,
+                           Ly, Lz):
+
+    pinning = get_pinning_field(X,
+                                Ms=Ms,
+                                pinning=pinning,
+                                Ly=Ly,
+                                Lz=Lz,
+                                V0_pin=V0_pin)
+    dxdt = alpha * gyro * dw * (hz + pinning) + gyro * dw * pi2 * (
+        -hy * math.cos(phi) + hx * math.sin(phi))
+    dphidt = gyro * (hz + pinning) + alpha * gyro * pi2 * (hy * math.cos(phi) -
+                                                           hx * math.sin(phi))
+    return dxdt, dphidt
+
+
+@njit
+def compute_gamma_a(X, phi, Q, dw, hk, hx, hy, hdmi, bj, IECterm):
+    pi2 = math.pi / 2.
+    fact_gamma = -0.5 * hk * math.sin(
+        2 * phi) - pi2 * hy * math.cos(phi) + pi2 * hx * math.sin(
+            phi) + Q * pi2 * hdmi * math.sin(phi) + IECterm
+    fact_stt = bj / dw
+    return gyro * fact_gamma + fact_stt
+
+
+@njit
+def compute_gamma_b(X, phi, Q, dw, hshe, hz, hr, beta, bj, Ms, Lx, Ly, Lz,
+                    V0_pin, V0_edge, pinning):
+    pi2 = math.pi / 2
+    hp = get_pinning_field(X,
+                           Ms=Ms,
+                           pinning=pinning,
+                           Ly=Ly,
+                           Lz=Lz,
+                           V0_pin=V0_pin)
+    he = get_edge_field(X, Lx, V0_edge)
+    fact_gamma = Q * (he + hz + hp + pi2 * hshe *
+                      math.cos(phi)) - beta * pi2 * hr * math.cos(phi)
+    fact_stt = beta * bj / dw
+    return gyro * fact_gamma + fact_stt
+
+
+@njit
+def compute_dynamics(X, phi, delta, alpha, Q, hx, hy, hz, hk, hdmi, hr, hshe,
+                     beta, bj, Ms, Lx, Ly, Lz, V0_pin, V0_edge, pinning,
+                     IECterm, thickness, A, Ku, Kp):
+    gamma_a = compute_gamma_a(X, phi, Q, delta, hk, hx, hy, hdmi, bj, IECterm)
+    gamma_b = compute_gamma_b(X, phi, Q, delta, hshe, hz, hr, beta, bj, Ms, Lx,
+                              Ly, Lz, V0_pin, V0_edge, pinning)
+    dXdt = delta * (gamma_a + alpha * gamma_b)
+    dPhidt = -alpha * gamma_a + gamma_b
+    pref = gyro / (alpha * mu0 * Ms * thickness)
+    # domain width relaxation from Thiaville
+    dDeltadt = pref * (A / delta - delta * (Ku + Kp * math.sin(phi)**2))
+    # dDeltadt  = 0
+    return dXdt, dPhidt, dDeltadt
+
+
+@dataclass
+class DomainWallDynamics:
+    """Domain Wall dynamics class.
+    :param H: applied magnetic field vector.
+    :param alpha: Gilbert damping.
+    :param Ms: magnetisation saturation [A/m].
+    :param thickness: thickness of the FM material.
+    :param SHE_angle: Spin Hall Effect angle.
+    :param D: DMI constant.
+    :param Ku: perpendicular anisotropy constant.
+    :param Kp: inplane anisotropy constant.
+    :param A: exchange constant.
+    :param beta: STT beta parameter.
+    :param p: STT polarisation efficiency.
+    :param V0_pin: pinning voltage constant.
+    :param V0_edge: edge voltage constant.
+    :param pinning: the pinning period.
+    :param Lx: z-dimension of the FM block.
+    :param Ly: y-dimension of the FM block.
+    :param Lz: z-dimension of the FM block.
+    :param Q: up-down or down-up wall parameter (either 1 or -1).
+    :param Hr: Rashba field [A/m].
+    :param moving_field: whether the anisotropy field is perpendicular or parallel
+    :param relax_dw: whether to relax the domain width. See DWRelax class.
+    For classical formulation see:
+    Current-driven dynamics of chiral ferromagnetic domain walls, Emori et al, 2013
+    """
+    H: VectorObj
+    alpha: float
+    Ms: float
+    thickness: float
+    SHE_angle: float
+    D: float
+    Ku: float  # The out-of-plane anisotropy constant
+    Kp: float  # The in-plane anisotropy constant
+    A: float = 1e-11  # J/m
+    beta: float = 1
+    p: float = 1
+    V0_pin: float = 1.65e-20
+    V0_edge: float = 0
+    pinning: float = 30e-9
+    Lx: float = 120e-9
+    Ly: float = 120e-9
+    Lz: float = 3e-9
+    Q: int = 1
+    Hr: float = 0
+    moving_field: Literal["perpendicular", "inplane"] = "perpendicular"
+    relax_dw: DWRelax = DWRelax.STATIC
+    dw0: float = field(init=False)
+
+    def __post_init__(self):
+        # in post init we already have p
+        self.bj = bohr_magneton * self.p / (echarge * self.Ms)
+        self.je_driver = lambda t: 0
+        denom = (2 * self.Ms * mu0 * echarge * self.thickness)
+        self.Hshe = hbar * self.SHE_angle / denom
+        self.hx, self.hy, self.hz = self.H.get_cartesian()
+        self.dw0 = self.get_unrelaxed_domain_width()
+
+        if self.moving_field == "perpendicular":
+            self.Hk = self.get_perpendicular_anisotropy_field()
+        elif self.moving_field == "inplane":
+            self.Hk = self.get_inplane_anisotropy_field()
+
+    def get_unrelaxed_domain_width(self, effective=False):
+        """Domain width is based off the effective perpendicular anisotropy.
+        We reduce the perpendicular anisotropy by demagnetising field"""
+        # Keff = self.Ku - 0.5*mu0*(self.Ms)**2
+        Keff = self.Ku - (0.5 * mu0) * (self.Ms**2) if effective else self.Ku
+        return math.sqrt(self.A / Keff)
+
+    def set_current_function(self, driver: Callable):
+        """
+        :param driver: A function of time that returns the current density
+        """
+        self.je_driver = driver
+
+    def get_Hdmi(self, domain_width):
+        """Returns the DMI field"""
+        return self.D / (mu0 * self.Ms * domain_width)
+
+    def get_perpendicular_anisotropy_field(self):
+        """Returns the perpeanisotropy field"""
+        return 2 * self.Ku / (mu0 * self.Ms)
+
+    def get_inplane_anisotropy_field(self):
+        """Returns the in-plane anisotropy field"""
+        return 2 * self.Kp / (mu0 * self.Ms)
+
+
+@dataclass
+class MultilayerWallDynamics:
+    layers: List[DomainWallDynamics]
+    J: float = 0
+    vector_size: int = 3  # 3 for X, phi, delta
+
+    def __post_init__(self):
+        if len(self.layers) > 2:
+            raise ValueError("Wall dynamics supported up to 2 layers")
+
+    def multilayer_dw_llg(self, t, vec):
+        """Solve the Thiaville llg equation for LLG.
+        :param t: current simulation time.
+        :param vec: contains [X, phi, delta], current DW position, its angle and domain width.
+        :returns (dXdt, dPhidt, dDeltad): velocity and change of angle and domain width.
+        """
+        # vector is X1, phi1, Delta1, X2, phi2, Delta2...
+        layer: DomainWallDynamics
+        new_vec = []
+        for i, layer in enumerate(self.layers):
+            je_at_t = layer.je_driver(t=t)
+            reduced_alpha = (1. + layer.alpha**2)
+            lx = vec[self.vector_size * i]
+            lphi = vec[(self.vector_size * i) + 1]
+            ldomain_width = vec[(self.vector_size * i) + 2]
+            if len(self.layers) == 1:
+                Jterm = 0
+            else:
+                Jterm = 2 * self.J / (layer.Ms * mu0 * layer.thickness)
+                otherphi = vec[self.vector_size * (i - 1) + 1]
+                Jterm *= math.sin(lphi - otherphi)
+
+            hdmi = layer.get_Hdmi(ldomain_width)
+            dXdt, dPhidt, dDeltadt = compute_dynamics(
+                X=lx,
+                phi=lphi,
+                delta=ldomain_width,
+                Q=layer.Q,
+                hx=layer.hx,
+                hy=layer.hy,
+                hz=layer.hz,
+                alpha=layer.alpha,
+                bj=layer.bj * je_at_t,
+                hr=layer.Hr,
+                beta=layer.beta,
+                hshe=layer.Hshe * je_at_t,
+                hdmi=hdmi,
+                hk=layer.Hk,
+                Ms=layer.Ms,
+                IECterm=Jterm,
+                V0_pin=layer.V0_pin,
+                V0_edge=layer.V0_edge,
+                pinning=layer.pinning,
+                Lx=layer.Lx,
+                Ly=layer.Ly,
+                Lz=layer.Lz,
+                A=layer.A,
+                Ku=layer.Ku,
+                Kp=layer.Kp,
+                thickness=layer.thickness)
+            dXdt = dXdt / reduced_alpha
+            dPhidt = dPhidt / reduced_alpha
+            if layer.relax_dw != DWRelax.DYNAMIC:
+                dDeltadt = 0  # no relaxation in the ODE
+            new_vec.extend([dXdt, dPhidt, dDeltadt])
+        return new_vec
+
+    def run(self,
+            sim_time: float,
+            starting_conditions: List[float],
+            max_step: float = 1e-10):
+        """Run simulation of DW dynamics.
+        :param sim_time: total simulation time (simulation units).
+        :param starting_conditions: starting position and angle of the DW.
+        :param max_step: maximum allowed step of the RK45 method.
+        """
+        integrator = RK45(fun=self.multilayer_dw_llg,
+                          t0=0.,
+                          first_step=1e-16,
+                          max_step=max_step,
+                          y0=starting_conditions,
+                          rtol=1e-12,
+                          t_bound=sim_time)
+        result = defaultdict(list)
+        while True:
+            integrator.step()
+            if integrator.status == 'failed':
+                print("Failed to converge")
+                break
+            layer_vecs = integrator.y
+            result['t'].append(integrator.t)
+            for i, layer in enumerate(self.layers):
+                x, phi, dw = layer_vecs[self.vector_size * i], layer_vecs[
+                    self.vector_size * i +
+                    1], layer_vecs[self.vector_size * i + 2]
+                # static relaxation Thiaville
+                if layer.relax_dw == DWRelax.STATIC:
+                    ratio = layer.Kp / layer.Ku
+                    dw = layer.dw0 / math.sqrt(1 + ratio * math.sin(phi)**2)
+                vel = (x - integrator.y_old[2 * i]) / integrator.step_size
+                result[f'dw_{i}'].append(dw)
+                result[f'v_{i}'].append(vel)
+                result[f'x_{i}'].append(x)
+                result[f'phi_{i}'].append(phi)
+                result[f'je_{i}'].append(layer.je_driver(t=integrator.t))
+            if integrator.status == 'finished':
+                break
+
+        return result
```

## cmtj/models/drivers.py

 * *Ordering differences only*

```diff
@@ -1,22 +1,22 @@
-import math
-
-from numba import njit
-
-
-def constant_driver(t, amp):
-    return amp
-
-
-@njit
-def sine_driver(t, amp, freq, phase):
-    return amp * math.sin(freq * t + phase)
-
-
-@njit
-def decay_driver(t, amp, tau):
-    return amp * math.exp(-t / tau)
-
-
-@njit
-def gaussian_driver(t, amp, sigma):
-    return amp * math.exp(-t**2 / sigma**2)
+import math
+
+from numba import njit
+
+
+def constant_driver(t, amp):
+    return amp
+
+
+@njit
+def sine_driver(t, amp, freq, phase):
+    return amp * math.sin(freq * t + phase)
+
+
+@njit
+def decay_driver(t, amp, tau):
+    return amp * math.exp(-t / tau)
+
+
+@njit
+def gaussian_driver(t, amp, sigma):
+    return amp * math.exp(-t**2 / sigma**2)
```

## cmtj/models/ensemble.py

 * *Ordering differences only*

```diff
@@ -1,51 +1,51 @@
-import numpy as np
-
-
-def meinert_model(phi, V1, V2, phase_offset, offset):
-    """
-    Fits to Meinert model.
-    :param phi: angle in degrees, given parameter
-    :param V1: (Hfl/Hext), fitting parameter
-    :param V2: (Va*Hdl/Heff), fitting parameter
-    :param phase_offset: phase offset in degrees, fitting parameter
-    :param offset: offset in V, fitting parameter
-    V2omega = (Acos(2(phi - phase_offset)) - B)*cos(phi - phase_offset) + offset
-    """
-    deg_rad = np.deg2rad(phi - phase_offset)
-    return (V1 * np.cos(2 * (deg_rad)) - V2) * np.cos(deg_rad) + offset
-
-
-def symmetric_lorentz(H, dH, Hr, Vs):
-    """
-    Symmetric Lorentzian function.
-    :param H: applied field in A/m
-    :param dH: half width at half maximum in A/m
-    :param Hr: resonance field in A/m
-    """
-    dH2 = dH**2
-    return Vs * dH2 / ((H - Hr)**2 + dH2)
-
-
-def antisymmetric_lorentz(H, dH, Hr, Vas):
-    """
-    Antisymmetric Lorentzian function.
-    :param H: applied field in A/m
-    :param dH: half width at half maximum in A/m
-    :param Hr: resonance field in A/m
-    """
-    dH2 = dH**2
-    dHr = H - Hr
-    return Vas * dH * dHr / (np.power(dHr, 2) + dH2)
-
-
-def mixed_lorentz(H, dH, Hr, Va, Vas):
-    """
-    Mixed Lorentzian function.
-    :param H: applied field in A/m
-    :param dH: half width at half maximum in A/m
-    :param Hr: resonance field in A/m
-    :param Va: amplitude of symmetric Lorentzian
-    :param Vas: amplitude of antisymmetric Lorentzian
-    """
-    return symmetric_lorentz(H, dH, Hr, Va) + antisymmetric_lorentz(
-        H, dH, Hr, Vas)
+import numpy as np
+
+
+def meinert_model(phi, V1, V2, phase_offset, offset):
+    """
+    Fits to Meinert model.
+    :param phi: angle in degrees, given parameter
+    :param V1: (Hfl/Hext), fitting parameter
+    :param V2: (Va*Hdl/Heff), fitting parameter
+    :param phase_offset: phase offset in degrees, fitting parameter
+    :param offset: offset in V, fitting parameter
+    V2omega = (Acos(2(phi - phase_offset)) - B)*cos(phi - phase_offset) + offset
+    """
+    deg_rad = np.deg2rad(phi - phase_offset)
+    return (V1 * np.cos(2 * (deg_rad)) - V2) * np.cos(deg_rad) + offset
+
+
+def symmetric_lorentz(H, dH, Hr, Vs):
+    """
+    Symmetric Lorentzian function.
+    :param H: applied field in A/m
+    :param dH: half width at half maximum in A/m
+    :param Hr: resonance field in A/m
+    """
+    dH2 = dH**2
+    return Vs * dH2 / ((H - Hr)**2 + dH2)
+
+
+def antisymmetric_lorentz(H, dH, Hr, Vas):
+    """
+    Antisymmetric Lorentzian function.
+    :param H: applied field in A/m
+    :param dH: half width at half maximum in A/m
+    :param Hr: resonance field in A/m
+    """
+    dH2 = dH**2
+    dHr = H - Hr
+    return Vas * dH * dHr / (np.power(dHr, 2) + dH2)
+
+
+def mixed_lorentz(H, dH, Hr, Va, Vas):
+    """
+    Mixed Lorentzian function.
+    :param H: applied field in A/m
+    :param dH: half width at half maximum in A/m
+    :param Hr: resonance field in A/m
+    :param Va: amplitude of symmetric Lorentzian
+    :param Vas: amplitude of antisymmetric Lorentzian
+    """
+    return symmetric_lorentz(H, dH, Hr, Va) + antisymmetric_lorentz(
+        H, dH, Hr, Vas)
```

## cmtj/models/general_sb.py

```diff
@@ -1,676 +1,747 @@
-import math
-import time
-import warnings
-from dataclasses import dataclass
-from functools import lru_cache
-from typing import Iterable, List, Tuple, Union
-
-import numpy as np
-import sympy as sym
-from numba import njit
-from tqdm import tqdm
-
-from ..utils import VectorObj, gamma, gamma_rad, mu0, perturb_position
-from ..utils.solvers import RootFinder
-
-EPS = np.finfo('float64').resolution
-
-
-def real_deocrator(fn):
-    """Using numpy real cast is way faster than sympy."""
-
-    def wrap_fn(*args):
-        return np.real(fn(*args))
-
-    return wrap_fn
-
-
-@njit
-def fast_norm(x):  # sourcery skip: for-index-underscore, sum-comprehension
-    """Fast norm function for 1D arrays."""
-    sum_ = 0
-    for x_ in x:
-        sum_ += x_**2
-    return math.sqrt(sum_)
-
-
-@lru_cache
-def general_hessian_functional(N: int):
-    """Create a generalised hessian functional for N layers.
-    :param N: number of layers.
-    ! WARNING: remember Ms Symbols must match!!!
-    """
-    all_symbols = []
-    for i in range(N):
-        # indx_i = str(i + 1) # for display purposes
-        indx_i = str(i)
-        all_symbols.extend(
-            (sym.Symbol(r"\theta_" + indx_i), sym.Symbol(r"\phi_" + indx_i)))
-    energy_functional_expr = sym.Function("E")(*all_symbols)
-    return get_hessian_from_energy_expr(
-        N, energy_functional_expr), energy_functional_expr
-
-
-@lru_cache
-def get_hessian_from_energy_expr(N: int, energy_functional_expr: sym.Expr):
-    """
-    Computes the Hessian matrix of the energy functional expression with respect to the spin angles and phases.
-
-    :param N (int): The number of spins.
-    :param energy_functional_expr (sympy.Expr): The energy functional expression.
-
-    returns: sympy.Matrix: The Hessian matrix of the energy functional expression.
-    """
-    hessian = [[0 for _ in range(2 * N)] for _ in range(2 * N)]
-    for i in range(N):
-        # indx_i = str(i + 1) # for display purposes
-        indx_i = str(i)
-        # z = sym.Symbol("Z")
-        # these here must match the Ms symbols!
-        z = sym.Symbol(
-            r"\omega") * sym.Symbol(r"M_{" + indx_i + "}") * sym.sin(
-                sym.Symbol(r"\theta_" + indx_i)) * sym.Symbol(r"t_{" + indx_i +
-                                                              "}")
-        for j in range(i, N):
-            # indx_j = str(j + 1) # for display purposes
-            indx_j = str(j)
-            s1 = sym.Symbol(r"\theta_" + indx_i)
-            s2 = sym.Symbol(r"\theta_" + indx_j)
-
-            expr = sym.diff(energy_functional_expr, s1, s2)
-            hessian[2 * i][2 * j] = expr
-            hessian[2 * j][2 * i] = expr
-            s1 = sym.Symbol(r"\phi_" + indx_i)
-            s2 = sym.Symbol(r"\phi_" + indx_j)
-            expr = sym.diff(energy_functional_expr, s1, s2)
-            hessian[2 * i + 1][2 * j + 1] = expr
-            hessian[2 * j + 1][2 * i + 1] = expr
-
-            s1 = sym.Symbol(r"\theta_" + indx_i)
-            s2 = sym.Symbol(r"\phi_" + indx_j)
-            expr = sym.diff(energy_functional_expr, s1, s2)
-            if i == j:
-                hessian[2 * i + 1][2 * j] = expr + sym.I * z
-                hessian[2 * i][2 * j + 1] = expr - sym.I * z
-            else:
-                hessian[2 * i][2 * j + 1] = expr
-                hessian[2 * j + 1][2 * i] = expr
-
-                s1 = sym.Symbol(r"\phi_" + indx_i)
-                s2 = sym.Symbol(r"\theta_" + indx_j)
-                expr = sym.diff(energy_functional_expr, s1, s2)
-                hessian[2 * i + 1][2 * j] = expr
-                hessian[2 * j][2 * i + 1] = expr
-    return sym.Matrix(hessian)
-
-
-@lru_cache()
-def solve_for_determinant(N: int):
-    """Solve for the determinant of the hessian functional.
-    :param N: number of layers.
-    """
-    hessian, energy_functional_expr = general_hessian_functional(N)
-    if N == 1:
-        return hessian.det(), energy_functional_expr
-
-    # LU decomposition
-    _, U, _ = hessian.LUdecomposition()
-    return U.det(), energy_functional_expr
-
-
-@lru_cache
-def find_analytical_roots(N: int):
-    det_expr, energy_functional_expr = solve_for_determinant(N)
-    solutions = sym.solve(sym.simplify(det_expr), sym.Symbol(r"\omega"))
-    return solutions, energy_functional_expr
-
-
-def get_all_second_derivatives(energy_functional_expr,
-                               energy_expression,
-                               subs={}):
-    """Get all second derivatives of the energy expression.
-    :param energy_functional_expr: symbolic energy_functional expression
-    :param energy_expression: symbolic energy expression (from solver)
-    :param subs: substitutions to be made."""
-    second_derivatives = subs
-    symbols = energy_expression.free_symbols
-    for i, s1 in enumerate(symbols):
-        for j, s2 in enumerate(symbols):
-            if i <= j:
-                org_diff = sym.diff(energy_functional_expr, s1, s2)
-                if subs is not None:
-                    second_derivatives[org_diff] = sym.diff(
-                        energy_expression, s1, s2).subs(subs)
-                else:
-                    second_derivatives[org_diff] = sym.diff(
-                        energy_expression, s1, s2)
-    return second_derivatives
-
-
-@dataclass
-class LayerSB:
-    """Basic Layer for Smit-Beljers model.
-    :param thickness: thickness of the FM layer (effective).
-    :param Kv: volumetric (in-plane) anisotropy. Only phi and mag count [J/m^3].
-    :param Ks: surface anisotropy (out-of plane, or perpendicular) value [J/m^3].
-    :param Ms: magnetisation saturation value in [A/m].
-    """
-    _id: int
-    thickness: float
-    Kv: VectorObj
-    Ks: float
-    Ms: float
-
-    def __post_init__(self):
-        if self._id > 9:
-            raise ValueError("Only up to 10 layers supported.")
-        self.theta = sym.Symbol(r"\theta_" + str(self._id))
-        self.phi = sym.Symbol(r"\phi_" + str(self._id))
-        self.m = sym.ImmutableMatrix([
-            sym.sin(self.theta) * sym.cos(self.phi),
-            sym.sin(self.theta) * sym.sin(self.phi),
-            sym.cos(self.theta)
-        ])
-
-    def get_coord_sym(self):
-        """Returns the symbolic coordinates of the layer."""
-        return self.theta, self.phi
-
-    def get_m_sym(self):
-        """Returns the magnetisation vector."""
-        return self.m
-
-    @lru_cache(3)
-    def symbolic_layer_energy(self, H: sym.ImmutableMatrix, J1top: float,
-                              J1bottom: float, J2top: float, J2bottom: float,
-                              top_layer: "LayerSB", down_layer: "LayerSB"):
-        """Returns the symbolic expression for the energy of the layer.
-        Coupling contribution comes only from the bottom layer (top-down crawl)"""
-        m = self.get_m_sym()
-
-        eng_non_interaction = self.no_iec_symbolic_layer_energy(H)
-
-        top_iec_energy = 0
-        bottom_iec_energy = 0
-
-        if top_layer is not None:
-            other_m = top_layer.get_m_sym()
-            top_iec_energy = -(J1top / self.thickness) * m.dot(other_m) - (
-                J2top / self.thickness) * m.dot(other_m)**2
-        if down_layer is not None:
-            other_m = down_layer.get_m_sym()
-            bottom_iec_energy = -(J1bottom / self.thickness) * m.dot(
-                other_m) - (J2bottom / self.thickness) * m.dot(other_m)**2
-        return eng_non_interaction + top_iec_energy + bottom_iec_energy
-
-    def no_iec_symbolic_layer_energy(self, H: sym.ImmutableMatrix):
-        """Returns the symbolic expression for the energy of the layer.
-        Coupling contribution comes only from the bottom layer (top-down crawl)"""
-        m = self.get_m_sym()
-
-        alpha = sym.ImmutableMatrix(
-            [sym.cos(self.Kv.phi),
-             sym.sin(self.Kv.phi), 0])
-
-        field_energy = -mu0 * self.Ms * m.dot(H)
-        surface_anistropy = (-self.Ks +
-                             (1. / 2.) * mu0 * self.Ms**2) * (m[-1]**2)
-        volume_anisotropy = -self.Kv.mag * (m.dot(alpha)**2)
-        return (field_energy + surface_anistropy + volume_anisotropy)
-
-    def sb_correction(self):
-        omega = sym.Symbol(r'\omega')
-        return (omega / gamma) * self.Ms * sym.sin(self.theta) * self.thickness
-
-    def __hash__(self) -> int:
-        return hash(str(self))
-
-    def __eq__(self, __value: "LayerSB") -> bool:
-        return self._id == __value._id and self.thickness == __value.thickness and self.Kv == __value.Kv and self.Ks == __value.Ks and self.Ms == __value.Ms
-
-
-@dataclass
-class LayerDynamic(LayerSB):
-    alpha: float
-
-    def rhs_llg(self, H: sym.Matrix, J1top: float, J1bottom: float,
-                J2top: float, J2bottom: float, top_layer: "LayerSB",
-                down_layer: "LayerSB"):
-        """Returns the symbolic expression for the RHS of the spherical LLG equation.
-        Coupling contribution comes only from the bottom layer (top-down crawl)"""
-        U = self.symbolic_layer_energy(H,
-                                       J1top=J1top,
-                                       J1bottom=J1bottom,
-                                       J2top=J2top,
-                                       J2bottom=J2bottom,
-                                       top_layer=top_layer,
-                                       down_layer=down_layer)
-        # sum all components
-        prefac = gamma_rad / (1. + self.alpha)**2
-        inv_sin = 1. / (sym.sin(self.theta) + EPS)
-        dUdtheta = sym.diff(U, self.theta)
-        dUdphi = sym.diff(U, self.phi)
-
-        dtheta = (-inv_sin * dUdphi - self.alpha * dUdtheta)
-        dphi = (inv_sin * dUdtheta - self.alpha * dUdphi * (inv_sin)**2)
-        return prefac * sym.ImmutableMatrix([dtheta, dphi]) / self.Ms
-
-    def __eq__(self, __value: "LayerDynamic") -> bool:
-        return super().__eq__(__value) and self.alpha == __value.alpha
-
-    def __hash__(self) -> int:
-        return super().__hash__()
-
-
-@dataclass
-class Solver:
-    layers: List[Union[LayerSB, LayerDynamic]]
-    J1: List[float]
-    J2: List[float]
-    H: VectorObj = None
-
-    def __post_init__(self):
-        if len(self.layers) != len(self.J1) + 1:
-            raise ValueError("Number of layers must be 1 more than J1.")
-        if len(self.layers) != len(self.J2) + 1:
-            raise ValueError("Number of layers must be 1 more than J2.")
-
-        id_sets = {layer._id for layer in self.layers}
-        ideal_set = set(range(len(self.layers)))
-        if id_sets != ideal_set:
-            raise ValueError("Layer ids must be 0, 1, 2, ... and unique."
-                             "Ids must start from 0.")
-
-    def get_layer_references(self, layer_indx, interaction_constant):
-        """Returns the references to the layers above and below the layer
-        with index layer_indx."""
-        if len(self.layers) == 1:
-            return None, None, 0, 0
-        if layer_indx == 0:
-            return None, self.layers[layer_indx +
-                                     1], 0, interaction_constant[0]
-        elif layer_indx == len(self.layers) - 1:
-            return self.layers[layer_indx -
-                               1], None, interaction_constant[-1], 0
-        return self.layers[layer_indx - 1], self.layers[
-            layer_indx +
-            1], interaction_constant[layer_indx -
-                                     1], interaction_constant[layer_indx]
-
-    def compose_llg_jacobian(self, H: VectorObj):
-        """Create a symbolic jacobian of the LLG equation in spherical coordinates."""
-        # has order theta0, phi0, theta1, phi1, ...
-        if isinstance(H, VectorObj):
-            H = sym.ImmutableMatrix(H.get_cartesian())
-
-        symbols, fns = [], []
-        for i, layer in enumerate(self.layers):
-            symbols.extend((layer.theta, layer.phi))
-            top_layer, bottom_layer, Jtop, Jbottom = self.get_layer_references(
-                i, self.J1)
-            _, _, J2top, J2bottom = self.get_layer_references(i, self.J2)
-            fns.append(
-                layer.rhs_llg(H, Jtop, Jbottom, J2top, J2bottom, top_layer,
-                              bottom_layer))
-        jac = sym.ImmutableMatrix(fns).jacobian(symbols)
-        return jac, symbols
-
-    def create_energy(self,
-                      H: Union[VectorObj, sym.ImmutableMatrix] = None,
-                      volumetric: bool = False):
-        """Creates the symbolic energy expression.
-
-        Due to problematic nature of coupling, there is an issue of
-        computing each layer's FMR in the presence of IEC.
-        If volumetric = True then we use the thickness of the layer to multiply the
-        energy and hence avoid having to divide J by the thickness of a layer.
-        If volumetric = False the J constant is divided by weighted thickness
-        and included in every layer's energy, correcting FMR automatically.
-        """
-        if H is None:
-            h = self.H.get_cartesian()
-            H = sym.ImmutableMatrix(h)
-        energy = 0
-        if volumetric:
-            # volumetric energy -- DO NOT USE IN GENERAL
-            for i, layer in enumerate(self.layers):
-                top_layer, bottom_layer, Jtop, Jbottom = self.get_layer_references(
-                    i, self.J1)
-                _, _, J2top, J2bottom = self.get_layer_references(i, self.J2)
-                ratio_top, ratio_bottom = 0, 0
-                if top_layer:
-                    ratio_top = top_layer.thickness / (top_layer.thickness +
-                                                       layer.thickness)
-                if bottom_layer:
-                    ratio_bottom = bottom_layer.thickness / (
-                        layer.thickness + bottom_layer.thickness)
-                energy += layer.symbolic_layer_energy(H, Jtop * ratio_top,
-                                                      Jbottom * ratio_bottom,
-                                                      J2top, J2bottom,
-                                                      top_layer, bottom_layer)
-        else:
-            # surface energy for correct angular gradient
-            for layer in self.layers:
-                # to avoid dividing J by thickness
-                energy += layer.no_iec_symbolic_layer_energy(
-                    H) * layer.thickness
-
-            for i in range(len(self.layers) - 1):
-                l1m = self.layers[i].get_m_sym()
-                l2m = self.layers[i + 1].get_m_sym()
-                ldot = (l1m.dot(l2m))
-                energy -= self.J1[i] * ldot
-                energy -= self.J2[i] * (ldot)**2
-
-        return energy
-
-    def create_energy_hessian(self, equilibrium_position: List[float]):
-        """Creates the symbolic hessian of the energy expression."""
-        energy = self.create_energy(volumetric=False)
-        subs = self.get_subs(equilibrium_position)
-        N = len(self.layers)
-        hessian = [[0 for _ in range(2 * N)] for _ in range(2 * N)]
-        for i in range(N):
-            z = self.layers[i].sb_correction()
-            theta_i, phi_i = self.layers[i].get_coord_sym()
-            for j in range(i, N):
-                # dtheta dtheta
-                theta_j, phi_j = self.layers[j].get_coord_sym()
-
-                expr = sym.diff(sym.diff(energy, theta_i), theta_j)
-                hessian[2 * i][2 * j] = expr
-                hessian[2 * j][2 * i] = expr
-
-                # dphi dphi
-                expr = sym.diff(sym.diff(energy, phi_i), phi_j)
-                hessian[2 * i + 1][2 * j + 1] = expr
-                hessian[2 * j + 1][2 * i + 1] = expr
-
-                expr = sym.diff(sym.diff(energy, theta_i), phi_j)
-                # mixed terms
-                if i == j:
-                    hessian[2 * i + 1][2 * j] = expr + sym.I * z
-                    hessian[2 * i][2 * j + 1] = expr - sym.I * z
-                else:
-                    hessian[2 * i][2 * j + 1] = expr
-                    hessian[2 * j + 1][2 * i] = expr
-
-                    expr = sym.diff(sym.diff(energy, phi_i), theta_j)
-                    hessian[2 * i + 1][2 * j] = expr
-                    hessian[2 * j][2 * i + 1] = expr
-
-        hes = sym.ImmutableMatrix(hessian)
-        _, U, _ = hes.LUdecomposition()
-        return U.det().subs(subs)
-
-    def get_gradient_expr(self, accel="math"):
-        """Returns the symbolic gradient of the energy expression."""
-        energy = self.create_energy(volumetric=False)
-        grad_vector = []
-        symbols = []
-        for layer in self.layers:
-            (theta, phi) = layer.get_coord_sym()
-            grad_vector.extend((sym.diff(energy, theta), sym.diff(energy,
-                                                                  phi)))
-            symbols.extend((theta, phi))
-        return sym.lambdify(symbols, grad_vector, accel)
-
-    def adam_gradient_descent(self,
-                              init_position: np.ndarray,
-                              max_steps: int,
-                              tol: float = 1e-8,
-                              learning_rate: float = 1e-4,
-                              first_momentum_decay: float = 0.9,
-                              second_momentum_decay: float = 0.999,
-                              perturbation: float = 1e-6):
-        """
-        A naive implementation of Adam gradient descent.
-        See: ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION, Kingma et Ba, 2015
-        :param max_steps: maximum number of gradient steps.
-        :param tol: tolerance of the solution.
-        :param learning_rate: the learning rate (descent speed).
-        :param first_momentum_decay: constant for the first momentum.
-        :param second_momentum_decay: constant for the second momentum.
-        """
-        step = 0
-        gradfn = self.get_gradient_expr()
-        current_position = init_position
-        if perturbation:
-            current_position = perturb_position(init_position, perturbation)
-        m = np.zeros_like(current_position)  # first momentum
-        v = np.zeros_like(current_position)  # second momentum
-        eps = 1e-12
-
-        while True:
-            step += 1
-            grad = np.asarray(gradfn(*current_position))
-            m = first_momentum_decay * m + (1. - first_momentum_decay) * grad
-            v = second_momentum_decay * v + (1. -
-                                             second_momentum_decay) * grad**2
-            m_hat = m / (1. - first_momentum_decay**step)
-            v_hat = v / (1. - second_momentum_decay**step)
-            new_position = current_position - learning_rate * m_hat / (
-                np.sqrt(v_hat) + eps)
-            if step > max_steps:
-                break
-            # if np.linalg.norm(current_position - new_position) < tol:
-            # break
-            if fast_norm(current_position - new_position) < tol:
-                break
-            current_position = new_position
-        return np.asarray(current_position)
-
-    def single_layer_resonance(self, layer_indx: int, eq_position: np.ndarray):
-        """We can compute the equilibrium position of a single layer directly.
-        :param layer_indx: the index of the layer to compute the equilibrium
-        :param eq_position: the equilibrium position vector"""
-        layer = self.layers[layer_indx]
-        theta_eq = eq_position[2 * layer_indx]
-        theta, phi = self.layers[layer_indx].get_coord_sym()
-        energy = self.create_energy(volumetric=True)
-        subs = self.get_subs(eq_position)
-        d2Edtheta2 = sym.diff(sym.diff(energy, theta), theta).subs(subs)
-        d2Edphi2 = sym.diff(sym.diff(energy, phi), phi).subs(subs)
-        # mixed, assuming symmetry
-        d2Edthetaphi = sym.diff(sym.diff(energy, theta), phi).subs(subs)
-        vareps = 1e-18
-
-        fmr = (d2Edtheta2 * d2Edphi2 - d2Edthetaphi**2) / np.power(
-            np.sin(theta_eq + vareps) * layer.Ms, 2)
-        fmr = np.sqrt(float(fmr)) * gamma_rad / (2 * np.pi)
-        return fmr
-
-    def solve(self,
-              init_position: np.ndarray,
-              max_steps: int = 1e9,
-              learning_rate: float = 1e-4,
-              adam_tol: float = 1e-8,
-              first_momentum_decay: float = 0.9,
-              second_momentum_decay: float = 0.999,
-              perturbation: float = 1e-3,
-              ftol: float = 0.01e9,
-              max_freq: float = 80e9,
-              force_single_layer: bool = False,
-              force_sb: bool = False):
-        """Solves the system.
-        1. Computes the energy functional.
-        2. Computes the gradient of the energy functional.
-        3. Performs a gradient descent to find the equilibrium position.
-        Returns the equilibrium position and frequencies in [GHz].
-        If there's only one layer, the frequency is computed analytically.
-        For full analytical solution, see: `analytical_field_scan`
-        :param init_position: initial position for the gradient descent.
-                              Must be a 1D array of size 2 * number of layers (theta, phi)
-        :param max_steps: maximum number of gradient steps.
-        :param learning_rate: the learning rate (descent speed).
-        :param adam_tol: tolerance for the consecutive Adam minima.
-        :param first_momentum_decay: constant for the first momentum.
-        :param second_momentum_decay: constant for the second momentum.
-        :param perturbation: the perturbation to use for the numerical gradient computation.
-        :param ftol: tolerance for the frequency search. [numerical only]
-        :param max_freq: maximum frequency to search for. [numerical only]
-        :param force_single_layer: whether to force the computation of the frequencies
-                                   for each layer individually.
-        :param force_sb: whether to force the computation of the frequencies.
-                        Takes effect only if the layers are LayerDynamic, not LayerSB.
-        :return: equilibrium position and frequencies in [GHz] (and eigenvectors if LayerDynamic instead of LayerSB).
-        """
-        if self.H is None:
-            raise ValueError(
-                "H must be set before solving the system numerically.")
-        eq = self.adam_gradient_descent(
-            init_position=init_position,
-            max_steps=max_steps,
-            tol=adam_tol,
-            learning_rate=learning_rate,
-            first_momentum_decay=first_momentum_decay,
-            second_momentum_decay=second_momentum_decay,
-            perturbation=perturbation)
-        if not force_sb and isinstance(self.layers[0], LayerDynamic):
-            eigenvalues, eigenvectors = self.dynamic_layer_solve(eq)
-            return eq, eigenvalues / 1e9, eigenvectors
-        N = len(self.layers)
-        if N == 1:
-            return eq, [self.single_layer_resonance(0, eq) / 1e9]
-        if force_single_layer:
-            frequencies = []
-            for indx in range(N):
-                frequency = self.single_layer_resonance(indx, eq) / 1e9
-                frequencies.append(frequency)
-            return eq, frequencies
-        return self.num_solve(eq, ftol=ftol, max_freq=max_freq)
-
-    def dynamic_layer_solve(self, eq: List[float]):
-        """Return the FMR frequencies and modes for N layers using the
-        dynamic RHS model
-        :param eq: the equilibrium position of the system.
-        :return: frequencies and eigenmode vectors."""
-        jac, symbols = self.compose_llg_jacobian(self.H)
-        subs = {symbols[i]: eq[i] for i in range(len(eq))}
-        jac = jac.subs(subs)
-        jac = np.asarray(jac, dtype=np.float32)
-        eigvals, eigvecs = np.linalg.eig(jac)
-        eigvals_im = np.imag(eigvals) / (2 * np.pi)
-        indx = np.argwhere(eigvals_im > 0).ravel()
-        return eigvals_im[indx], eigvecs[indx]
-
-    def num_solve(self,
-                  eq: List[float],
-                  ftol: float = 0.01e9,
-                  max_freq: float = 80e9):
-        hes = self.create_energy_hessian(eq)
-        omega = sym.Symbol(r"\omega")
-        if len(self.layers) <= 3:
-            y = real_deocrator(njit(sym.lambdify(omega, hes, 'math')))
-        else:
-            y = real_deocrator(sym.lambdify(omega, hes, 'math'))
-        r = RootFinder(0, max_freq, step=ftol, xtol=1e-8, root_dtype="float16")
-        roots = r.find(y)
-        # convert to GHz
-        # reduce unique solutions to 2 decimal places
-        # don't divide by 2pi, we used gamma instead of gamma / 2pi
-        f = np.unique(np.around(roots / 1e9, 2))
-        return eq, f
-
-    def analytical_roots(self):
-        """Find & cache the analytical roots of the system.
-        Returns a list of solutions.
-        Ineffecient for more than 2 layers (can try though).
-        """
-        Hsym = sym.Matrix([
-            sym.Symbol(r"H_{x}"),
-            sym.Symbol(r"H_{y}"),
-            sym.Symbol(r"H_{z}"),
-        ])
-        N = len(self.layers)
-        if N > 2:
-            warnings.warn(
-                "Analytical solutions for over 2 layers may be computationally expensive."
-            )
-        system_energy = self.create_energy(H=Hsym, volumetric=False)
-        root_expr, energy_functional_expr = find_analytical_roots(N)
-        subs = get_all_second_derivatives(energy_functional_expr,
-                                          energy_expression=system_energy,
-                                          subs={})
-        subs.update(self.get_ms_subs())
-        return [s.subs(subs) for s in root_expr]
-
-    def get_subs(self, equilibrium_position: List[float]):
-        """Returns the substitution dictionary for the energy expression."""
-        subs = {}
-        for i in range(len(self.layers)):
-            theta, phi = self.layers[i].get_coord_sym()
-            subs[theta] = equilibrium_position[2 * i]
-            subs[phi] = equilibrium_position[(2 * i) + 1]
-        return subs
-
-    def get_ms_subs(self):
-        """Returns a dictionary of substitutions for the Ms symbols."""
-        a = {r"M_{" + str(layer._id) + "}": layer.Ms for layer in self.layers}
-        b = {
-            r"t_{" + str(layer._id) + r"}": layer.thickness
-            for layer in self.layers
-        }
-        return a | b
-
-    def set_H(self, H: VectorObj):
-        """Sets the external field."""
-        self.H = H
-
-    def analytical_field_scan(
-        self,
-        Hrange: List[VectorObj],
-        init_position: List[float] = None,
-        max_steps: int = 1e9,
-        learning_rate: float = 1e-4,
-        first_momentum_decay: float = 0.9,
-        second_momentum_decay: float = 0.999,
-        disable_tqdm: bool = False
-    ) -> Iterable[Tuple[List[float], List[float], VectorObj]]:
-        """Performs a field scan using the analytical solutions.
-        :param Hrange: the range of fields to scan.
-        :param init_position: the initial position for the gradient descent.
-                              If None, the first field in Hrange will be used.
-        :param max_steps: maximum number of gradient steps.
-        :param learning_rate: the learning rate (descent speed).
-        :param first_momentum_decay: constant for the first momentum.
-        :param second_momentum_decay: constant for the second momentum.
-        :param disable_tqdm: disable the progress bar.
-        :return: an iterable of (equilibrium position, frequencies, field)
-        """
-        s1 = time.time()
-        global_roots = self.analytical_roots()
-        s2 = time.time()
-        if not disable_tqdm:
-            print(f"Analytical roots found in {s2 - s1:.2f} seconds.")
-        if init_position is None:
-            start = Hrange[0]
-            start.mag = 1
-            init_position = []
-            # align with the first field
-            for _ in self.layers:
-                init_position.extend([start.theta, start.phi])
-        Hsym = sym.Matrix([
-            sym.Symbol(r"H_{x}"),
-            sym.Symbol(r"H_{y}"),
-            sym.Symbol(r"H_{z}"),
-        ])
-        current_position = init_position
-        for Hvalue in tqdm(Hrange, disable=disable_tqdm):
-            self.set_H(Hvalue)
-            hx, hy, hz = Hvalue.get_cartesian()
-            eq = self.adam_gradient_descent(
-                init_position=current_position,
-                max_steps=max_steps,
-                tol=1e-9,
-                learning_rate=learning_rate,
-                first_momentum_decay=first_momentum_decay,
-                second_momentum_decay=second_momentum_decay,
-            )
-            step_subs = self.get_subs(eq)
-            step_subs.update(self.get_ms_subs())
-            step_subs.update({Hsym[0]: hx, Hsym[1]: hy, Hsym[2]: hz})
-            roots = [s.subs(step_subs) for s in global_roots]
-            roots = np.asarray(roots, dtype=np.float32) * gamma / 1e9
-            yield eq, roots, Hvalue
-            current_position = eq
+import math
+import time
+import warnings
+from dataclasses import dataclass
+from functools import lru_cache
+from typing import Iterable, List, Tuple, Union
+
+import numpy as np
+import sympy as sym
+from numba import njit
+from tqdm import tqdm
+
+from ..utils import VectorObj, gamma, gamma_rad, mu0, perturb_position
+from ..utils.solvers import RootFinder
+
+EPS = np.finfo("float64").resolution
+
+
+def real_deocrator(fn):
+    """Using numpy real cast is way faster than sympy."""
+
+    def wrap_fn(*args):
+        return np.real(fn(*args))
+
+    return wrap_fn
+
+
+@njit
+def fast_norm(x):  # sourcery skip: for-index-underscore, sum-comprehension
+    """Fast norm function for 1D arrays."""
+    sum_ = 0
+    for x_ in x:
+        sum_ += x_**2
+    return math.sqrt(sum_)
+
+
+@lru_cache
+def general_hessian_functional(N: int):
+    """Create a generalised hessian functional for N layers.
+    :param N: number of layers.
+    ! WARNING: remember Ms Symbols must match!!!
+    """
+    all_symbols = []
+    for i in range(N):
+        # indx_i = str(i + 1) # for display purposes
+        indx_i = str(i)
+        all_symbols.extend(
+            (sym.Symbol(r"\theta_" + indx_i), sym.Symbol(r"\phi_" + indx_i)))
+    energy_functional_expr = sym.Function("E")(*all_symbols)
+    return (
+        get_hessian_from_energy_expr(N, energy_functional_expr),
+        energy_functional_expr,
+    )
+
+
+@lru_cache
+def get_hessian_from_energy_expr(N: int, energy_functional_expr: sym.Expr):
+    """
+    Computes the Hessian matrix of the energy functional expression with respect to the spin angles and phases.
+
+    :param N (int): The number of spins.
+    :param energy_functional_expr (sympy.Expr): The energy functional expression.
+
+    returns: sympy.Matrix: The Hessian matrix of the energy functional expression.
+    """
+    hessian = [[0 for _ in range(2 * N)] for _ in range(2 * N)]
+    for i in range(N):
+        # indx_i = str(i + 1) # for display purposes
+        indx_i = str(i)
+        # z = sym.Symbol("Z")
+        # these here must match the Ms symbols!
+        z = (sym.Symbol(r"\omega") * sym.Symbol(r"M_{" + indx_i + "}") *
+             sym.sin(sym.Symbol(r"\theta_" + indx_i)) *
+             sym.Symbol(r"t_{" + indx_i + "}"))
+        for j in range(i, N):
+            # indx_j = str(j + 1) # for display purposes
+            indx_j = str(j)
+            s1 = sym.Symbol(r"\theta_" + indx_i)
+            s2 = sym.Symbol(r"\theta_" + indx_j)
+
+            expr = sym.diff(energy_functional_expr, s1, s2)
+            hessian[2 * i][2 * j] = expr
+            hessian[2 * j][2 * i] = expr
+            s1 = sym.Symbol(r"\phi_" + indx_i)
+            s2 = sym.Symbol(r"\phi_" + indx_j)
+            expr = sym.diff(energy_functional_expr, s1, s2)
+            hessian[2 * i + 1][2 * j + 1] = expr
+            hessian[2 * j + 1][2 * i + 1] = expr
+
+            s1 = sym.Symbol(r"\theta_" + indx_i)
+            s2 = sym.Symbol(r"\phi_" + indx_j)
+            expr = sym.diff(energy_functional_expr, s1, s2)
+            if i == j:
+                hessian[2 * i + 1][2 * j] = expr + sym.I * z
+                hessian[2 * i][2 * j + 1] = expr - sym.I * z
+            else:
+                hessian[2 * i][2 * j + 1] = expr
+                hessian[2 * j + 1][2 * i] = expr
+
+                s1 = sym.Symbol(r"\phi_" + indx_i)
+                s2 = sym.Symbol(r"\theta_" + indx_j)
+                expr = sym.diff(energy_functional_expr, s1, s2)
+                hessian[2 * i + 1][2 * j] = expr
+                hessian[2 * j][2 * i + 1] = expr
+    return sym.Matrix(hessian)
+
+
+@lru_cache()
+def solve_for_determinant(N: int):
+    """Solve for the determinant of the hessian functional.
+    :param N: number of layers.
+    """
+    hessian, energy_functional_expr = general_hessian_functional(N)
+    if N == 1:
+        return hessian.det(), energy_functional_expr
+
+    # LU decomposition
+    _, U, _ = hessian.LUdecomposition()
+    return U.det(), energy_functional_expr
+
+
+@lru_cache
+def find_analytical_roots(N: int):
+    det_expr, energy_functional_expr = solve_for_determinant(N)
+    solutions = sym.solve(sym.simplify(det_expr), sym.Symbol(r"\omega"))
+    return solutions, energy_functional_expr
+
+
+def get_all_second_derivatives(energy_functional_expr,
+                               energy_expression,
+                               subs=None):
+    """Get all second derivatives of the energy expression.
+    :param energy_functional_expr: symbolic energy_functional expression
+    :param energy_expression: symbolic energy expression (from solver)
+    :param subs: substitutions to be made."""
+    if subs is None:
+        subs = {}
+    second_derivatives = subs
+    symbols = energy_expression.free_symbols
+    for i, s1 in enumerate(symbols):
+        for j, s2 in enumerate(symbols):
+            if i <= j:
+                org_diff = sym.diff(energy_functional_expr, s1, s2)
+                if subs is not None:
+                    second_derivatives[org_diff] = sym.diff(
+                        energy_expression, s1, s2).subs(subs)
+                else:
+                    second_derivatives[org_diff] = sym.diff(
+                        energy_expression, s1, s2)
+    return second_derivatives
+
+
+@dataclass
+class LayerSB:
+    """Basic Layer for Smit-Beljers model.
+    :param thickness: thickness of the FM layer (effective).
+    :param Kv: volumetric (in-plane) anisotropy. Only phi and mag count [J/m^3].
+    :param Ks: surface anisotropy (out-of plane, or perpendicular) value [J/m^3].
+    :param Ms: magnetisation saturation value in [A/m].
+    """
+
+    _id: int
+    thickness: float
+    Kv: VectorObj
+    Ks: float
+    Ms: float
+
+    def __post_init__(self):
+        if self._id > 9:
+            raise ValueError("Only up to 10 layers supported.")
+        self.theta = sym.Symbol(r"\theta_" + str(self._id))
+        self.phi = sym.Symbol(r"\phi_" + str(self._id))
+        self.m = sym.ImmutableMatrix([
+            sym.sin(self.theta) * sym.cos(self.phi),
+            sym.sin(self.theta) * sym.sin(self.phi),
+            sym.cos(self.theta),
+        ])
+
+    def get_coord_sym(self):
+        """Returns the symbolic coordinates of the layer."""
+        return self.theta, self.phi
+
+    def get_m_sym(self):
+        """Returns the magnetisation vector."""
+        return self.m
+
+    @lru_cache(3)
+    def symbolic_layer_energy(
+        self,
+        H: sym.ImmutableMatrix,
+        J1top: float,
+        J1bottom: float,
+        J2top: float,
+        J2bottom: float,
+        top_layer: "LayerSB",
+        down_layer: "LayerSB",
+    ):
+        """Returns the symbolic expression for the energy of the layer.
+        Coupling contribution comes only from the bottom layer (top-down crawl)"""
+        m = self.get_m_sym()
+
+        eng_non_interaction = self.no_iec_symbolic_layer_energy(H)
+
+        top_iec_energy = 0
+        bottom_iec_energy = 0
+
+        if top_layer is not None:
+            other_m = top_layer.get_m_sym()
+            top_iec_energy = (-(J1top / self.thickness) * m.dot(other_m) -
+                              (J2top / self.thickness) * m.dot(other_m)**2)
+        if down_layer is not None:
+            other_m = down_layer.get_m_sym()
+            bottom_iec_energy = (
+                -(J1bottom / self.thickness) * m.dot(other_m) -
+                (J2bottom / self.thickness) * m.dot(other_m)**2)
+        return eng_non_interaction + top_iec_energy + bottom_iec_energy
+
+    def no_iec_symbolic_layer_energy(self, H: sym.ImmutableMatrix):
+        """Returns the symbolic expression for the energy of the layer.
+        Coupling contribution comes only from the bottom layer (top-down crawl)"""
+        m = self.get_m_sym()
+
+        alpha = sym.ImmutableMatrix(
+            [sym.cos(self.Kv.phi),
+             sym.sin(self.Kv.phi), 0])
+
+        field_energy = -mu0 * self.Ms * m.dot(H)
+        surface_anistropy = (-self.Ks +
+                             (1.0 / 2.0) * mu0 * self.Ms**2) * (m[-1]**2)
+        volume_anisotropy = -self.Kv.mag * (m.dot(alpha)**2)
+        return field_energy + surface_anistropy + volume_anisotropy
+
+    def sb_correction(self):
+        omega = sym.Symbol(r"\omega")
+        return (omega / gamma) * self.Ms * sym.sin(self.theta) * self.thickness
+
+    def __hash__(self) -> int:
+        return hash(str(self))
+
+    def __eq__(self, __value: "LayerSB") -> bool:
+        return (self._id == __value._id and self.thickness == __value.thickness
+                and self.Kv == __value.Kv and self.Ks == __value.Ks
+                and self.Ms == __value.Ms)
+
+
+@dataclass
+class LayerDynamic(LayerSB):
+    alpha: float
+
+    def rhs_llg(
+        self,
+        H: sym.Matrix,
+        J1top: float,
+        J1bottom: float,
+        J2top: float,
+        J2bottom: float,
+        top_layer: "LayerSB",
+        down_layer: "LayerSB",
+    ):
+        """Returns the symbolic expression for the RHS of the spherical LLG equation.
+        Coupling contribution comes only from the bottom layer (top-down crawl)"""
+        U = self.symbolic_layer_energy(
+            H,
+            J1top=J1top,
+            J1bottom=J1bottom,
+            J2top=J2top,
+            J2bottom=J2bottom,
+            top_layer=top_layer,
+            down_layer=down_layer,
+        )
+        # sum all components
+        prefac = gamma_rad / (1.0 + self.alpha)**2
+        inv_sin = 1.0 / (sym.sin(self.theta) + EPS)
+        dUdtheta = sym.diff(U, self.theta)
+        dUdphi = sym.diff(U, self.phi)
+
+        dtheta = -inv_sin * dUdphi - self.alpha * dUdtheta
+        dphi = inv_sin * dUdtheta - self.alpha * dUdphi * (inv_sin)**2
+        return prefac * sym.ImmutableMatrix([dtheta, dphi]) / self.Ms
+
+    def __eq__(self, __value: "LayerDynamic") -> bool:
+        return super().__eq__(__value) and self.alpha == __value.alpha
+
+    def __hash__(self) -> int:
+        return super().__hash__()
+
+
+@dataclass
+class Solver:
+    """General solver for the system.
+
+    :param layers: list of layers in the system.
+    :param J1: list of interlayer exchange constants. Goes (i)-(i+1), i = 0, 1, 2, ...
+        with i being the index of the layer.
+    :param J2: list of interlayer exchange constants.
+    :param H: external field.
+    :param Ndipole: list of dipole fields for each layer. Defaults to None.
+        Goes (i)-(i+1), i = 0, 1, 2, ... with i being the index of the layer.
+    """
+
+    layers: List[Union[LayerSB, LayerDynamic]]
+    J1: List[float]
+    J2: List[float]
+    H: VectorObj = None
+    Ndipole: List[List[VectorObj]] = None
+
+    def __post_init__(self):
+        if len(self.layers) != len(self.J1) + 1:
+            raise ValueError("Number of layers must be 1 more than J1.")
+        if len(self.layers) != len(self.J2) + 1:
+            raise ValueError("Number of layers must be 1 more than J2.")
+
+        self.dipoleMatrix: list[sym.Matrix] = None
+        if self.Ndipole is not None:
+            if len(self.layers) != len(self.Ndipole) + 1:
+                raise ValueError(
+                    "Number of layers must be 1 more than number of tensors.")
+            if isinstance(self.layers[0], LayerDynamic):
+                raise ValueError(
+                    "Dipole coupling is not yet supported for LayerDynamic.")
+            self.dipoleMatrix = [
+                sym.Matrix([d.get_cartesian() for d in dipole])
+                for dipole in self.Ndipole
+            ]
+
+        id_sets = {layer._id for layer in self.layers}
+        ideal_set = set(range(len(self.layers)))
+        if id_sets != ideal_set:
+            raise ValueError("Layer ids must be 0, 1, 2, ... and unique."
+                             "Ids must start from 0.")
+
+    def get_layer_references(self, layer_indx, interaction_constant):
+        """Returns the references to the layers above and below the layer
+        with index layer_indx."""
+        if len(self.layers) == 1:
+            return None, None, 0, 0
+        if layer_indx == 0:
+            return None, self.layers[layer_indx +
+                                     1], 0, interaction_constant[0]
+        elif layer_indx == len(self.layers) - 1:
+            return self.layers[layer_indx -
+                               1], None, interaction_constant[-1], 0
+        return (
+            self.layers[layer_indx - 1],
+            self.layers[layer_indx + 1],
+            interaction_constant[layer_indx - 1],
+            interaction_constant[layer_indx],
+        )
+
+    def compose_llg_jacobian(self, H: VectorObj):
+        """Create a symbolic jacobian of the LLG equation in spherical coordinates."""
+        # has order theta0, phi0, theta1, phi1, ...
+        if isinstance(H, VectorObj):
+            H = sym.ImmutableMatrix(H.get_cartesian())
+
+        symbols, fns = [], []
+        for i, layer in enumerate(self.layers):
+            symbols.extend((layer.theta, layer.phi))
+            top_layer, bottom_layer, Jtop, Jbottom = self.get_layer_references(
+                i, self.J1)
+            _, _, J2top, J2bottom = self.get_layer_references(i, self.J2)
+            fns.append(
+                layer.rhs_llg(H, Jtop, Jbottom, J2top, J2bottom, top_layer,
+                              bottom_layer))
+        jac = sym.ImmutableMatrix(fns).jacobian(symbols)
+        return jac, symbols
+
+    def create_energy(self,
+                      H: Union[VectorObj, sym.ImmutableMatrix] = None,
+                      volumetric: bool = False):
+        """Creates the symbolic energy expression.
+
+        Due to problematic nature of coupling, there is an issue of
+        computing each layer's FMR in the presence of IEC.
+        If volumetric = True then we use the thickness of the layer to multiply the
+        energy and hence avoid having to divide J by the thickness of a layer.
+        If volumetric = False the J constant is divided by weighted thickness
+        and included in every layer's energy, correcting FMR automatically.
+        """
+        if H is None:
+            h = self.H.get_cartesian()
+            H = sym.ImmutableMatrix(h)
+        energy = 0
+        if volumetric:
+            # volumetric energy -- DO NOT USE IN GENERAL
+            for i, layer in enumerate(self.layers):
+                top_layer, bottom_layer, Jtop, Jbottom = self.get_layer_references(
+                    i, self.J1)
+                _, _, J2top, J2bottom = self.get_layer_references(i, self.J2)
+                ratio_top, ratio_bottom = 0, 0
+                if top_layer:
+                    ratio_top = top_layer.thickness / (top_layer.thickness +
+                                                       layer.thickness)
+                if bottom_layer:
+                    ratio_bottom = bottom_layer.thickness / (
+                        layer.thickness + bottom_layer.thickness)
+                energy += layer.symbolic_layer_energy(
+                    H,
+                    Jtop * ratio_top,
+                    Jbottom * ratio_bottom,
+                    J2top,
+                    J2bottom,
+                    top_layer,
+                    bottom_layer,
+                )
+        else:
+            # surface energy for correct angular gradient
+            for layer in self.layers:
+                # to avoid dividing J by thickness
+                energy += layer.no_iec_symbolic_layer_energy(
+                    H) * layer.thickness
+
+            for i in range(len(self.layers) - 1):
+                l1m = self.layers[i].get_m_sym()
+                l2m = self.layers[i + 1].get_m_sym()
+                ldot = l1m.dot(l2m)
+                energy -= self.J1[i] * ldot
+                energy -= self.J2[i] * (ldot)**2
+
+                # dipole fields
+                if self.dipoleMatrix is not None:
+                    mat = self.dipoleMatrix[i]
+                    # is positive, just like demag
+                    energy += ((mu0 / 2.0) * l1m.dot(mat * l2m) *
+                               self.layers[i].Ms * self.layers[i + 1].Ms *
+                               self.layers[i].thickness)
+                    energy += ((mu0 / 2.0) * l2m.dot(mat * l1m) *
+                               self.layers[i].Ms * self.layers[i + 1].Ms *
+                               self.layers[i + 1].thickness)
+        return energy
+
+    def create_energy_hessian(self, equilibrium_position: List[float]):
+        """Creates the symbolic hessian of the energy expression."""
+        energy = self.create_energy(volumetric=False)
+        subs = self.get_subs(equilibrium_position)
+        N = len(self.layers)
+        hessian = [[0 for _ in range(2 * N)] for _ in range(2 * N)]
+        for i in range(N):
+            z = self.layers[i].sb_correction()
+            theta_i, phi_i = self.layers[i].get_coord_sym()
+            for j in range(i, N):
+                # dtheta dtheta
+                theta_j, phi_j = self.layers[j].get_coord_sym()
+
+                expr = sym.diff(sym.diff(energy, theta_i), theta_j)
+                hessian[2 * i][2 * j] = expr
+                hessian[2 * j][2 * i] = expr
+
+                # dphi dphi
+                expr = sym.diff(sym.diff(energy, phi_i), phi_j)
+                hessian[2 * i + 1][2 * j + 1] = expr
+                hessian[2 * j + 1][2 * i + 1] = expr
+
+                expr = sym.diff(sym.diff(energy, theta_i), phi_j)
+                # mixed terms
+                if i == j:
+                    hessian[2 * i + 1][2 * j] = expr + sym.I * z
+                    hessian[2 * i][2 * j + 1] = expr - sym.I * z
+                else:
+                    hessian[2 * i][2 * j + 1] = expr
+                    hessian[2 * j + 1][2 * i] = expr
+
+                    expr = sym.diff(sym.diff(energy, phi_i), theta_j)
+                    hessian[2 * i + 1][2 * j] = expr
+                    hessian[2 * j][2 * i + 1] = expr
+
+        hes = sym.ImmutableMatrix(hessian)
+        _, U, _ = hes.LUdecomposition()
+        return U.det().subs(subs)
+
+    def get_gradient_expr(self, accel="math"):
+        """Returns the symbolic gradient of the energy expression."""
+        energy = self.create_energy(volumetric=False)
+        grad_vector = []
+        symbols = []
+        for layer in self.layers:
+            (theta, phi) = layer.get_coord_sym()
+            grad_vector.extend((sym.diff(energy, theta), sym.diff(energy,
+                                                                  phi)))
+            symbols.extend((theta, phi))
+        return sym.lambdify(symbols, grad_vector, accel)
+
+    def adam_gradient_descent(
+        self,
+        init_position: np.ndarray,
+        max_steps: int,
+        tol: float = 1e-8,
+        learning_rate: float = 1e-4,
+        first_momentum_decay: float = 0.9,
+        second_momentum_decay: float = 0.999,
+        perturbation: float = 1e-6,
+    ):
+        """
+        A naive implementation of Adam gradient descent.
+        See: ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION, Kingma et Ba, 2015
+        :param max_steps: maximum number of gradient steps.
+        :param tol: tolerance of the solution.
+        :param learning_rate: the learning rate (descent speed).
+        :param first_momentum_decay: constant for the first momentum.
+        :param second_momentum_decay: constant for the second momentum.
+        """
+        step = 0
+        gradfn = self.get_gradient_expr()
+        current_position = init_position
+        if perturbation:
+            current_position = perturb_position(init_position, perturbation)
+        m = np.zeros_like(current_position)  # first momentum
+        v = np.zeros_like(current_position)  # second momentum
+        eps = 1e-12
+        # history = []
+        while True:
+            step += 1
+            grad = np.asarray(gradfn(*current_position))
+            m = first_momentum_decay * m + (1.0 - first_momentum_decay) * grad
+            v = second_momentum_decay * v + (1.0 -
+                                             second_momentum_decay) * grad**2
+            m_hat = m / (1.0 - first_momentum_decay**step)
+            v_hat = v / (1.0 - second_momentum_decay**step)
+            new_position = current_position - learning_rate * m_hat / (
+                np.sqrt(v_hat) + eps)
+            if step > max_steps:
+                break
+            if fast_norm(current_position - new_position) < tol:
+                break
+            current_position = new_position
+            # history.append(current_position)
+        # return np.asarray(current_position), np.asarray(history)
+        return np.asarray(current_position)
+
+    def single_layer_resonance(self, layer_indx: int, eq_position: np.ndarray):
+        """We can compute the equilibrium position of a single layer directly.
+        :param layer_indx: the index of the layer to compute the equilibrium
+        :param eq_position: the equilibrium position vector"""
+        layer = self.layers[layer_indx]
+        theta_eq = eq_position[2 * layer_indx]
+        theta, phi = self.layers[layer_indx].get_coord_sym()
+        energy = self.create_energy(volumetric=True)
+        subs = self.get_subs(eq_position)
+        d2Edtheta2 = sym.diff(sym.diff(energy, theta), theta).subs(subs)
+        d2Edphi2 = sym.diff(sym.diff(energy, phi), phi).subs(subs)
+        # mixed, assuming symmetry
+        d2Edthetaphi = sym.diff(sym.diff(energy, theta), phi).subs(subs)
+        vareps = 1e-18
+
+        fmr = (d2Edtheta2 * d2Edphi2 - d2Edthetaphi**2) / np.power(
+            np.sin(theta_eq + vareps) * layer.Ms, 2)
+        fmr = np.sqrt(float(fmr)) * gamma_rad / (2 * np.pi)
+        return fmr
+
+    def solve(
+        self,
+        init_position: np.ndarray,
+        max_steps: int = 1e9,
+        learning_rate: float = 1e-4,
+        adam_tol: float = 1e-8,
+        first_momentum_decay: float = 0.9,
+        second_momentum_decay: float = 0.999,
+        perturbation: float = 1e-3,
+        ftol: float = 0.01e9,
+        max_freq: float = 80e9,
+        force_single_layer: bool = False,
+        force_sb: bool = False,
+    ):
+        """Solves the system.
+        For dynamic LayerDynamic, the return is different, check :return.
+        1. Computes the energy functional.
+        2. Computes the gradient of the energy functional.
+        3. Performs a gradient descent to find the equilibrium position.
+        Returns the equilibrium position and frequencies in [GHz].
+        If there's only one layer, the frequency is computed analytically.
+        For full analytical solution, see: `analytical_field_scan`
+        :param init_position: initial position for the gradient descent.
+                              Must be a 1D array of size 2 * number of layers (theta, phi)
+        :param max_steps: maximum number of gradient steps.
+        :param learning_rate: the learning rate (descent speed).
+        :param adam_tol: tolerance for the consecutive Adam minima.
+        :param first_momentum_decay: constant for the first momentum.
+        :param second_momentum_decay: constant for the second momentum.
+        :param perturbation: the perturbation to use for the numerical gradient computation.
+        :param ftol: tolerance for the frequency search. [numerical only]
+        :param max_freq: maximum frequency to search for. [numerical only]
+        :param force_single_layer: whether to force the computation of the frequencies
+                                   for each layer individually.
+        :param force_sb: whether to force the computation of the frequencies.
+                        Takes effect only if the layers are LayerDynamic, not LayerSB.
+        :return: equilibrium position and frequencies in [GHz] (and eigenvectors if LayerDynamic instead of LayerSB).
+        """
+        if self.H is None:
+            raise ValueError(
+                "H must be set before solving the system numerically.")
+        eq = self.adam_gradient_descent(
+            init_position=init_position,
+            max_steps=max_steps,
+            tol=adam_tol,
+            learning_rate=learning_rate,
+            first_momentum_decay=first_momentum_decay,
+            second_momentum_decay=second_momentum_decay,
+            perturbation=perturbation,
+        )
+        if not force_sb and isinstance(self.layers[0], LayerDynamic):
+            eigenvalues, eigenvectors = self.dynamic_layer_solve(eq)
+            return eq, eigenvalues / 1e9, eigenvectors
+        N = len(self.layers)
+        if N == 1:
+            return eq, [self.single_layer_resonance(0, eq) / 1e9]
+        if force_single_layer:
+            frequencies = []
+            for indx in range(N):
+                frequency = self.single_layer_resonance(indx, eq) / 1e9
+                frequencies.append(frequency)
+            return eq, frequencies
+        return self.num_solve(eq, ftol=ftol, max_freq=max_freq)
+
+    def dynamic_layer_solve(self, eq: List[float]):
+        """Return the FMR frequencies and modes for N layers using the
+        dynamic RHS model
+        :param eq: the equilibrium position of the system.
+        :return: frequencies and eigenmode vectors."""
+        jac, symbols = self.compose_llg_jacobian(self.H)
+        subs = {symbols[i]: eq[i] for i in range(len(eq))}
+        jac = jac.subs(subs)
+        jac = np.asarray(jac, dtype=np.float32)
+        eigvals, eigvecs = np.linalg.eig(jac)
+        eigvals_im = np.imag(eigvals) / (2 * np.pi)
+        indx = np.argwhere(eigvals_im > 0).ravel()
+        return eigvals_im[indx], eigvecs[indx]
+
+    def num_solve(self,
+                  eq: List[float],
+                  ftol: float = 0.01e9,
+                  max_freq: float = 80e9):
+        hes = self.create_energy_hessian(eq)
+        omega = sym.Symbol(r"\omega")
+        if len(self.layers) <= 3:
+            y = real_deocrator(njit(sym.lambdify(omega, hes, "math")))
+        else:
+            y = real_deocrator(sym.lambdify(omega, hes, "math"))
+        r = RootFinder(0, max_freq, step=ftol, xtol=1e-8, root_dtype="float16")
+        roots = r.find(y)
+        # convert to GHz
+        # reduce unique solutions to 2 decimal places
+        # don't divide by 2pi, we used gamma instead of gamma / 2pi
+        f = np.unique(np.around(roots / 1e9, 2))
+        return eq, f
+
+    def analytical_roots(self):
+        """Find & cache the analytical roots of the system.
+        Returns a list of solutions.
+        Ineffecient for more than 2 layers (can try though).
+        """
+        Hsym = sym.Matrix([
+            sym.Symbol(r"H_{x}"),
+            sym.Symbol(r"H_{y}"),
+            sym.Symbol(r"H_{z}"),
+        ])
+        N = len(self.layers)
+        if N > 2:
+            warnings.warn(
+                "Analytical solutions for over 2 layers may be computationally expensive."
+            )
+        system_energy = self.create_energy(H=Hsym, volumetric=False)
+        root_expr, energy_functional_expr = find_analytical_roots(N)
+        subs = get_all_second_derivatives(energy_functional_expr,
+                                          energy_expression=system_energy,
+                                          subs={})
+        subs.update(self.get_ms_subs())
+        return [s.subs(subs) for s in root_expr]
+
+    def get_subs(self, equilibrium_position: List[float]):
+        """Returns the substitution dictionary for the energy expression."""
+        subs = {}
+        for i in range(len(self.layers)):
+            theta, phi = self.layers[i].get_coord_sym()
+            subs[theta] = equilibrium_position[2 * i]
+            subs[phi] = equilibrium_position[(2 * i) + 1]
+        return subs
+
+    def get_ms_subs(self):
+        """Returns a dictionary of substitutions for the Ms symbols."""
+        a = {r"M_{" + str(layer._id) + "}": layer.Ms for layer in self.layers}
+        b = {
+            r"t_{" + str(layer._id) + r"}": layer.thickness
+            for layer in self.layers
+        }
+        return a | b
+
+    def set_H(self, H: VectorObj):
+        """Sets the external field."""
+        self.H = H
+
+    def analytical_field_scan(
+        self,
+        Hrange: List[VectorObj],
+        init_position: List[float] = None,
+        max_steps: int = 1e9,
+        learning_rate: float = 1e-4,
+        first_momentum_decay: float = 0.9,
+        second_momentum_decay: float = 0.999,
+        disable_tqdm: bool = False,
+    ) -> Iterable[Tuple[List[float], List[float], VectorObj]]:
+        """Performs a field scan using the analytical solutions.
+        :param Hrange: the range of fields to scan.
+        :param init_position: the initial position for the gradient descent.
+                              If None, the first field in Hrange will be used.
+        :param max_steps: maximum number of gradient steps.
+        :param learning_rate: the learning rate (descent speed).
+        :param first_momentum_decay: constant for the first momentum.
+        :param second_momentum_decay: constant for the second momentum.
+        :param disable_tqdm: disable the progress bar.
+        :return: an iterable of (equilibrium position, frequencies, field)
+        """
+        s1 = time.time()
+        global_roots = self.analytical_roots()
+        s2 = time.time()
+        if not disable_tqdm:
+            print(f"Analytical roots found in {s2 - s1:.2f} seconds.")
+        if init_position is None:
+            start = Hrange[0]
+            start.mag = 1
+            init_position = []
+            # align with the first field
+            for _ in self.layers:
+                init_position.extend([start.theta, start.phi])
+        Hsym = sym.Matrix([
+            sym.Symbol(r"H_{x}"),
+            sym.Symbol(r"H_{y}"),
+            sym.Symbol(r"H_{z}"),
+        ])
+        current_position = init_position
+        for Hvalue in tqdm(Hrange, disable=disable_tqdm):
+            self.set_H(Hvalue)
+            hx, hy, hz = Hvalue.get_cartesian()
+            eq = self.adam_gradient_descent(
+                init_position=current_position,
+                max_steps=max_steps,
+                tol=1e-9,
+                learning_rate=learning_rate,
+                first_momentum_decay=first_momentum_decay,
+                second_momentum_decay=second_momentum_decay,
+            )
+            step_subs = self.get_subs(eq)
+            step_subs.update(self.get_ms_subs())
+            step_subs.update({Hsym[0]: hx, Hsym[1]: hy, Hsym[2]: hz})
+            roots = [s.subs(step_subs) for s in global_roots]
+            roots = np.asarray(roots, dtype=np.float32) * gamma / 1e9
+            yield eq, roots, Hvalue
+            current_position = eq
```

## cmtj/models/oersted.py

 * *Ordering differences only*

```diff
@@ -1,221 +1,221 @@
-import math
-from dataclasses import dataclass
-from typing import Literal
-
-import matplotlib.pyplot as plt
-import numpy as np
-from numba import njit, prange
-from tqdm import tqdm
-
-two_pi = math.pi * 2
-
-
-@njit
-def distance(p1, p2):
-    return math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)
-
-
-@njit
-def ampere_law(I, p1, p2):
-    r = distance(p1, p2)
-    return I / (two_pi * r)
-
-
-@dataclass
-class Block:
-    ix: int
-    iy: int
-    iz: int
-    dx: float
-    dy: float
-    dz: float
-    Hlocal: float = 0
-    I: float = 0
-
-    def __post_init__(self):
-        self.x = (self.ix + 1) * self.dx / 2.  # compute center point
-        self.y = (self.iy + 1) * self.dy / 2.  # compute center point
-        self.z = (self.iz + 1) * self.dz / 2.  # compute center point
-        self.area = self.dx * self.dy
-        self.dl = self.dz
-        return self.dz
-
-    def distance_sqr_from(self, other_block: 'Block'):
-        return (self.x - other_block.x)**2 + (self.y - other_block.y)**2 + (
-            self.z - other_block.z)**2
-
-    def set_I(self, I):
-        self.I = I
-
-    def set_j(self, j):
-        self.I = j * self.area
-
-    def add_H(self, H):
-        self.Hlocal += H
-
-    def biot_savart(self, other_block: 'Block'):
-        r = distance((self.x, self.y), (other_block.x, other_block.y))
-        if r < 1e-15:
-            return 0.
-        H = other_block.I * other_block.area * self.dl / r**2
-        return H / (4 * math.pi)
-
-    def ampere_law(self, other_block: 'Block'):
-        return ampere_law(other_block.I, (self.x, self.y),
-                          (other_block.x, other_block.y))
-
-    def __eq__(self, __o: 'Block') -> bool:
-        return self.ix == __o.ix and self.iy == __o.iy and self.iz == __o.iz
-
-
-class Structure:
-
-    def __init__(self,
-                 maxX,
-                 maxY,
-                 maxZ,
-                 dx,
-                 dy,
-                 dz,
-                 method: Literal['ampere', 'biot-savart'] = 'ampere') -> None:
-        self.maxX = maxX
-        self.maxY = maxY
-        self.maxZ = maxZ
-        self.dx = dx
-        self.dy = dy
-        self.dz = dz
-        self.Xsize = math.ceil(maxX / dx)
-        self.Ysize = math.ceil(maxY / dy)
-        self.Zsize = max(math.ceil(maxZ / dz), 1)
-        print(f"Creating {self.Xsize}x{self.Ysize}x{self.Zsize} blocks")
-        if (method == 'ampere') and (self.Zsize > 1):
-            raise ValueError("Wasting compute with z dim non-zero!")
-
-        self.blocks = self.init_blocks()
-        self.borders = []
-        self.labels = []
-
-    def set_region_I_idx(self, I, min_y_indx, max_y_indx=-1):
-        if max_y_indx == -1:
-            max_y_indx = self.Ysize
-        I_mag = I / (self.Xsize *
-                     (min(max_y_indx + 1, self.Ysize) - min_y_indx))
-        # print(f"Setting I={I*1e3:.2f}mA in region {min_y_indx}:{max_y_indx}")
-        # print(f"Unit I={I_mag*1e6:.2f}uA")
-        for yindx in prange(min_y_indx, min(max_y_indx, self.Ysize)):
-            for x in range(self.Xsize):
-                for zindx in range(self.Zsize):
-                    self.blocks[x, yindx, zindx].set_I(I_mag)
-
-    def set_region_I(self, I, min_y, max_y=-1, label=None):
-        # convert to index
-        self.borders.append(min_y)
-        self.labels.append(label)
-        min_y_indx = math.ceil(min_y / self.dy)
-        min_y_indx, max_y_indx = self.__ycoords2indx(min_y, max_y)
-        self.set_region_I_idx(I, min_y_indx, max_y_indx)
-
-    def init_blocks(self):
-        null_blocks = np.empty((self.Xsize, self.Ysize, self.Zsize),
-                               dtype=Block)
-        for ix in prange(self.Xsize):
-            for iy in range(self.Ysize):
-                for iz in range(self.Zsize):
-                    null_blocks[ix, iy, iz] = Block(ix, iy, iz, self.dx,
-                                                    self.dy, self.dz)
-        return null_blocks
-
-    def reset(self):
-        self.blocks = self.init_blocks()
-
-    def compute_blocks(self):
-        all_blocks = self.blocks.flatten()
-        for i in tqdm(prange(len(all_blocks)), mininterval=0.5):
-            for j in range(i + 1, len(all_blocks)):
-                block = all_blocks[i]
-                other_block = all_blocks[j]
-                # use symmetry to reduce complexity
-                Hval1 = block.ampere_law(other_block)
-                Hval2 = other_block.ampere_law(block)
-                block.Hlocal += Hval1
-                other_block.Hlocal += Hval2
-
-    def __ycoords2indx(self, min_coord_y, max_coord_y):
-        min_y_indx = math.ceil(min_coord_y / self.dy)
-        if max_coord_y == -1:
-            max_y_indx = self.maxY
-        else:
-            max_y_indx = math.ceil(max_coord_y / self.dy)
-        return min_y_indx, max_y_indx
-
-    def get_region_contributions_idx(self, min_y_indx, max_y_indx=-1):
-        if max_y_indx == -1:
-            max_y_indx = self.Ysize
-        H = 0
-        for yindx in prange(min_y_indx, min(max_y_indx, self.Ysize)):
-            for x in range(self.Xsize):
-                for zindx in range(self.Zsize):
-                    H += self.blocks[x, yindx, zindx].Hlocal
-        return H
-
-    def compute_region_contribution(self, source_min_y, source_max_y,
-                                    target_min_y, target_max_y):
-        source_min_y_indx, source_max_y_indx = self.__ycoords2indx(
-            source_min_y, source_max_y)
-        target_min_y_indx, target_max_y_indx = self.__ycoords2indx(
-            target_min_y, target_max_y)
-
-        return self.compute_region_contribution_idx(source_min_y_indx,
-                                                    source_max_y_indx,
-                                                    target_min_y_indx,
-                                                    target_max_y_indx)
-
-    def compute_region_contribution_idx(self, source_min_y_indx,
-                                        source_max_y_indx, target_min_y_indx,
-                                        target_max_y_indx):
-        print(
-            f"Computing H from {source_min_y_indx}:{source_max_y_indx} to {target_min_y_indx}:{target_max_y_indx}"
-        )
-        total_H = 0
-        block_src = self.blocks[:, source_min_y_indx:
-                                source_max_y_indx, :].flatten()
-        block_targ = self.blocks[:, target_min_y_indx:
-                                 target_max_y_indx, :].flatten()
-        print(f"Source blocks: {block_src.shape}")
-
-        print(f"Target blocks: {block_targ.shape}")
-        for source_block in block_src:
-            for target_block in block_targ:
-                if source_block == target_block:
-                    continue
-                H = target_block.ampere_law(source_block)
-                total_H += H
-        return total_H
-
-    def show_field(self, log=False):
-        field = np.zeros((self.Xsize, self.Ysize))
-        for block in self.blocks.flatten():
-            field[block.ix, block.iy] = block.Hlocal
-        with plt.style.context(['nature', 'science']):
-            fig, ax = plt.subplots(dpi=300)
-
-            if log:
-                img = ax.pcolormesh(np.log(field).T, cmap='viridis')
-            else:
-                img = ax.pcolormesh(field.T, cmap='viridis')
-            # add colorbar
-            ax.set_xticklabels([
-                f"{x*1e9:.2f}"
-                for x in np.linspace(0, self.Xsize * self.dx, self.Xsize)
-            ])
-            ax.set_yticklabels([
-                f"{y*1e9:.2f}"
-                for y in np.linspace(0, self.Ysize * self.dy, self.Ysize)
-            ])
-            ax.set_xlabel("x (nm)")
-            ax.set_ylabel("y (nm)")
-            # add colorbar
-            for unq_border, label in zip(self.borders, self.labels):
-                ax.axhline(unq_border / self.dy, color='crimson')
-            fig.colorbar(img, ax=ax)
-        return field
+import math
+from dataclasses import dataclass
+from typing import Literal
+
+import matplotlib.pyplot as plt
+import numpy as np
+from numba import njit, prange
+from tqdm import tqdm
+
+two_pi = math.pi * 2
+
+
+@njit
+def distance(p1, p2):
+    return math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)
+
+
+@njit
+def ampere_law(I, p1, p2):
+    r = distance(p1, p2)
+    return I / (two_pi * r)
+
+
+@dataclass
+class Block:
+    ix: int
+    iy: int
+    iz: int
+    dx: float
+    dy: float
+    dz: float
+    Hlocal: float = 0
+    I: float = 0
+
+    def __post_init__(self):
+        self.x = (self.ix + 1) * self.dx / 2.  # compute center point
+        self.y = (self.iy + 1) * self.dy / 2.  # compute center point
+        self.z = (self.iz + 1) * self.dz / 2.  # compute center point
+        self.area = self.dx * self.dy
+        self.dl = self.dz
+        return self.dz
+
+    def distance_sqr_from(self, other_block: 'Block'):
+        return (self.x - other_block.x)**2 + (self.y - other_block.y)**2 + (
+            self.z - other_block.z)**2
+
+    def set_I(self, I):
+        self.I = I
+
+    def set_j(self, j):
+        self.I = j * self.area
+
+    def add_H(self, H):
+        self.Hlocal += H
+
+    def biot_savart(self, other_block: 'Block'):
+        r = distance((self.x, self.y), (other_block.x, other_block.y))
+        if r < 1e-15:
+            return 0.
+        H = other_block.I * other_block.area * self.dl / r**2
+        return H / (4 * math.pi)
+
+    def ampere_law(self, other_block: 'Block'):
+        return ampere_law(other_block.I, (self.x, self.y),
+                          (other_block.x, other_block.y))
+
+    def __eq__(self, __o: 'Block') -> bool:
+        return self.ix == __o.ix and self.iy == __o.iy and self.iz == __o.iz
+
+
+class Structure:
+
+    def __init__(self,
+                 maxX,
+                 maxY,
+                 maxZ,
+                 dx,
+                 dy,
+                 dz,
+                 method: Literal['ampere', 'biot-savart'] = 'ampere') -> None:
+        self.maxX = maxX
+        self.maxY = maxY
+        self.maxZ = maxZ
+        self.dx = dx
+        self.dy = dy
+        self.dz = dz
+        self.Xsize = math.ceil(maxX / dx)
+        self.Ysize = math.ceil(maxY / dy)
+        self.Zsize = max(math.ceil(maxZ / dz), 1)
+        print(f"Creating {self.Xsize}x{self.Ysize}x{self.Zsize} blocks")
+        if (method == 'ampere') and (self.Zsize > 1):
+            raise ValueError("Wasting compute with z dim non-zero!")
+
+        self.blocks = self.init_blocks()
+        self.borders = []
+        self.labels = []
+
+    def set_region_I_idx(self, I, min_y_indx, max_y_indx=-1):
+        if max_y_indx == -1:
+            max_y_indx = self.Ysize
+        I_mag = I / (self.Xsize *
+                     (min(max_y_indx + 1, self.Ysize) - min_y_indx))
+        # print(f"Setting I={I*1e3:.2f}mA in region {min_y_indx}:{max_y_indx}")
+        # print(f"Unit I={I_mag*1e6:.2f}uA")
+        for yindx in prange(min_y_indx, min(max_y_indx, self.Ysize)):
+            for x in range(self.Xsize):
+                for zindx in range(self.Zsize):
+                    self.blocks[x, yindx, zindx].set_I(I_mag)
+
+    def set_region_I(self, I, min_y, max_y=-1, label=None):
+        # convert to index
+        self.borders.append(min_y)
+        self.labels.append(label)
+        min_y_indx = math.ceil(min_y / self.dy)
+        min_y_indx, max_y_indx = self.__ycoords2indx(min_y, max_y)
+        self.set_region_I_idx(I, min_y_indx, max_y_indx)
+
+    def init_blocks(self):
+        null_blocks = np.empty((self.Xsize, self.Ysize, self.Zsize),
+                               dtype=Block)
+        for ix in prange(self.Xsize):
+            for iy in range(self.Ysize):
+                for iz in range(self.Zsize):
+                    null_blocks[ix, iy, iz] = Block(ix, iy, iz, self.dx,
+                                                    self.dy, self.dz)
+        return null_blocks
+
+    def reset(self):
+        self.blocks = self.init_blocks()
+
+    def compute_blocks(self):
+        all_blocks = self.blocks.flatten()
+        for i in tqdm(prange(len(all_blocks)), mininterval=0.5):
+            for j in range(i + 1, len(all_blocks)):
+                block = all_blocks[i]
+                other_block = all_blocks[j]
+                # use symmetry to reduce complexity
+                Hval1 = block.ampere_law(other_block)
+                Hval2 = other_block.ampere_law(block)
+                block.Hlocal += Hval1
+                other_block.Hlocal += Hval2
+
+    def __ycoords2indx(self, min_coord_y, max_coord_y):
+        min_y_indx = math.ceil(min_coord_y / self.dy)
+        if max_coord_y == -1:
+            max_y_indx = self.maxY
+        else:
+            max_y_indx = math.ceil(max_coord_y / self.dy)
+        return min_y_indx, max_y_indx
+
+    def get_region_contributions_idx(self, min_y_indx, max_y_indx=-1):
+        if max_y_indx == -1:
+            max_y_indx = self.Ysize
+        H = 0
+        for yindx in prange(min_y_indx, min(max_y_indx, self.Ysize)):
+            for x in range(self.Xsize):
+                for zindx in range(self.Zsize):
+                    H += self.blocks[x, yindx, zindx].Hlocal
+        return H
+
+    def compute_region_contribution(self, source_min_y, source_max_y,
+                                    target_min_y, target_max_y):
+        source_min_y_indx, source_max_y_indx = self.__ycoords2indx(
+            source_min_y, source_max_y)
+        target_min_y_indx, target_max_y_indx = self.__ycoords2indx(
+            target_min_y, target_max_y)
+
+        return self.compute_region_contribution_idx(source_min_y_indx,
+                                                    source_max_y_indx,
+                                                    target_min_y_indx,
+                                                    target_max_y_indx)
+
+    def compute_region_contribution_idx(self, source_min_y_indx,
+                                        source_max_y_indx, target_min_y_indx,
+                                        target_max_y_indx):
+        print(
+            f"Computing H from {source_min_y_indx}:{source_max_y_indx} to {target_min_y_indx}:{target_max_y_indx}"
+        )
+        total_H = 0
+        block_src = self.blocks[:, source_min_y_indx:
+                                source_max_y_indx, :].flatten()
+        block_targ = self.blocks[:, target_min_y_indx:
+                                 target_max_y_indx, :].flatten()
+        print(f"Source blocks: {block_src.shape}")
+
+        print(f"Target blocks: {block_targ.shape}")
+        for source_block in block_src:
+            for target_block in block_targ:
+                if source_block == target_block:
+                    continue
+                H = target_block.ampere_law(source_block)
+                total_H += H
+        return total_H
+
+    def show_field(self, log=False):
+        field = np.zeros((self.Xsize, self.Ysize))
+        for block in self.blocks.flatten():
+            field[block.ix, block.iy] = block.Hlocal
+        with plt.style.context(['nature', 'science']):
+            fig, ax = plt.subplots(dpi=300)
+
+            if log:
+                img = ax.pcolormesh(np.log(field).T, cmap='viridis')
+            else:
+                img = ax.pcolormesh(field.T, cmap='viridis')
+            # add colorbar
+            ax.set_xticklabels([
+                f"{x*1e9:.2f}"
+                for x in np.linspace(0, self.Xsize * self.dx, self.Xsize)
+            ])
+            ax.set_yticklabels([
+                f"{y*1e9:.2f}"
+                for y in np.linspace(0, self.Ysize * self.dy, self.Ysize)
+            ])
+            ax.set_xlabel("x (nm)")
+            ax.set_ylabel("y (nm)")
+            # add colorbar
+            for unq_border, label in zip(self.borders, self.labels):
+                ax.axhline(unq_border / self.dy, color='crimson')
+            fig.colorbar(img, ax=ax)
+        return field
```

## cmtj/utils/__init__.py

 * *Ordering differences only*

```diff
@@ -1,28 +1,28 @@
-import math
-
-from .filters import Filters
-from .general import VectorObj, box_muller_random, perturb_position
-from .linear import FieldScan
-from .resistance import *
-
-# constants
-OetoAm = 79.57747
-AmtoOe = 1.0 / OetoAm
-TtoAm = 795774.715459
-AmtoT = 1.0 / TtoAm
-echarge = -1.602e-19
-mu0 = 12.566e-7
-hplanck = 6.6260e-34
-hbar = hplanck / (2 * math.pi)
-gyromagnetic_ratio = 2.211e5
-gamma = 28024e6
-gamma_rad = 1.76e11
-me = 9.109e-31
-bohr_magneton = echarge * hbar / (2 * me)
-
-__all__ = [
-    "Filters", "FieldScan", "compute_sd", "compute_resistance",
-    "calculate_magnetoresistance", "calculate_resistance_series",
-    "calculate_resistance_parallel", "VectorObj", "box_muller_random",
-    "perturb_position"
-]
+import math
+
+from .filters import Filters
+from .general import VectorObj, box_muller_random, perturb_position
+from .linear import FieldScan
+from .resistance import *
+
+# constants
+OetoAm = 79.57747
+AmtoOe = 1.0 / OetoAm
+TtoAm = 795774.715459
+AmtoT = 1.0 / TtoAm
+echarge = -1.602e-19
+mu0 = 12.566e-7
+hplanck = 6.6260e-34
+hbar = hplanck / (2 * math.pi)
+gyromagnetic_ratio = 2.211e5
+gamma = 28024e6
+gamma_rad = 1.76e11
+me = 9.109e-31
+bohr_magneton = echarge * hbar / (2 * me)
+
+__all__ = [
+    "Filters", "FieldScan", "compute_sd", "compute_resistance",
+    "calculate_magnetoresistance", "calculate_resistance_series",
+    "calculate_resistance_parallel", "VectorObj", "box_muller_random",
+    "perturb_position"
+]
```

## cmtj/utils/energy.py

 * *Ordering differences only*

```diff
@@ -1,71 +1,71 @@
-from typing import Dict, List
-
-import numpy as np
-
-
-class EnergyCompute:
-    """Energy density in [J/m^3] computing functions"""
-
-    def __init__(self, cell_surface: float, thickness: float,
-                 log: Dict[str, List[float]]) -> None:
-        """Initialise energy computation class
-        :param cell_surface: surface of the cell in [m^2]
-        :param thickness: thickness of the cell in [m]
-        :param log: log of the simulation (directly from .getLog())"""
-        self.cell_surface = cell_surface
-        self.thickness = thickness
-        self.cell_volumne = self.cell_surface * thickness
-        self.log = log
-
-    def compute_from_log(self) -> Dict[str, List[float]]:
-        """
-        Computes a log of energies over time and returns it
-        in the same form of the
-        """
-        field_keys = list({k[:-1] for k in self.log if "_H" in k})
-        mag_k = (k.replace("_mx", "") for k in self.log if "_mx" in k)
-        mag_vectors = {
-            k: np.asarray([
-                self.log[f"{k}_mx"], self.log[f"{k}_my"], self.log[f"{k}_mz"]
-            ])
-            for k in mag_k
-        }
-        energy_data = {}
-        for field_key in field_keys:
-            if "J_" in field_key:
-                eng_fn = self.calculate_energy_from_field_interfacial
-            else:
-                eng_fn = self.calculate_energy_from_field
-
-            m_key = field_key.split("_")[0]  # get m key
-            m = mag_vectors[m_key]
-            field_series = np.asarray([
-                self.log[f"{field_key}x"],
-                self.log[f"{field_key}y"],
-                self.log[f"{field_key}z"],
-            ])
-            energy_data[f"energy_{field_key}"] = eng_fn(m, field_series)
-
-        return energy_data
-
-    def calculate_energy_from_field(self, m: np.ndarray,
-                                    field_vector: np.ndarray) -> np.ndarray:
-        """
-        :param m: magnetisation
-        :param field_vector: magnetic field vector (can be external, Oersted etc.)
-        Compute generic energy density
-        E = H * (mi0 Ms/V)
-        where mi0 Ms is in [T], Ms in [A/m], H in [A/m]
-        """
-        return -np.sum(m * field_vector, axis=0) / self.cell_volumne
-
-    def calculate_energy_from_field_interfacial(
-            self, m: np.ndarray, field_vector: np.ndarray) -> np.ndarray:
-        """
-        :param m: magnetisation
-        :param field_vector: magnetic field vector (can be IEC etc.)
-        Compute generic energy density
-        E = H * (mi0 Ms/A)
-        where mi0 Ms is in [T], Ms in [A/m], H in [A/m]
-        """
-        return -np.sum(m * field_vector, axis=0) / self.cell_surface
+from typing import Dict, List
+
+import numpy as np
+
+
+class EnergyCompute:
+    """Energy density in [J/m^3] computing functions"""
+
+    def __init__(self, cell_surface: float, thickness: float,
+                 log: Dict[str, List[float]]) -> None:
+        """Initialise energy computation class
+        :param cell_surface: surface of the cell in [m^2]
+        :param thickness: thickness of the cell in [m]
+        :param log: log of the simulation (directly from .getLog())"""
+        self.cell_surface = cell_surface
+        self.thickness = thickness
+        self.cell_volumne = self.cell_surface * thickness
+        self.log = log
+
+    def compute_from_log(self) -> Dict[str, List[float]]:
+        """
+        Computes a log of energies over time and returns it
+        in the same form of the
+        """
+        field_keys = list({k[:-1] for k in self.log if "_H" in k})
+        mag_k = (k.replace("_mx", "") for k in self.log if "_mx" in k)
+        mag_vectors = {
+            k: np.asarray([
+                self.log[f"{k}_mx"], self.log[f"{k}_my"], self.log[f"{k}_mz"]
+            ])
+            for k in mag_k
+        }
+        energy_data = {}
+        for field_key in field_keys:
+            if "J_" in field_key:
+                eng_fn = self.calculate_energy_from_field_interfacial
+            else:
+                eng_fn = self.calculate_energy_from_field
+
+            m_key = field_key.split("_")[0]  # get m key
+            m = mag_vectors[m_key]
+            field_series = np.asarray([
+                self.log[f"{field_key}x"],
+                self.log[f"{field_key}y"],
+                self.log[f"{field_key}z"],
+            ])
+            energy_data[f"energy_{field_key}"] = eng_fn(m, field_series)
+
+        return energy_data
+
+    def calculate_energy_from_field(self, m: np.ndarray,
+                                    field_vector: np.ndarray) -> np.ndarray:
+        """
+        :param m: magnetisation
+        :param field_vector: magnetic field vector (can be external, Oersted etc.)
+        Compute generic energy density
+        E = H * (mi0 Ms/V)
+        where mi0 Ms is in [T], Ms in [A/m], H in [A/m]
+        """
+        return -np.sum(m * field_vector, axis=0) / self.cell_volumne
+
+    def calculate_energy_from_field_interfacial(
+            self, m: np.ndarray, field_vector: np.ndarray) -> np.ndarray:
+        """
+        :param m: magnetisation
+        :param field_vector: magnetic field vector (can be IEC etc.)
+        Compute generic energy density
+        E = H * (mi0 Ms/A)
+        where mi0 Ms is in [T], Ms in [A/m], H in [A/m]
+        """
+        return -np.sum(m * field_vector, axis=0) / self.cell_surface
```

## cmtj/utils/filters.py

 * *Ordering differences only*

```diff
@@ -1,64 +1,64 @@
-from typing import Tuple
-
-import numpy as np
-from scipy.signal import butter, lfilter
-
-
-class Filters:
-
-    @staticmethod
-    def butter_bandpass_filter(data: np.ndarray,
-                               pass_freq: Tuple[float, float],
-                               fs: float,
-                               order: int = 5):
-        """Basic bandpass (notch) butterworth filter.
-        :param data: input data.
-        :param pass_freq: the tuple of (low, high) band frequencies.
-        :param fs: sampling frequency.
-        """
-        # Nyquist is half of the sampling freq
-        nyq = 0.5 * fs
-        if isinstance(pass_freq, float):
-            if pass_freq == 0:
-                pass_freq = 0.1
-                try:
-                    b, a = butter(
-                        order,
-                        [0.9 * pass_freq / nyq, pass_freq / nyq],
-                        btype="bandpass",
-                        analog=False,
-                    )
-                except ValueError as e:
-                    print(fs, pass_freq, nyq, 0.9 * pass_freq / nyq,
-                          pass_freq / nyq)
-                    raise ValueError("Error in filtering") from e
-        elif isinstance(pass_freq, tuple):
-            b, a = butter(order, [pass_freq[0], pass_freq[1]],
-                          btype="bandpass",
-                          analog=False)
-        return lfilter(b, a, data, zi=None)
-
-    @staticmethod
-    def butter_lowpass_filter(data: np.ndarray,
-                              cutoff: float,
-                              fs: float,
-                              order: int = 5):
-        """Low pass digital filter.
-        :param data: data to be filtered.
-        :param cutoff: cutoff frequency of the filter.
-        :param fs: sampling frequency.
-        :param order: order of the filter.
-        """
-        nyq = 0.5 * fs
-        normal_cutoff = cutoff / nyq
-        b, a = butter(order, normal_cutoff, btype="low", analog=False)
-        return lfilter(b, a, data, zi=None)
-
-    @staticmethod
-    def detrend_axis(arr, axis):
-        """Detrend axis for better spectrum visibility.
-        :param arr: input array (spectrum)
-        :param axis: axis along which to detrend
-        """
-        medians = np.median(arr, axis=axis)
-        return (arr.T - medians).T if axis else arr - medians
+from typing import Tuple
+
+import numpy as np
+from scipy.signal import butter, lfilter
+
+
+class Filters:
+
+    @staticmethod
+    def butter_bandpass_filter(data: np.ndarray,
+                               pass_freq: Tuple[float, float],
+                               fs: float,
+                               order: int = 5):
+        """Basic bandpass (notch) butterworth filter.
+        :param data: input data.
+        :param pass_freq: the tuple of (low, high) band frequencies.
+        :param fs: sampling frequency.
+        """
+        # Nyquist is half of the sampling freq
+        nyq = 0.5 * fs
+        if isinstance(pass_freq, float):
+            if pass_freq == 0:
+                pass_freq = 0.1
+                try:
+                    b, a = butter(
+                        order,
+                        [0.9 * pass_freq / nyq, pass_freq / nyq],
+                        btype="bandpass",
+                        analog=False,
+                    )
+                except ValueError as e:
+                    print(fs, pass_freq, nyq, 0.9 * pass_freq / nyq,
+                          pass_freq / nyq)
+                    raise ValueError("Error in filtering") from e
+        elif isinstance(pass_freq, tuple):
+            b, a = butter(order, [pass_freq[0], pass_freq[1]],
+                          btype="bandpass",
+                          analog=False)
+        return lfilter(b, a, data, zi=None)
+
+    @staticmethod
+    def butter_lowpass_filter(data: np.ndarray,
+                              cutoff: float,
+                              fs: float,
+                              order: int = 5):
+        """Low pass digital filter.
+        :param data: data to be filtered.
+        :param cutoff: cutoff frequency of the filter.
+        :param fs: sampling frequency.
+        :param order: order of the filter.
+        """
+        nyq = 0.5 * fs
+        normal_cutoff = cutoff / nyq
+        b, a = butter(order, normal_cutoff, btype="low", analog=False)
+        return lfilter(b, a, data, zi=None)
+
+    @staticmethod
+    def detrend_axis(arr, axis):
+        """Detrend axis for better spectrum visibility.
+        :param arr: input array (spectrum)
+        :param axis: axis along which to detrend
+        """
+        medians = np.median(arr, axis=axis)
+        return (arr.T - medians).T if axis else arr - medians
```

## cmtj/utils/general.py

 * *Ordering differences only*

```diff
@@ -1,108 +1,108 @@
-import math
-from dataclasses import dataclass
-from typing import Union
-
-import numpy as np
-
-from cmtj import CVector
-
-
-@dataclass
-class VectorObj:
-    """Vector object for standard manipulation.
-    Alternative to CVectors (which are used in the C++ code).
-    Easier to modify and manipulate, but slower.
-    :param theta: positive z-axis angle (in xz plane) in radians.
-    :param phi: positive x-axis (in xy plane) angle in radians
-    :param mag: magnitude of the vector, if not set defaults to 1 *unit vector*
-    """
-    theta: float  # in radians
-    phi: float  # rad
-    mag: float = 1
-
-    def __add__(self, other):
-        """Adds two vectors"""
-        return VectorObj.from_cvector(self.to_cvector() + other.to_cvector())
-
-    def __mul__(self, other: Union["VectorObj", float]):
-        """Multiplies a vector by a scalar"""
-        if isinstance(other, VectorObj):
-            return self._componentwise_mul(other)
-        return VectorObj.from_cvector(self.to_cvector() * other)
-
-    def __rmul__(self, other: Union["VectorObj", float]):
-        """Multiplies a vector by a scalar"""
-        return self.__mul__(other)
-
-    def __repr__(self) -> str:
-        return f"VectorObj(theta={self.theta}, phi={self.phi}, mag={self.mag})"
-
-    def __hash__(self) -> int:
-        return hash(str(self))
-
-    def __eq__(self, __value: "VectorObj") -> bool:
-        return self.theta == __value.theta and self.phi == __value.phi and self.mag == __value.mag
-
-    def _componentwise_mul(self, other):
-        coors = self.get_cartesian()
-        other_coords = other.get_cartesian()
-        return VectorObj.from_cartesian(
-            coors[0] * other_coords[0],
-            coors[1] * other_coords[1],
-            coors[2] * other_coords[2],
-        )
-
-    def get_cartesian(self):
-        """Returns the vector in Cartesian coordinates with (x, y, z) compnents"""
-        return VectorObj.from_spherical(self.theta, self.phi, self.mag)
-
-    @staticmethod
-    def from_spherical(theta, phi, mag=1):
-        """Creates a Cartesian vector from spherical components"""
-        return [
-            mag * math.sin(theta) * math.cos(phi),
-            mag * math.sin(theta) * math.sin(phi), mag * math.cos(theta)
-        ]
-
-    @staticmethod
-    def from_cartesian(x: float, y: float, z: float):
-        """Creates a spherical vector from Cartesian components"""
-        mag = math.sqrt(x**2 + y**2 + z**2)
-        theta = math.acos(z / mag)
-        phi = math.atan2(y, x)
-        return VectorObj(theta, phi, mag)
-
-    @staticmethod
-    def from_cvector(cvector: CVector):
-        """Creates a spherical vector from Cartesian components"""
-        mag = cvector.length()
-        theta = math.acos(cvector.z / mag)
-        phi = math.atan2(cvector.y, cvector.x)
-        return VectorObj(theta, phi, mag)
-
-    def to_cvector(self):
-        """Creates a Cartesian vector from spherical components"""
-        return CVector(*self.get_cartesian())
-
-
-def box_muller_random(mean, std):
-    """
-    Generates Gaussian noise with mean and standard deviation
-    using the Box-Muller transform.
-    https://en.wikipedia.org/wiki/Box–Muller_transform
-    :param mean: mean of the Gaussian.
-    :param std: standard deviation of the Gaussian.
-    """
-    u1 = np.random.uniform(0, 1)
-    u2 = np.random.uniform(0, 1)
-    mag = std * math.sqrt(-2.0 * math.log(u1))
-    z0 = mag * math.cos(2 * math.pi * u2) + mean
-    z1 = mag * math.sin(2 * math.pi * u2) + mean
-    return z0, z1
-
-
-def perturb_position(eq_point, pmax=1e-3):
-    """
-    Perturbs an equilibrium point by a random amount.
-    """
-    return np.asarray(eq_point) + np.random.normal(0, pmax, len(eq_point))
+import math
+from dataclasses import dataclass
+from typing import Union
+
+import numpy as np
+
+from cmtj import CVector
+
+
+@dataclass
+class VectorObj:
+    """Vector object for standard manipulation.
+    Alternative to CVectors (which are used in the C++ code).
+    Easier to modify and manipulate, but slower.
+    :param theta: positive z-axis angle (in xz plane) in radians.
+    :param phi: positive x-axis (in xy plane) angle in radians
+    :param mag: magnitude of the vector, if not set defaults to 1 *unit vector*
+    """
+    theta: float  # in radians
+    phi: float  # rad
+    mag: float = 1
+
+    def __add__(self, other):
+        """Adds two vectors"""
+        return VectorObj.from_cvector(self.to_cvector() + other.to_cvector())
+
+    def __mul__(self, other: Union["VectorObj", float]):
+        """Multiplies a vector by a scalar"""
+        if isinstance(other, VectorObj):
+            return self._componentwise_mul(other)
+        return VectorObj.from_cvector(self.to_cvector() * other)
+
+    def __rmul__(self, other: Union["VectorObj", float]):
+        """Multiplies a vector by a scalar"""
+        return self.__mul__(other)
+
+    def __repr__(self) -> str:
+        return f"VectorObj(theta={self.theta}, phi={self.phi}, mag={self.mag})"
+
+    def __hash__(self) -> int:
+        return hash(str(self))
+
+    def __eq__(self, __value: "VectorObj") -> bool:
+        return self.theta == __value.theta and self.phi == __value.phi and self.mag == __value.mag
+
+    def _componentwise_mul(self, other):
+        coors = self.get_cartesian()
+        other_coords = other.get_cartesian()
+        return VectorObj.from_cartesian(
+            coors[0] * other_coords[0],
+            coors[1] * other_coords[1],
+            coors[2] * other_coords[2],
+        )
+
+    def get_cartesian(self):
+        """Returns the vector in Cartesian coordinates with (x, y, z) compnents"""
+        return VectorObj.from_spherical(self.theta, self.phi, self.mag)
+
+    @staticmethod
+    def from_spherical(theta, phi, mag=1):
+        """Creates a Cartesian vector from spherical components"""
+        return [
+            mag * math.sin(theta) * math.cos(phi),
+            mag * math.sin(theta) * math.sin(phi), mag * math.cos(theta)
+        ]
+
+    @staticmethod
+    def from_cartesian(x: float, y: float, z: float):
+        """Creates a spherical vector from Cartesian components"""
+        mag = math.sqrt(x**2 + y**2 + z**2)
+        theta = math.acos(z / mag)
+        phi = math.atan2(y, x)
+        return VectorObj(theta, phi, mag)
+
+    @staticmethod
+    def from_cvector(cvector: CVector):
+        """Creates a spherical vector from Cartesian components"""
+        mag = cvector.length()
+        theta = math.acos(cvector.z / mag)
+        phi = math.atan2(cvector.y, cvector.x)
+        return VectorObj(theta, phi, mag)
+
+    def to_cvector(self):
+        """Creates a Cartesian vector from spherical components"""
+        return CVector(*self.get_cartesian())
+
+
+def box_muller_random(mean, std):
+    """
+    Generates Gaussian noise with mean and standard deviation
+    using the Box-Muller transform.
+    https://en.wikipedia.org/wiki/Box–Muller_transform
+    :param mean: mean of the Gaussian.
+    :param std: standard deviation of the Gaussian.
+    """
+    u1 = np.random.uniform(0, 1)
+    u2 = np.random.uniform(0, 1)
+    mag = std * math.sqrt(-2.0 * math.log(u1))
+    z0 = mag * math.cos(2 * math.pi * u2) + mean
+    z1 = mag * math.sin(2 * math.pi * u2) + mean
+    return z0, z1
+
+
+def perturb_position(eq_point, pmax=1e-3):
+    """
+    Perturbs an equilibrium point by a random amount.
+    """
+    return np.asarray(eq_point) + np.random.normal(0, pmax, len(eq_point))
```

## cmtj/utils/linear.py

 * *Ordering differences only*

```diff
@@ -1,124 +1,124 @@
-from typing import Tuple
-
-import numpy as np
-
-from cmtj import CVector
-
-
-class FieldScan:
-
-    @staticmethod
-    def _trig_compute(theta, phi) -> Tuple:
-        """Compute trigonometric functions for theta and phi.
-        :param theta: theta angle in [deg].
-        :param phi: phi angle in [deg].
-        :returns: trigonometric functions for theta and phi."""
-        st = np.sin(np.deg2rad(theta))
-        ct = np.cos(np.deg2rad(theta))
-        sp = np.sin(np.deg2rad(phi))
-        cp = np.cos(np.deg2rad(phi))
-        return st, ct, sp, cp
-
-    @staticmethod
-    def angle2vector(theta, phi, amplitude=1) -> CVector:
-        """Convert spherical coordinates to cartesian coordinates.
-        :param theta: polar angle in degrees.
-        :param phi: azimuthal angle in degrees.
-        :param amplitude: amplitude of target vector.
-        :returns: cartesian vector."""
-        st, ct, sp, cp = FieldScan._trig_compute(theta, phi)
-        return CVector(
-            st * cp * amplitude,
-            st * sp * amplitude,
-            ct * amplitude,
-        )
-
-    @staticmethod
-    def vector2angle(x, y, z) -> Tuple:
-        """Convert cartesian coordinates to spherical coordinates.
-        :param x: x coordinate of the vector.
-        :param y: y coordinate of the vector.
-        :param z: z coordinate of the vector.
-        :returns (theta, phi, r)
-        https://github.com/numpy/numpy/issues/5228
-        """
-        r = np.sqrt(x**2 + y**2 + z**2)
-        theta = np.rad2deg(np.arctan2(np.sqrt(x**2 + y**2), z))
-        phi = np.rad2deg(np.arctan2(y, x))
-        return theta, phi, r
-
-    @staticmethod
-    def cvector2angle(vector: CVector) -> Tuple:
-        """
-        :param vector: cartesian vector.
-        :returns (theta, phi, r)
-        https://github.com/numpy/numpy/issues/5228
-        """
-        return FieldScan.vector2angle(vector.x, vector.y, vector.z)
-
-    @staticmethod
-    def amplitude_scan(
-        start: float,
-        stop: float,
-        steps: int,
-        theta: float,
-        phi: float,
-        back: bool = False,
-    ) -> Tuple[np.ndarray, np.ndarray]:
-        """
-        Compute a linear magnitude sweep. Angles given in deg.
-        :param start: start of the sweep
-        :param stop: end of the sweep
-        :param steps: number of steps
-        :param theta: polar angle in deg.
-        :param phi: azimuthal angle in deg.
-        :returns: linear amplitude, field vectors
-        """
-        Hspan = np.linspace(start, stop, endpoint=True, num=steps)
-        st, ct, sp, cp = FieldScan._trig_compute(theta, phi)
-        Hx = st * cp * Hspan
-        Hy = st * sp * Hspan
-        Hz = ct * Hspan
-        if back:
-            forward = np.vstack((Hx, Hy, Hz)).T
-            back = forward[::-1]
-            return np.concatenate((Hspan, Hspan[::-1]),
-                                  axis=0), np.concatenate((forward, back),
-                                                          axis=0)
-        return Hspan, np.vstack((Hx, Hy, Hz)).T
-
-    @staticmethod
-    def theta_scan(start: float, stop: float, steps: int, amplitude: float,
-                   phi: float) -> Tuple[np.ndarray, np.ndarray]:
-        """
-        Compute a linear theta angle sweep. Angles given in deg.
-        :param start: polar angle start of the sweep
-        :param stop: polar angle end of the sweep
-        :param steps: number of steps
-        :param amplitude: amplitude of the scanned field.
-        :param phi: azimuthal angle in deg.
-        """
-        theta_span = np.linspace(start, stop, endpoint=True, num=steps)
-        st, ct, sp, cp = FieldScan._trig_compute(theta_span, phi)
-        Hx = st * cp * amplitude
-        Hy = st * sp * amplitude
-        Hz = ct * amplitude
-        return theta_span, np.vstack((Hx, Hy, Hz)).T
-
-    @staticmethod
-    def phi_scan(start: float, stop: float, steps: int, amplitude: float,
-                 theta: float) -> Tuple[np.ndarray, np.ndarray]:
-        """
-        Compute a linear phi angle sweep. Angles given in deg.
-        :param start: azimuthal angle start of the sweep
-        :param stop: azimuthal angle end of the sweep
-        :param steps: number of steps
-        :param amplitude: amplitude of the scanned field
-        :param theta: polar angle in deg.
-        """
-        phi_span = np.linspace(start, stop, endpoint=True, num=steps)
-        st, ct, sp, cp = FieldScan._trig_compute(theta, phi_span)
-        Hx = st * cp * amplitude
-        Hy = st * sp * amplitude
-        Hz = ct * amplitude * np.ones_like(Hy)
-        return phi_span, np.vstack((Hx, Hy, Hz)).T
+from typing import Tuple
+
+import numpy as np
+
+from cmtj import CVector
+
+
+class FieldScan:
+
+    @staticmethod
+    def _trig_compute(theta, phi) -> Tuple:
+        """Compute trigonometric functions for theta and phi.
+        :param theta: theta angle in [deg].
+        :param phi: phi angle in [deg].
+        :returns: trigonometric functions for theta and phi."""
+        st = np.sin(np.deg2rad(theta))
+        ct = np.cos(np.deg2rad(theta))
+        sp = np.sin(np.deg2rad(phi))
+        cp = np.cos(np.deg2rad(phi))
+        return st, ct, sp, cp
+
+    @staticmethod
+    def angle2vector(theta, phi, amplitude=1) -> CVector:
+        """Convert spherical coordinates to cartesian coordinates.
+        :param theta: polar angle in degrees.
+        :param phi: azimuthal angle in degrees.
+        :param amplitude: amplitude of target vector.
+        :returns: cartesian vector."""
+        st, ct, sp, cp = FieldScan._trig_compute(theta, phi)
+        return CVector(
+            st * cp * amplitude,
+            st * sp * amplitude,
+            ct * amplitude,
+        )
+
+    @staticmethod
+    def vector2angle(x, y, z) -> Tuple:
+        """Convert cartesian coordinates to spherical coordinates.
+        :param x: x coordinate of the vector.
+        :param y: y coordinate of the vector.
+        :param z: z coordinate of the vector.
+        :returns (theta, phi, r)
+        https://github.com/numpy/numpy/issues/5228
+        """
+        r = np.sqrt(x**2 + y**2 + z**2)
+        theta = np.rad2deg(np.arctan2(np.sqrt(x**2 + y**2), z))
+        phi = np.rad2deg(np.arctan2(y, x))
+        return theta, phi, r
+
+    @staticmethod
+    def cvector2angle(vector: CVector) -> Tuple:
+        """
+        :param vector: cartesian vector.
+        :returns (theta, phi, r)
+        https://github.com/numpy/numpy/issues/5228
+        """
+        return FieldScan.vector2angle(vector.x, vector.y, vector.z)
+
+    @staticmethod
+    def amplitude_scan(
+        start: float,
+        stop: float,
+        steps: int,
+        theta: float,
+        phi: float,
+        back: bool = False,
+    ) -> Tuple[np.ndarray, np.ndarray]:
+        """
+        Compute a linear magnitude sweep. Angles given in deg.
+        :param start: start of the sweep
+        :param stop: end of the sweep
+        :param steps: number of steps
+        :param theta: polar angle in deg.
+        :param phi: azimuthal angle in deg.
+        :returns: linear amplitude, field vectors
+        """
+        Hspan = np.linspace(start, stop, endpoint=True, num=steps)
+        st, ct, sp, cp = FieldScan._trig_compute(theta, phi)
+        Hx = st * cp * Hspan
+        Hy = st * sp * Hspan
+        Hz = ct * Hspan
+        if back:
+            forward = np.vstack((Hx, Hy, Hz)).T
+            back = forward[::-1]
+            return np.concatenate((Hspan, Hspan[::-1]),
+                                  axis=0), np.concatenate((forward, back),
+                                                          axis=0)
+        return Hspan, np.vstack((Hx, Hy, Hz)).T
+
+    @staticmethod
+    def theta_scan(start: float, stop: float, steps: int, amplitude: float,
+                   phi: float) -> Tuple[np.ndarray, np.ndarray]:
+        """
+        Compute a linear theta angle sweep. Angles given in deg.
+        :param start: polar angle start of the sweep
+        :param stop: polar angle end of the sweep
+        :param steps: number of steps
+        :param amplitude: amplitude of the scanned field.
+        :param phi: azimuthal angle in deg.
+        """
+        theta_span = np.linspace(start, stop, endpoint=True, num=steps)
+        st, ct, sp, cp = FieldScan._trig_compute(theta_span, phi)
+        Hx = st * cp * amplitude
+        Hy = st * sp * amplitude
+        Hz = ct * amplitude
+        return theta_span, np.vstack((Hx, Hy, Hz)).T
+
+    @staticmethod
+    def phi_scan(start: float, stop: float, steps: int, amplitude: float,
+                 theta: float) -> Tuple[np.ndarray, np.ndarray]:
+        """
+        Compute a linear phi angle sweep. Angles given in deg.
+        :param start: azimuthal angle start of the sweep
+        :param stop: azimuthal angle end of the sweep
+        :param steps: number of steps
+        :param amplitude: amplitude of the scanned field
+        :param theta: polar angle in deg.
+        """
+        phi_span = np.linspace(start, stop, endpoint=True, num=steps)
+        st, ct, sp, cp = FieldScan._trig_compute(theta, phi_span)
+        Hx = st * cp * amplitude
+        Hy = st * sp * amplitude
+        Hz = ct * amplitude * np.ones_like(Hy)
+        return phi_span, np.vstack((Hx, Hy, Hz)).T
```

## cmtj/utils/optimization.py

 * *Ordering differences only*

```diff
@@ -1,107 +1,107 @@
-from concurrent.futures import ProcessPoolExecutor
-from typing import Callable, Dict, List
-
-import numpy as np
-from tqdm import tqdm
-
-
-def coordinate_descent(
-    operating_point: Dict[str, float],
-    fn: Callable,
-    best_mse: float = float("-inf"),
-    granularity: int = 10,
-    percentage: float = 0.05,
-):
-    """Performs coordinate descent on the operating point.
-    :param operating_point: operating point to be optimised. Order of that dict matters.
-    :param fn: function to be optimised
-    :param best_mse: best mse so far
-    :param granularity: granularity of the search
-    :param percentage: percentage of the search
-    :returns: best operating point, best mse
-    """
-    opt_params = operating_point
-    for k, org_v in tqdm(operating_point.items(), desc="Coordinate descent"):
-        new_params = operating_point.copy()
-        for v in tqdm(
-                np.linspace((1 - percentage) * org_v, (1 + percentage) * org_v,
-                            granularity),
-                desc=f"Optimising {k}",
-                leave=False,
-        ):
-            new_params[k] = v
-            mse = fn(**new_params)
-            if mse > best_mse:
-                opt_params = new_params
-                best_mse = mse
-    return opt_params, best_mse
-
-
-def multiprocess_simulate(
-    fn: Callable,
-    error_fn: Callable,
-    suggestions: List[dict],
-    target: np.ndarray,
-    fixed_parameters: dict,
-):
-    with ProcessPoolExecutor(max_workers=len(suggestions)) as executor:
-        futures = [
-            executor.submit(
-                fn,
-                **fixed_parameters,
-                **suggestion,
-            ) for suggestion in suggestions
-        ]
-        errors = np.zeros(len(suggestions))
-        for j, future in enumerate(futures):
-            result = future.result()
-            errors[j] = error_fn(target, result)
-    return errors
-
-
-def hebo_optimization_loop(
-    cfg: dict,
-    fn: Callable,
-    error_fn: Callable,
-    target: np.ndarray,
-    fixed_parameters: dict,
-    n_iters: int = 150,
-    n_suggestions: int = 8,
-):
-    """Optimizes the parameters of a function using HEBO.
-    See HEBO documentation for more details: https://github.com/huawei-noah/HEBO
-    :param cfg: configuration of the design space
-    :param fn: function to be optimised fn(**parameters, **fixed_parameters)
-    :param error_fn: function to compute the error: error_fn(target, result)
-    :param target: target data
-    :param fixed_parameters: parameters that are fixed
-    :param n_iters: number of iterations
-    :param n_suggestions: number of suggestions per iteration
-    """
-    try:
-        from hebo.design_space.design_space import DesignSpace
-        from hebo.optimizers.hebo import HEBO
-    except ImportError as e:
-        raise ImportError(
-            "HEBO is not installed. Please install it with `pip install HEBO`"
-        ) from e
-    space = DesignSpace().parse(cfg)
-    opt = HEBO(space)
-    best_mse = float("inf")
-    for i in tqdm(range(1, n_iters + 1), desc="HEBO optimization loop"):
-        rec = opt.suggest(n_suggestions)
-        errors = multiprocess_simulate(
-            fn=fn,
-            error_fn=error_fn,
-            suggestions=rec.to_dict(orient="records"),
-            target=target,
-            fixed_parameters=fixed_parameters,
-        )
-        opt.observe(rec, errors)
-        val = opt.y.min()
-        if val < best_mse:
-            best_mse = val
-            best_params = opt.best_x.iloc[0].to_dict()
-            print(f"iteration {i} best mse {best_mse}")
-            print(best_params)
-    return opt
+from concurrent.futures import ProcessPoolExecutor
+from typing import Callable, Dict, List
+
+import numpy as np
+from tqdm import tqdm
+
+
+def coordinate_descent(
+    operating_point: Dict[str, float],
+    fn: Callable,
+    best_mse: float = float("-inf"),
+    granularity: int = 10,
+    percentage: float = 0.05,
+):
+    """Performs coordinate descent on the operating point.
+    :param operating_point: operating point to be optimised. Order of that dict matters.
+    :param fn: function to be optimised
+    :param best_mse: best mse so far
+    :param granularity: granularity of the search
+    :param percentage: percentage of the search
+    :returns: best operating point, best mse
+    """
+    opt_params = operating_point
+    for k, org_v in tqdm(operating_point.items(), desc="Coordinate descent"):
+        new_params = operating_point.copy()
+        for v in tqdm(
+                np.linspace((1 - percentage) * org_v, (1 + percentage) * org_v,
+                            granularity),
+                desc=f"Optimising {k}",
+                leave=False,
+        ):
+            new_params[k] = v
+            mse = fn(**new_params)
+            if mse > best_mse:
+                opt_params = new_params
+                best_mse = mse
+    return opt_params, best_mse
+
+
+def multiprocess_simulate(
+    fn: Callable,
+    error_fn: Callable,
+    suggestions: List[dict],
+    target: np.ndarray,
+    fixed_parameters: dict,
+):
+    with ProcessPoolExecutor(max_workers=len(suggestions)) as executor:
+        futures = [
+            executor.submit(
+                fn,
+                **fixed_parameters,
+                **suggestion,
+            ) for suggestion in suggestions
+        ]
+        errors = np.zeros(len(suggestions))
+        for j, future in enumerate(futures):
+            result = future.result()
+            errors[j] = error_fn(target, result)
+    return errors
+
+
+def hebo_optimization_loop(
+    cfg: dict,
+    fn: Callable,
+    error_fn: Callable,
+    target: np.ndarray,
+    fixed_parameters: dict,
+    n_iters: int = 150,
+    n_suggestions: int = 8,
+):
+    """Optimizes the parameters of a function using HEBO.
+    See HEBO documentation for more details: https://github.com/huawei-noah/HEBO
+    :param cfg: configuration of the design space
+    :param fn: function to be optimised fn(**parameters, **fixed_parameters)
+    :param error_fn: function to compute the error: error_fn(target, result)
+    :param target: target data
+    :param fixed_parameters: parameters that are fixed
+    :param n_iters: number of iterations
+    :param n_suggestions: number of suggestions per iteration
+    """
+    try:
+        from hebo.design_space.design_space import DesignSpace
+        from hebo.optimizers.hebo import HEBO
+    except ImportError as e:
+        raise ImportError(
+            "HEBO is not installed. Please install it with `pip install HEBO`"
+        ) from e
+    space = DesignSpace().parse(cfg)
+    opt = HEBO(space)
+    best_mse = float("inf")
+    for i in tqdm(range(1, n_iters + 1), desc="HEBO optimization loop"):
+        rec = opt.suggest(n_suggestions)
+        errors = multiprocess_simulate(
+            fn=fn,
+            error_fn=error_fn,
+            suggestions=rec.to_dict(orient="records"),
+            target=target,
+            fixed_parameters=fixed_parameters,
+        )
+        opt.observe(rec, errors)
+        val = opt.y.min()
+        if val < best_mse:
+            best_mse = val
+            best_params = opt.best_x.iloc[0].to_dict()
+            print(f"iteration {i} best mse {best_mse}")
+            print(best_params)
+    return opt
```

## cmtj/utils/parallel.py

 * *Ordering differences only*

```diff
@@ -1,48 +1,48 @@
-from itertools import product
-from typing import Callable, List
-
-import numpy as np
-from multiprocess import Pool
-from tqdm import tqdm
-
-__all__ = ["distribute"]
-
-
-def distribute(simulation_fn: Callable,
-               spaces: List[List[float]],
-               n_cores: int = None,
-               shuffle: bool = False):
-    """
-    Distribute a function over a list of parameters in parallel.
-    :param simulation_fn: function to be distributed
-    :param spaces: list of lists of parameters
-    :param n_cores: number of cores to use.
-    :returns: index, simulation_fn output
-    """
-    spaces = [np.asarray(space) for space in spaces]
-
-    def _get_index(values):
-        return [
-            np.argwhere(space == values[i]).ravel()[0]
-            for i, space in enumerate(spaces)
-        ]
-
-    iterables = list(product(*spaces))
-    indexes = [_get_index(val) for val in iterables]
-    # shuffle the indexes
-    if shuffle:
-        index_reshuffle = np.arange(len(indexes))
-        np.random.shuffle(index_reshuffle)
-        # reorder the indexes
-        iterables = np.asarray(iterables)[index_reshuffle].tolist()
-        indexes = np.asarray(indexes)[index_reshuffle].tolist()
-
-    def func_wrapper(iterable):
-        return iterable, simulation_fn(*iterable)
-
-    with Pool(processes=n_cores) as pool:
-        for result in tqdm(pool.imap_unordered(func_wrapper, iterables),
-                           total=len(iterables)):
-            iterable, output = result
-            indx = indexes[iterables.index(iterable)]
-            yield indx, output
+from itertools import product
+from typing import Callable, List
+
+import numpy as np
+from multiprocess import Pool
+from tqdm import tqdm
+
+__all__ = ["distribute"]
+
+
+def distribute(simulation_fn: Callable,
+               spaces: List[List[float]],
+               n_cores: int = None,
+               shuffle: bool = False):
+    """
+    Distribute a function over a list of parameters in parallel.
+    :param simulation_fn: function to be distributed
+    :param spaces: list of lists of parameters
+    :param n_cores: number of cores to use.
+    :returns: index, simulation_fn output
+    """
+    spaces = [np.asarray(space) for space in spaces]
+
+    def _get_index(values):
+        return [
+            np.argwhere(space == values[i]).ravel()[0]
+            for i, space in enumerate(spaces)
+        ]
+
+    iterables = list(product(*spaces))
+    indexes = [_get_index(val) for val in iterables]
+    # shuffle the indexes
+    if shuffle:
+        index_reshuffle = np.arange(len(indexes))
+        np.random.shuffle(index_reshuffle)
+        # reorder the indexes
+        iterables = np.asarray(iterables)[index_reshuffle].tolist()
+        indexes = np.asarray(indexes)[index_reshuffle].tolist()
+
+    def func_wrapper(iterable):
+        return iterable, simulation_fn(*iterable)
+
+    with Pool(processes=n_cores) as pool:
+        for result in tqdm(pool.imap_unordered(func_wrapper, iterables),
+                           total=len(iterables)):
+            iterable, output = result
+            indx = indexes[iterables.index(iterable)]
+            yield indx, output
```

## cmtj/utils/plotting.py

 * *Ordering differences only*

```diff
@@ -1,298 +1,298 @@
-from itertools import permutations
-
-import matplotlib.patches as patches
-import matplotlib.pyplot as plt
-import numpy as np
-import seaborn as sns
-from mpl_toolkits.mplot3d.art3d import Line3DCollection
-
-
-def get_sphere():
-    r = 1
-    pi = np.pi
-    cos = np.cos
-    sin = np.sin
-    phi, theta = np.mgrid[0.0:pi:100j, 0.0:2.0 * pi:100j]
-    xs = r * sin(phi) * cos(theta)
-    ys = r * sin(phi) * sin(theta)
-    zs = r * cos(phi)
-    return xs, ys, zs
-
-
-def plot_trajectory_sphere(x, y, z, color='blue', alpha=1, ax=None):
-    """Plot a trajectory in 3D. Normalises to unit sphere
-    :param ax: matplotlib axis
-    :param x: x-coordinates
-    :param y: y-coordinates
-    :param z: z-coordinates
-    :param color: color of the trajectory
-    :param alpha: alpha value of the trajectory
-    """
-    # Compute a unit sphere first
-    xs, ys, zs = get_sphere()
-    m = np.asarray([x, y, z])
-    # make sure we are unit norm for m
-    m = m / np.linalg.norm(m)
-    if ax is None:
-        with plt.style.context(['science', 'nature']):
-            fig = plt.figure(dpi=300)
-            ax = fig.add_subplot(1, 1, 1, projection='3d')
-            ax.plot3D(m[0], m[1], m[2], color=color, alpha=alpha)
-            ax.set_axis_off()
-            ax.plot_surface(xs,
-                            ys,
-                            zs,
-                            rstride=2,
-                            cstride=2,
-                            color='azure',
-                            alpha=0.1,
-                            linewidth=0.1)
-            ax.scatter([0], [0], [1], color='crimson', alpha=1.0)
-    else:
-        ax.plot3D(m[0], m[1], m[2], color=color, alpha=alpha)
-        ax.set_axis_off()
-        ax.plot_surface(xs,
-                        ys,
-                        zs,
-                        rstride=2,
-                        cstride=2,
-                        color='azure',
-                        alpha=0.1,
-                        linewidth=0.1)
-        ax.scatter([0], [0], [1], color='crimson', alpha=1.0)
-
-
-def plot_coloured_trajectory(x, y, z, colormap='plasma', ax=None):
-    """Plot a coloured trajectory in 3D. Normalises to unit sphere.
-    Colour of the trajectory now designates the flow of time.
-    :param ax: matplotlib axis
-    :param x: x-coordinates
-    :param y: y-coordinates
-    :param z: z-coordinates
-    :param colormap: colormap to use
-    """
-    xs, ys, zs = get_sphere()
-    m = np.asarray([x, y, z])
-    points = m.T.reshape(-1, 1, 3)
-    segs = np.concatenate([points[:-1], points[1:]], axis=1)
-    colors = sns.color_palette(colormap, len(segs))
-    if ax is None:
-        with plt.style.context(['science', 'nature']):
-            fig = plt.figure(dpi=300)
-            ax = fig.add_subplot(1, 1, 1, projection='3d')
-            # plot the sphere firext
-            ax.set_axis_off()
-            ax.plot_surface(xs,
-                            ys,
-                            zs,
-                            rstride=2,
-                            cstride=2,
-                            color='azure',
-                            alpha=0.1,
-                            linewidth=0.1)
-            ax.add_collection(Line3DCollection(segs, colors=colors, alpha=1))
-    else:
-        ax.set_axis_off()
-        ax.plot_surface(xs,
-                        ys,
-                        zs,
-                        rstride=2,
-                        cstride=2,
-                        color='azure',
-                        alpha=0.1,
-                        linewidth=0.1)
-        ax.add_collection(Line3DCollection(segs, colors=colors, alpha=1))
-
-
-def unpack_ndim_map(map, axes):
-    """
-    Unpack N-dimensional map into a list of 1-dimensional arrays
-    :param map: N-dimensional map, each axis is separate parameter space.
-    :param axes: list of axes to unpack.
-    """
-    # how long each one is
-    sample_length = len(axes[0])
-    perm_indx = permutations(range(sample_length), len(axes))
-
-    ax_lists = [[] for _ in axes]
-    value_list = []
-    for indx in perm_indx:
-        value_list.append(map[indx])
-        for i, ax in enumerate(axes):
-            ax_lists[i].append(ax[indx[i]])
-
-    return ax_lists, value_list
-
-
-def create_coordinates_plot(axes,
-                            ax_names,
-                            result_map,
-                            sample=0,
-                            alpha_black=0.01):
-    """Create parallel coordinates plot for multidimensional parameter space.
-    Modified from:
-    https://stackoverflow.com/questions/8230638/parallel-coordinates-plot-in-matplotlib
-    :param axes: N list of parameters
-    :param ax_names: N list of parameter names
-    :param result_map: map of values (N-dim)
-    :param sample: if != 0, subsample the parameter space
-    :param alpha_black: alpha value zero value
-    """
-    import matplotlib
-    import matplotlib.cm as cm
-    import matplotlib.patches as patches
-    from matplotlib.path import Path
-    with plt.style.context(['science', 'nature']):
-        fig, host = plt.subplots(dpi=400)
-        ax_lists, value_list = unpack_ndim_map(result_map, axes)
-
-        norm = matplotlib.colors.Normalize(vmin=min(value_list),
-                                           vmax=max(value_list),
-                                           clip=True)
-        mapper = cm.ScalarMappable(norm=norm, cmap=cm.magma)
-
-        # organize the data
-        ys = np.dstack([*ax_lists, value_list])[0]
-        indices = np.arange(len(ys))
-        if sample:
-            indices = np.random.choice(indices, sample).ravel()
-        ys = ys[indices]
-
-        ymins = ys.min(axis=0)
-        ymaxs = ys.max(axis=0)
-        dys = ymaxs - ymins
-        ymins -= dys * 0.05  # add 5% padding below and above
-        ymaxs += dys * 0.05
-        dys = ymaxs - ymins
-
-        # transform all data to be compatible with the main axis
-        zs = np.zeros_like(ys)
-        zs[:, 0] = ys[:, 0]
-        zs[:, 1:] = (ys[:, 1:] - ymins[1:]) / dys[1:] * dys[0] + ymins[0]
-
-        axes = [host] + [host.twinx() for _ in range(ys.shape[1] - 1)]
-        for i, ax in enumerate(axes):
-            ax.set_ylim(ymins[i], ymaxs[i])
-            ax.spines['top'].set_visible(False)
-            ax.spines['bottom'].set_visible(False)
-            if ax != host:
-                ax.spines['left'].set_visible(False)
-                ax.yaxis.set_ticks_position('right')
-                ax.spines["right"].set_position(
-                    ("axes", i / (ys.shape[1] - 1)))
-
-        host.set_xlim(0, ys.shape[1] - 1)
-        host.set_xticks(range(ys.shape[1]))
-        host.set_xticklabels(ax_names, fontsize=8)
-        host.tick_params(axis='x', which='major', pad=7)
-        host.spines['right'].set_visible(False)
-        host.xaxis.tick_top()
-        host.set_title('Parallel Coordinates Plot')
-
-        for j in range(ys.shape[0]):
-            # create bezier curves
-            # for each axis, there will a control vertex at the point itself, one at 1/3rd towards the previous and one
-            #   at one third towards the next axis; the first and last axis have one less control vertex
-            # x-coordinate of the control vertices: at each integer (for the axes) and two inbetween
-            # y-coordinate: repeat every point three times, except the first and last only twice
-            verts = list(
-                zip(
-                    list(
-                        np.linspace(
-                            0, len(ys) - 1, len(ys) * 3 - 2, endpoint=True
-                        )
-                    ),
-                    np.repeat(zs[j, :], 3)[1:-1],
-                )
-            )
-            # for x,y in verts: host.plot(x, y, 'go') # to show the control points of the beziers
-            codes = [Path.MOVETO
-                     ] + [Path.CURVE4 for _ in range(len(verts) - 1)]
-            path = Path(verts, codes)
-            alpha = alpha_black if ys[j, -1] == 0 else 0.8
-            patch = patches.PathPatch(path,
-                                      facecolor='none',
-                                      lw=.5,
-                                      edgecolor=mapper.to_rgba(
-                                          ys[j, -1], alpha))
-            host.add_patch(patch)
-        fig.tight_layout()
-
-
-def rotation_matrix(theta):
-    return np.array([[np.cos(theta), -np.sin(theta)],
-                     [np.sin(theta), np.cos(theta)]])
-
-
-def create_stack(ax,
-                 colors,
-                 heights,
-                 angles,
-                 labels,
-                 width=2,
-                 labelpad_left=.2,
-                 offset_x=0,
-                 offset_y=0,
-                 lw_arrow=1.5,
-                 ms=10,
-                 r=0.6,
-                 text_fontsize=4,
-                 reversed=True):
-    """
-    Create a material stack plot.
-    If a given layer is to have no arrow, pass None.
-    :param ax: matplotlib axis
-    :param colors: list of colors
-    :param heights: list of heights
-    :param angles: list of angles
-    :param labels: list of labels
-    :param width: width of the bars
-    :param labelpad_left: padding of the labels
-    :param offset_x: offset of the patches in x direction
-    :param offset_y: offset of the patches in y direction
-    :param lw_arrow: linewidth of the arrows
-    :param ms: mutation size of the arrows
-    :param r: length of the arrows
-    :param reversed: if True, the stack is reversed
-    """
-    [x, y] = [r, 0]
-    first_offset = offset_y
-    if reversed:
-        heights = heights[::-1]
-        colors = colors[::-1]
-        angles = angles[::-1]
-        labels = labels[::-1]
-    for i, (height, angle, color,
-            label) in enumerate(zip(heights, angles, colors, labels)):
-        ax.add_patch(
-            patches.Rectangle((offset_x, offset_y),
-                              width,
-                              height,
-                              fill=True,
-                              color=color,
-                              zorder=10))
-        ax.text(offset_x - labelpad_left,
-                offset_y + height / 2,
-                label,
-                horizontalalignment='center',
-                verticalalignment='center',
-                fontsize=text_fontsize,
-                zorder=11)
-        if angle is not None:
-            [dx, dy] = np.dot(rotation_matrix(np.deg2rad(angle)), [x, y])
-            x_mid = dx / 2
-            y_mid = dy / 2
-            centre_x = (offset_x + width) / 2 - x_mid
-            centre_y = offset_y + height / 2 - y_mid
-            ax.add_patch(
-                patches.FancyArrowPatch((centre_x, centre_y),
-                                        (centre_x + dx, centre_y + dy),
-                                        mutation_scale=ms,
-                                        lw=lw_arrow,
-                                        color='black',
-                                        zorder=10))
-        offset_y += height
-    ax.set_ylim([first_offset - max(heights) / 2, offset_y + max(heights) / 2])
-    ax.set_xlim([offset_x - width / 2, offset_x + width + width / 2])
-    ax.axis("off")
-    return ax
+from itertools import permutations
+
+import matplotlib.patches as patches
+import matplotlib.pyplot as plt
+import numpy as np
+import seaborn as sns
+from mpl_toolkits.mplot3d.art3d import Line3DCollection
+
+
+def get_sphere():
+    r = 1
+    pi = np.pi
+    cos = np.cos
+    sin = np.sin
+    phi, theta = np.mgrid[0.0:pi:100j, 0.0:2.0 * pi:100j]
+    xs = r * sin(phi) * cos(theta)
+    ys = r * sin(phi) * sin(theta)
+    zs = r * cos(phi)
+    return xs, ys, zs
+
+
+def plot_trajectory_sphere(x, y, z, color='blue', alpha=1, ax=None):
+    """Plot a trajectory in 3D. Normalises to unit sphere
+    :param ax: matplotlib axis
+    :param x: x-coordinates
+    :param y: y-coordinates
+    :param z: z-coordinates
+    :param color: color of the trajectory
+    :param alpha: alpha value of the trajectory
+    """
+    # Compute a unit sphere first
+    xs, ys, zs = get_sphere()
+    m = np.asarray([x, y, z])
+    # make sure we are unit norm for m
+    m = m / np.linalg.norm(m)
+    if ax is None:
+        with plt.style.context(['science', 'nature']):
+            fig = plt.figure(dpi=300)
+            ax = fig.add_subplot(1, 1, 1, projection='3d')
+            ax.plot3D(m[0], m[1], m[2], color=color, alpha=alpha)
+            ax.set_axis_off()
+            ax.plot_surface(xs,
+                            ys,
+                            zs,
+                            rstride=2,
+                            cstride=2,
+                            color='azure',
+                            alpha=0.1,
+                            linewidth=0.1)
+            ax.scatter([0], [0], [1], color='crimson', alpha=1.0)
+    else:
+        ax.plot3D(m[0], m[1], m[2], color=color, alpha=alpha)
+        ax.set_axis_off()
+        ax.plot_surface(xs,
+                        ys,
+                        zs,
+                        rstride=2,
+                        cstride=2,
+                        color='azure',
+                        alpha=0.1,
+                        linewidth=0.1)
+        ax.scatter([0], [0], [1], color='crimson', alpha=1.0)
+
+
+def plot_coloured_trajectory(x, y, z, colormap='plasma', ax=None):
+    """Plot a coloured trajectory in 3D. Normalises to unit sphere.
+    Colour of the trajectory now designates the flow of time.
+    :param ax: matplotlib axis
+    :param x: x-coordinates
+    :param y: y-coordinates
+    :param z: z-coordinates
+    :param colormap: colormap to use
+    """
+    xs, ys, zs = get_sphere()
+    m = np.asarray([x, y, z])
+    points = m.T.reshape(-1, 1, 3)
+    segs = np.concatenate([points[:-1], points[1:]], axis=1)
+    colors = sns.color_palette(colormap, len(segs))
+    if ax is None:
+        with plt.style.context(['science', 'nature']):
+            fig = plt.figure(dpi=300)
+            ax = fig.add_subplot(1, 1, 1, projection='3d')
+            # plot the sphere firext
+            ax.set_axis_off()
+            ax.plot_surface(xs,
+                            ys,
+                            zs,
+                            rstride=2,
+                            cstride=2,
+                            color='azure',
+                            alpha=0.1,
+                            linewidth=0.1)
+            ax.add_collection(Line3DCollection(segs, colors=colors, alpha=1))
+    else:
+        ax.set_axis_off()
+        ax.plot_surface(xs,
+                        ys,
+                        zs,
+                        rstride=2,
+                        cstride=2,
+                        color='azure',
+                        alpha=0.1,
+                        linewidth=0.1)
+        ax.add_collection(Line3DCollection(segs, colors=colors, alpha=1))
+
+
+def unpack_ndim_map(map, axes):
+    """
+    Unpack N-dimensional map into a list of 1-dimensional arrays
+    :param map: N-dimensional map, each axis is separate parameter space.
+    :param axes: list of axes to unpack.
+    """
+    # how long each one is
+    sample_length = len(axes[0])
+    perm_indx = permutations(range(sample_length), len(axes))
+
+    ax_lists = [[] for _ in axes]
+    value_list = []
+    for indx in perm_indx:
+        value_list.append(map[indx])
+        for i, ax in enumerate(axes):
+            ax_lists[i].append(ax[indx[i]])
+
+    return ax_lists, value_list
+
+
+def create_coordinates_plot(axes,
+                            ax_names,
+                            result_map,
+                            sample=0,
+                            alpha_black=0.01):
+    """Create parallel coordinates plot for multidimensional parameter space.
+    Modified from:
+    https://stackoverflow.com/questions/8230638/parallel-coordinates-plot-in-matplotlib
+    :param axes: N list of parameters
+    :param ax_names: N list of parameter names
+    :param result_map: map of values (N-dim)
+    :param sample: if != 0, subsample the parameter space
+    :param alpha_black: alpha value zero value
+    """
+    import matplotlib
+    import matplotlib.cm as cm
+    import matplotlib.patches as patches
+    from matplotlib.path import Path
+    with plt.style.context(['science', 'nature']):
+        fig, host = plt.subplots(dpi=400)
+        ax_lists, value_list = unpack_ndim_map(result_map, axes)
+
+        norm = matplotlib.colors.Normalize(vmin=min(value_list),
+                                           vmax=max(value_list),
+                                           clip=True)
+        mapper = cm.ScalarMappable(norm=norm, cmap=cm.magma)
+
+        # organize the data
+        ys = np.dstack([*ax_lists, value_list])[0]
+        indices = np.arange(len(ys))
+        if sample:
+            indices = np.random.choice(indices, sample).ravel()
+        ys = ys[indices]
+
+        ymins = ys.min(axis=0)
+        ymaxs = ys.max(axis=0)
+        dys = ymaxs - ymins
+        ymins -= dys * 0.05  # add 5% padding below and above
+        ymaxs += dys * 0.05
+        dys = ymaxs - ymins
+
+        # transform all data to be compatible with the main axis
+        zs = np.zeros_like(ys)
+        zs[:, 0] = ys[:, 0]
+        zs[:, 1:] = (ys[:, 1:] - ymins[1:]) / dys[1:] * dys[0] + ymins[0]
+
+        axes = [host] + [host.twinx() for _ in range(ys.shape[1] - 1)]
+        for i, ax in enumerate(axes):
+            ax.set_ylim(ymins[i], ymaxs[i])
+            ax.spines['top'].set_visible(False)
+            ax.spines['bottom'].set_visible(False)
+            if ax != host:
+                ax.spines['left'].set_visible(False)
+                ax.yaxis.set_ticks_position('right')
+                ax.spines["right"].set_position(
+                    ("axes", i / (ys.shape[1] - 1)))
+
+        host.set_xlim(0, ys.shape[1] - 1)
+        host.set_xticks(range(ys.shape[1]))
+        host.set_xticklabels(ax_names, fontsize=8)
+        host.tick_params(axis='x', which='major', pad=7)
+        host.spines['right'].set_visible(False)
+        host.xaxis.tick_top()
+        host.set_title('Parallel Coordinates Plot')
+
+        for j in range(ys.shape[0]):
+            # create bezier curves
+            # for each axis, there will a control vertex at the point itself, one at 1/3rd towards the previous and one
+            #   at one third towards the next axis; the first and last axis have one less control vertex
+            # x-coordinate of the control vertices: at each integer (for the axes) and two inbetween
+            # y-coordinate: repeat every point three times, except the first and last only twice
+            verts = list(
+                zip(
+                    list(
+                        np.linspace(
+                            0, len(ys) - 1, len(ys) * 3 - 2, endpoint=True
+                        )
+                    ),
+                    np.repeat(zs[j, :], 3)[1:-1],
+                )
+            )
+            # for x,y in verts: host.plot(x, y, 'go') # to show the control points of the beziers
+            codes = [Path.MOVETO
+                     ] + [Path.CURVE4 for _ in range(len(verts) - 1)]
+            path = Path(verts, codes)
+            alpha = alpha_black if ys[j, -1] == 0 else 0.8
+            patch = patches.PathPatch(path,
+                                      facecolor='none',
+                                      lw=.5,
+                                      edgecolor=mapper.to_rgba(
+                                          ys[j, -1], alpha))
+            host.add_patch(patch)
+        fig.tight_layout()
+
+
+def rotation_matrix(theta):
+    return np.array([[np.cos(theta), -np.sin(theta)],
+                     [np.sin(theta), np.cos(theta)]])
+
+
+def create_stack(ax,
+                 colors,
+                 heights,
+                 angles,
+                 labels,
+                 width=2,
+                 labelpad_left=.2,
+                 offset_x=0,
+                 offset_y=0,
+                 lw_arrow=1.5,
+                 ms=10,
+                 r=0.6,
+                 text_fontsize=4,
+                 reversed=True):
+    """
+    Create a material stack plot.
+    If a given layer is to have no arrow, pass None.
+    :param ax: matplotlib axis
+    :param colors: list of colors
+    :param heights: list of heights
+    :param angles: list of angles
+    :param labels: list of labels
+    :param width: width of the bars
+    :param labelpad_left: padding of the labels
+    :param offset_x: offset of the patches in x direction
+    :param offset_y: offset of the patches in y direction
+    :param lw_arrow: linewidth of the arrows
+    :param ms: mutation size of the arrows
+    :param r: length of the arrows
+    :param reversed: if True, the stack is reversed
+    """
+    [x, y] = [r, 0]
+    first_offset = offset_y
+    if reversed:
+        heights = heights[::-1]
+        colors = colors[::-1]
+        angles = angles[::-1]
+        labels = labels[::-1]
+    for i, (height, angle, color,
+            label) in enumerate(zip(heights, angles, colors, labels)):
+        ax.add_patch(
+            patches.Rectangle((offset_x, offset_y),
+                              width,
+                              height,
+                              fill=True,
+                              color=color,
+                              zorder=10))
+        ax.text(offset_x - labelpad_left,
+                offset_y + height / 2,
+                label,
+                horizontalalignment='center',
+                verticalalignment='center',
+                fontsize=text_fontsize,
+                zorder=11)
+        if angle is not None:
+            [dx, dy] = np.dot(rotation_matrix(np.deg2rad(angle)), [x, y])
+            x_mid = dx / 2
+            y_mid = dy / 2
+            centre_x = (offset_x + width) / 2 - x_mid
+            centre_y = offset_y + height / 2 - y_mid
+            ax.add_patch(
+                patches.FancyArrowPatch((centre_x, centre_y),
+                                        (centre_x + dx, centre_y + dy),
+                                        mutation_scale=ms,
+                                        lw=lw_arrow,
+                                        color='black',
+                                        zorder=10))
+        offset_y += height
+    ax.set_ylim([first_offset - max(heights) / 2, offset_y + max(heights) / 2])
+    ax.set_xlim([offset_x - width / 2, offset_x + width + width / 2])
+    ax.axis("off")
+    return ax
```

## cmtj/utils/procedures.py

 * *Ordering differences only*

```diff
@@ -1,329 +1,329 @@
-import math
-from collections import defaultdict
-from dataclasses import dataclass
-from typing import Any, Callable, Dict, List, Tuple
-
-import numpy as np
-from scipy.fft import fft, fftfreq
-from tqdm import tqdm
-
-from cmtj import AxialDriver, Axis, CVector, Junction, NullDriver, ScalarDriver
-
-from .resistance import calculate_resistance_series, compute_sd
-
-
-@dataclass
-class ResistanceParameters:
-    """A data holder for resistance parameters. Not all have to be filled in."""
-
-    Rxx0: float = 0
-    Rxy0: float = 0
-    Rahe: float = 0
-    Rsmr: float = 0
-    Ramr: float = 0
-    w: float = 0  # width
-    l: float = 0  # length
-
-
-def compute_spectrum_strip(input_m: np.ndarray, int_step: float,
-                           max_frequency: float):
-    """Compute the spectrum of a given magnetization trajectory."""
-    yf = np.abs(fft(input_m))
-    freqs = fftfreq(len(yf), int_step)
-    freqs = freqs[:len(freqs) // 2]
-    yf = yf[:len(yf) // 2]
-
-    findx = np.argwhere(freqs <= max_frequency)
-    freqs = freqs[findx]
-    yf = yf[findx]
-
-    return yf, freqs
-
-
-def PIMM_procedure(
-    junction: "Junction",
-    Hvecs: np.ndarray,
-    int_step: float,
-    resistance_params: List[ResistanceParameters],
-    Hoe_direction: Axis = Axis.zaxis,
-    Hoe_excitation: float = 50,
-    Hoe_duration: int = 3,
-    simulation_duration: float = 5e-9,
-    wait_time: float = 0e-9,
-    max_frequency: float = 80e9,
-    resistance_fn: Callable = calculate_resistance_series,
-    disturbance: float = 1e-3,
-    take_last_n: int = 100,
-    full_output: bool = False,
-    disable_tqdm: bool = False,
-    static_only: bool = False,
-) -> Tuple[np.ndarray, np.ndarray, Dict[str, Any]]:
-    """Procedure for computing Pulse Induced Microwave Magnetometry.
-    It computes both PIMM and Resistance (for instance AHE loops).
-    Set `static_only` to True to only compute the static resistance.
-    :param junction: junction to be simulated.
-    :param Hvecs: list of cartesian vectors. (use FieldScan.amplitude_scan or alike)
-    :param int_step: integration step [s].
-    :param resistance_params: list of resistance parameters.
-    :param Hoe_direction: direction of oersted field (x, y or z).
-    :param simulation_duration: duration of simulation [s].
-    :param wait_time: time to wait before taking vector for the fft [s].
-    :param Hoe_duration: duration of Hoe excitation in multiples of in step
-    :param max_frequency: maximum frequency -- larger will be dropped [Hz].
-    :param resistance_fn: function to be used to compute the resistance
-        (either calculate_resistance_series or calculate_resistance_parallel).
-    :param disturbance: disturbance to be applied to the magnetization (std of normal distribution).
-    :param take_last_n: number of last time steps to be taken for the compuation.
-    :param full_output: if True, return the full trajectories and per layer spectra.
-    :param disable_tqdm: if True, disable tqdm progress bar.
-    :param static_only: if True, only compute the static resistance.
-    :return: (spectrum, frequencies, other_data)
-    other_data is a dictionary with the following keys:
-    - 'H': Hext field [A/m]
-    - 'Rx': resistance in x direction [Ohm]
-    - 'Ry': resistance in y direction [Ohm]
-    - 'm_avg': average magnetization [unit]
-    - 'm_traj': magnetization trajectories [unit]
-    """
-    if wait_time > simulation_duration:
-        raise ValueError("wait_time must be smaller than simulation_duration!")
-    spectrum = []
-    extraction_m_component = None
-    if Hoe_direction == Axis.zaxis:
-        extraction_m_component = "z"
-        oedriver = AxialDriver(
-            NullDriver(),
-            NullDriver(),
-            ScalarDriver.getStepDriver(0, Hoe_excitation, 0,
-                                       int_step * Hoe_duration),
-        )
-    elif Hoe_direction == Axis.yaxis:
-        extraction_m_component = "y"
-        oedriver = AxialDriver(
-            NullDriver(),
-            ScalarDriver.getStepDriver(0, Hoe_excitation, 0,
-                                       int_step * Hoe_duration),
-            NullDriver(),
-        )
-    else:
-        extraction_m_component = "x"
-        oedriver = AxialDriver(
-            ScalarDriver.getStepDriver(0, Hoe_excitation, 0,
-                                       int_step * Hoe_duration),
-            NullDriver(),
-            NullDriver(),
-        )
-
-    # get layer strings
-    layer_ids = junction.getLayerIds()
-    if len(layer_ids) != len(resistance_params):
-        raise ValueError(
-            "The number of layers in the junction must match the number of resistance parameters!"
-        )
-    output = defaultdict(list)
-    normalising_factor = np.sum(
-        [layer.thickness * layer.Ms for layer in junction.layers])
-    freqs = None  # in case of static_only
-    for H in tqdm(Hvecs, desc="Computing PIMM", disable=disable_tqdm):
-        junction.clearLog()
-        junction.setLayerExternalFieldDriver(
-            "all",
-            AxialDriver(
-                ScalarDriver.getConstantDriver(H[0]),
-                ScalarDriver.getConstantDriver(H[1]),
-                ScalarDriver.getConstantDriver(H[2]),
-            ),
-        )
-        junction.setLayerOerstedFieldDriver("all", oedriver)
-        if disturbance:
-            for layer_id in layer_ids:
-                old_mag = junction.getLayerMagnetisation(layer_id)
-                new_mag = CVector(
-                    old_mag.x + np.random.normal(0, disturbance),
-                    old_mag.y + np.random.normal(0, disturbance),
-                    old_mag.z + np.random.normal(0, disturbance),
-                )
-                new_mag.normalize()
-                junction.setLayerMagnetisation(layer_id, new_mag)
-        junction.runSimulation(simulation_duration, int_step, int_step)
-        log = junction.getLog()
-        indx = np.argwhere(np.asarray(log["time"]) >= wait_time).ravel()
-        m_traj = np.asarray([
-            np.asarray([
-                log[f"{layer.id}_mx"],
-                log[f"{layer.id}_my"],
-                log[f"{layer.id}_mz"],
-            ]) * layer.thickness * layer.Ms / normalising_factor
-            for layer in junction.layers
-        ])
-        m = m_traj[:, :,
-                   -take_last_n:]  # all layers, all x, y, z, last 100 steps
-        Rx, Ry = resistance_fn(
-            [r.Rxx0 for r in resistance_params],
-            [r.Rxy0 for r in resistance_params],
-            [r.Ramr for r in resistance_params],
-            [r.Rahe for r in resistance_params],
-            [r.Rsmr for r in resistance_params],
-            m,
-            l=[r.l for r in resistance_params],
-            w=[r.w for r in resistance_params],
-        )
-        if not static_only:
-            mixed = np.asarray([
-                np.asarray(log[f"{layer.id}_m{extraction_m_component}"])[indx]
-                * layer.thickness * layer.Ms / normalising_factor
-                for layer in junction.layers
-            ])
-            mixed_sum = mixed.sum(axis=0)
-            yf, freqs = compute_spectrum_strip(mixed_sum, int_step,
-                                               max_frequency)
-
-            spectrum.append(yf)
-
-        # fill the output dict
-        output["H"].append(H)
-        output["Rx"].append(Rx)
-        output["Ry"].append(Ry)
-        output["m_avg"].append(m_traj[:, :, -1].sum(0))
-        if full_output and not static_only:
-            output["m_traj"].append(m_traj)
-            for li, layer_id in enumerate(layer_ids):
-                y, _ = compute_spectrum_strip(mixed[li], int_step,
-                                              max_frequency)
-                output[layer_id].append(y)
-    spectrum = np.squeeze(np.asarray(spectrum))
-    if full_output:
-        for layer_id in layer_ids:
-            output[layer_id] = np.asarray(output[layer_id]).squeeze()
-    return spectrum, freqs, output
-
-
-def VSD_procedure(
-    junction: Junction,
-    Hvecs: np.ndarray,
-    frequencies: np.ndarray,
-    int_step: float,
-    resistance_params: List[ResistanceParameters] = [],
-    Hoe_direction: Axis = Axis.yaxis,
-    Hoe_excitation: float = 50,
-    simulation_duration: float = 30e-9,
-    disturbance: float = 1e-3,
-    Rtype: str = "Rz",
-    resistance_fn: Callable = calculate_resistance_series,
-    disable_tqdm: bool = False,
-):
-    """Procedure for computing Voltage-Spin Diode.
-    We use the Oersted field sine exctitation to excite the system.
-    :param junction: junction to be simulated.
-    :param Hvecs: list of cartesian vectors. (use FieldScan.amplitude_scan or alike)
-    :param frequencies: list of frequencies [Hz].
-    :param int_step: integration step [s].
-    :param resistance_params: list of resistance parameters.
-    :param Hoe_direction: direction of oersted field (x, y or z).
-    :param Hoe_excitation: excitation amplitude of Hoe [A/m].
-    :param simulation_duration: duration of simulation [s].
-    :param disturbance: disturbance to be applied to the magnetization (std of normal distribution).
-    :param resistance_fn: function to be used to compute the resistance
-        (either calculate_resistance_series or calculate_resistance_parallel). Rz forces standard magnetores.
-    :param Rtype: type of resistance to be used. (Rx Ry or Rz)
-    :param disable_tqdm: if True, disable tqdm progress bar.
-    """
-    layer_ids = junction.getLayerIds()
-    if Rtype == "Rz" and len(layer_ids) > 2:
-        raise ValueError(
-            "Rz can only be used for 2 layer junctions. Use Rx or Ry instead.")
-    elif len(resistance_params) != len(layer_ids):
-        raise ValueError(
-            "The number of layers in the junction must match the number of resistance parameters!"
-        )
-
-    def simulate_VSD(H: np.ndarray, frequency: float,
-                     resistance_params: ResistanceParameters):
-        if Hoe_direction == Axis.zaxis:
-            oedriver = AxialDriver(
-                NullDriver(),
-                NullDriver(),
-                ScalarDriver.getSineDriver(0, Hoe_excitation, frequency, 0),
-            )
-        elif Hoe_direction == Axis.yaxis:
-            oedriver = AxialDriver(
-                NullDriver(),
-                ScalarDriver.getSineDriver(0, Hoe_excitation, frequency, 0),
-                NullDriver(),
-            )
-        else:
-            oedriver = AxialDriver(
-                ScalarDriver.getSineDriver(0, Hoe_excitation, frequency, 0),
-                NullDriver(),
-                NullDriver(),
-            )
-
-        junction.clearLog()
-        junction.setLayerExternalFieldDriver(
-            "all",
-            AxialDriver(
-                ScalarDriver.getConstantDriver(H[0]),
-                ScalarDriver.getConstantDriver(H[1]),
-                ScalarDriver.getConstantDriver(H[2]),
-            ),
-        )
-        junction.setLayerOerstedFieldDriver("all", oedriver)
-        if disturbance:
-            for layer_id in layer_ids:
-                old_mag = junction.getLayerMagnetisation(layer_id)
-                new_mag = CVector(
-                    old_mag.x + np.random.normal(0, disturbance),
-                    old_mag.y + np.random.normal(0, disturbance),
-                    old_mag.z + np.random.normal(0, disturbance),
-                )
-                new_mag.normalize()
-                junction.setLayerMagnetisation(layer_id, new_mag)
-        junction.runSimulation(simulation_duration, int_step, int_step)
-        log = junction.getLog()
-        m_traj = np.asarray([[
-            log[f"{layer_ids[i]}_mx"],
-            log[f"{layer_ids[i]}_my"],
-            log[f"{layer_ids[i]}_mz"],
-        ] for i in range(len(layer_ids))])
-        if Rtype == "Rz":
-            if len(layer_ids) > 2:
-                raise ValueError(
-                    "Rz can only be used for 2 layer junctions. One layer can be fictisious."
-                )
-            elif len(layer_ids) == 2:
-                R = log[f"R_{layer_ids[0]}_{layer_ids[1]}"]
-            elif len(layer_ids) == 1:
-                R = log["Resistance"]
-            else:
-                raise ValueError(
-                    "Resistance definition ambiguous!"
-                    "If you want to use Rz, you must provide"
-                    "a single resistance parameter set or set Rp Rap"
-                    " at junction creation.")
-        else:
-            Rx, Ry = resistance_fn(
-                [r.Rxx0 for r in resistance_params],
-                [r.Rxy0 for r in resistance_params],
-                [r.Ramr for r in resistance_params],
-                [r.Rahe for r in resistance_params],
-                [r.Rsmr for r in resistance_params],
-                m_traj,
-                l=[r.l for r in resistance_params],
-                w=[r.w for r in resistance_params],
-            )
-            if Rtype == "Rx":
-                R = Rx
-            elif Rtype == "Ry":
-                R = Ry
-            else:
-                raise ValueError("Rtype must be either Rx or Ry or Rz")
-        dynamicI = np.sin(2 * math.pi * frequency * np.asarray(log["time"]))
-        vmix = compute_sd(R, dynamicI, int_step)
-        return vmix
-
-    spectrum = np.zeros((len(Hvecs), len(frequencies)))
-    for hindx, H in enumerate(
-            tqdm(Hvecs, "Computing VSD", disable=disable_tqdm)):
-        for findx, f in enumerate(frequencies):
-            spectrum[hindx, findx] = simulate_VSD(H, f, resistance_params)
-    return spectrum
+import math
+from collections import defaultdict
+from dataclasses import dataclass
+from typing import Any, Callable, Dict, List, Tuple
+
+import numpy as np
+from scipy.fft import fft, fftfreq
+from tqdm import tqdm
+
+from cmtj import AxialDriver, Axis, CVector, Junction, NullDriver, ScalarDriver
+
+from .resistance import calculate_resistance_series, compute_sd
+
+
+@dataclass
+class ResistanceParameters:
+    """A data holder for resistance parameters. Not all have to be filled in."""
+
+    Rxx0: float = 0
+    Rxy0: float = 0
+    Rahe: float = 0
+    Rsmr: float = 0
+    Ramr: float = 0
+    w: float = 0  # width
+    l: float = 0  # length
+
+
+def compute_spectrum_strip(input_m: np.ndarray, int_step: float,
+                           max_frequency: float):
+    """Compute the spectrum of a given magnetization trajectory."""
+    yf = np.abs(fft(input_m))
+    freqs = fftfreq(len(yf), int_step)
+    freqs = freqs[:len(freqs) // 2]
+    yf = yf[:len(yf) // 2]
+
+    findx = np.argwhere(freqs <= max_frequency)
+    freqs = freqs[findx]
+    yf = yf[findx]
+
+    return yf, freqs
+
+
+def PIMM_procedure(
+    junction: "Junction",
+    Hvecs: np.ndarray,
+    int_step: float,
+    resistance_params: List[ResistanceParameters],
+    Hoe_direction: Axis = Axis.zaxis,
+    Hoe_excitation: float = 50,
+    Hoe_duration: int = 3,
+    simulation_duration: float = 5e-9,
+    wait_time: float = 0e-9,
+    max_frequency: float = 80e9,
+    resistance_fn: Callable = calculate_resistance_series,
+    disturbance: float = 1e-3,
+    take_last_n: int = 100,
+    full_output: bool = False,
+    disable_tqdm: bool = False,
+    static_only: bool = False,
+) -> Tuple[np.ndarray, np.ndarray, Dict[str, Any]]:
+    """Procedure for computing Pulse Induced Microwave Magnetometry.
+    It computes both PIMM and Resistance (for instance AHE loops).
+    Set `static_only` to True to only compute the static resistance.
+    :param junction: junction to be simulated.
+    :param Hvecs: list of cartesian vectors. (use FieldScan.amplitude_scan or alike)
+    :param int_step: integration step [s].
+    :param resistance_params: list of resistance parameters.
+    :param Hoe_direction: direction of oersted field (x, y or z).
+    :param simulation_duration: duration of simulation [s].
+    :param wait_time: time to wait before taking vector for the fft [s].
+    :param Hoe_duration: duration of Hoe excitation in multiples of in step
+    :param max_frequency: maximum frequency -- larger will be dropped [Hz].
+    :param resistance_fn: function to be used to compute the resistance
+        (either calculate_resistance_series or calculate_resistance_parallel).
+    :param disturbance: disturbance to be applied to the magnetization (std of normal distribution).
+    :param take_last_n: number of last time steps to be taken for the compuation.
+    :param full_output: if True, return the full trajectories and per layer spectra.
+    :param disable_tqdm: if True, disable tqdm progress bar.
+    :param static_only: if True, only compute the static resistance.
+    :return: (spectrum, frequencies, other_data)
+    other_data is a dictionary with the following keys:
+    - 'H': Hext field [A/m]
+    - 'Rx': resistance in x direction [Ohm]
+    - 'Ry': resistance in y direction [Ohm]
+    - 'm_avg': average magnetization [unit]
+    - 'm_traj': magnetization trajectories [unit]
+    """
+    if wait_time > simulation_duration:
+        raise ValueError("wait_time must be smaller than simulation_duration!")
+    spectrum = []
+    extraction_m_component = None
+    if Hoe_direction == Axis.zaxis:
+        extraction_m_component = "z"
+        oedriver = AxialDriver(
+            NullDriver(),
+            NullDriver(),
+            ScalarDriver.getStepDriver(0, Hoe_excitation, 0,
+                                       int_step * Hoe_duration),
+        )
+    elif Hoe_direction == Axis.yaxis:
+        extraction_m_component = "y"
+        oedriver = AxialDriver(
+            NullDriver(),
+            ScalarDriver.getStepDriver(0, Hoe_excitation, 0,
+                                       int_step * Hoe_duration),
+            NullDriver(),
+        )
+    else:
+        extraction_m_component = "x"
+        oedriver = AxialDriver(
+            ScalarDriver.getStepDriver(0, Hoe_excitation, 0,
+                                       int_step * Hoe_duration),
+            NullDriver(),
+            NullDriver(),
+        )
+
+    # get layer strings
+    layer_ids = junction.getLayerIds()
+    if len(layer_ids) != len(resistance_params):
+        raise ValueError(
+            "The number of layers in the junction must match the number of resistance parameters!"
+        )
+    output = defaultdict(list)
+    normalising_factor = np.sum(
+        [layer.thickness * layer.Ms for layer in junction.layers])
+    freqs = None  # in case of static_only
+    for H in tqdm(Hvecs, desc="Computing PIMM", disable=disable_tqdm):
+        junction.clearLog()
+        junction.setLayerExternalFieldDriver(
+            "all",
+            AxialDriver(
+                ScalarDriver.getConstantDriver(H[0]),
+                ScalarDriver.getConstantDriver(H[1]),
+                ScalarDriver.getConstantDriver(H[2]),
+            ),
+        )
+        junction.setLayerOerstedFieldDriver("all", oedriver)
+        if disturbance:
+            for layer_id in layer_ids:
+                old_mag = junction.getLayerMagnetisation(layer_id)
+                new_mag = CVector(
+                    old_mag.x + np.random.normal(0, disturbance),
+                    old_mag.y + np.random.normal(0, disturbance),
+                    old_mag.z + np.random.normal(0, disturbance),
+                )
+                new_mag.normalize()
+                junction.setLayerMagnetisation(layer_id, new_mag)
+        junction.runSimulation(simulation_duration, int_step, int_step)
+        log = junction.getLog()
+        indx = np.argwhere(np.asarray(log["time"]) >= wait_time).ravel()
+        m_traj = np.asarray([
+            np.asarray([
+                log[f"{layer.id}_mx"],
+                log[f"{layer.id}_my"],
+                log[f"{layer.id}_mz"],
+            ]) * layer.thickness * layer.Ms / normalising_factor
+            for layer in junction.layers
+        ])
+        m = m_traj[:, :,
+                   -take_last_n:]  # all layers, all x, y, z, last 100 steps
+        Rx, Ry = resistance_fn(
+            [r.Rxx0 for r in resistance_params],
+            [r.Rxy0 for r in resistance_params],
+            [r.Ramr for r in resistance_params],
+            [r.Rahe for r in resistance_params],
+            [r.Rsmr for r in resistance_params],
+            m,
+            l=[r.l for r in resistance_params],
+            w=[r.w for r in resistance_params],
+        )
+        if not static_only:
+            mixed = np.asarray([
+                np.asarray(log[f"{layer.id}_m{extraction_m_component}"])[indx]
+                * layer.thickness * layer.Ms / normalising_factor
+                for layer in junction.layers
+            ])
+            mixed_sum = mixed.sum(axis=0)
+            yf, freqs = compute_spectrum_strip(mixed_sum, int_step,
+                                               max_frequency)
+
+            spectrum.append(yf)
+
+        # fill the output dict
+        output["H"].append(H)
+        output["Rx"].append(Rx)
+        output["Ry"].append(Ry)
+        output["m_avg"].append(m_traj[:, :, -1].sum(0))
+        if full_output and not static_only:
+            output["m_traj"].append(m_traj)
+            for li, layer_id in enumerate(layer_ids):
+                y, _ = compute_spectrum_strip(mixed[li], int_step,
+                                              max_frequency)
+                output[layer_id].append(y)
+    spectrum = np.squeeze(np.asarray(spectrum))
+    if full_output:
+        for layer_id in layer_ids:
+            output[layer_id] = np.asarray(output[layer_id]).squeeze()
+    return spectrum, freqs, output
+
+
+def VSD_procedure(
+    junction: Junction,
+    Hvecs: np.ndarray,
+    frequencies: np.ndarray,
+    int_step: float,
+    resistance_params: List[ResistanceParameters] = [],
+    Hoe_direction: Axis = Axis.yaxis,
+    Hoe_excitation: float = 50,
+    simulation_duration: float = 30e-9,
+    disturbance: float = 1e-3,
+    Rtype: str = "Rz",
+    resistance_fn: Callable = calculate_resistance_series,
+    disable_tqdm: bool = False,
+):
+    """Procedure for computing Voltage-Spin Diode.
+    We use the Oersted field sine exctitation to excite the system.
+    :param junction: junction to be simulated.
+    :param Hvecs: list of cartesian vectors. (use FieldScan.amplitude_scan or alike)
+    :param frequencies: list of frequencies [Hz].
+    :param int_step: integration step [s].
+    :param resistance_params: list of resistance parameters.
+    :param Hoe_direction: direction of oersted field (x, y or z).
+    :param Hoe_excitation: excitation amplitude of Hoe [A/m].
+    :param simulation_duration: duration of simulation [s].
+    :param disturbance: disturbance to be applied to the magnetization (std of normal distribution).
+    :param resistance_fn: function to be used to compute the resistance
+        (either calculate_resistance_series or calculate_resistance_parallel). Rz forces standard magnetores.
+    :param Rtype: type of resistance to be used. (Rx Ry or Rz)
+    :param disable_tqdm: if True, disable tqdm progress bar.
+    """
+    layer_ids = junction.getLayerIds()
+    if Rtype == "Rz" and len(layer_ids) > 2:
+        raise ValueError(
+            "Rz can only be used for 2 layer junctions. Use Rx or Ry instead.")
+    elif len(resistance_params) != len(layer_ids):
+        raise ValueError(
+            "The number of layers in the junction must match the number of resistance parameters!"
+        )
+
+    def simulate_VSD(H: np.ndarray, frequency: float,
+                     resistance_params: ResistanceParameters):
+        if Hoe_direction == Axis.zaxis:
+            oedriver = AxialDriver(
+                NullDriver(),
+                NullDriver(),
+                ScalarDriver.getSineDriver(0, Hoe_excitation, frequency, 0),
+            )
+        elif Hoe_direction == Axis.yaxis:
+            oedriver = AxialDriver(
+                NullDriver(),
+                ScalarDriver.getSineDriver(0, Hoe_excitation, frequency, 0),
+                NullDriver(),
+            )
+        else:
+            oedriver = AxialDriver(
+                ScalarDriver.getSineDriver(0, Hoe_excitation, frequency, 0),
+                NullDriver(),
+                NullDriver(),
+            )
+
+        junction.clearLog()
+        junction.setLayerExternalFieldDriver(
+            "all",
+            AxialDriver(
+                ScalarDriver.getConstantDriver(H[0]),
+                ScalarDriver.getConstantDriver(H[1]),
+                ScalarDriver.getConstantDriver(H[2]),
+            ),
+        )
+        junction.setLayerOerstedFieldDriver("all", oedriver)
+        if disturbance:
+            for layer_id in layer_ids:
+                old_mag = junction.getLayerMagnetisation(layer_id)
+                new_mag = CVector(
+                    old_mag.x + np.random.normal(0, disturbance),
+                    old_mag.y + np.random.normal(0, disturbance),
+                    old_mag.z + np.random.normal(0, disturbance),
+                )
+                new_mag.normalize()
+                junction.setLayerMagnetisation(layer_id, new_mag)
+        junction.runSimulation(simulation_duration, int_step, int_step)
+        log = junction.getLog()
+        m_traj = np.asarray([[
+            log[f"{layer_ids[i]}_mx"],
+            log[f"{layer_ids[i]}_my"],
+            log[f"{layer_ids[i]}_mz"],
+        ] for i in range(len(layer_ids))])
+        if Rtype == "Rz":
+            if len(layer_ids) > 2:
+                raise ValueError(
+                    "Rz can only be used for 2 layer junctions. One layer can be fictisious."
+                )
+            elif len(layer_ids) == 2:
+                R = log[f"R_{layer_ids[0]}_{layer_ids[1]}"]
+            elif len(layer_ids) == 1:
+                R = log["Resistance"]
+            else:
+                raise ValueError(
+                    "Resistance definition ambiguous!"
+                    "If you want to use Rz, you must provide"
+                    "a single resistance parameter set or set Rp Rap"
+                    " at junction creation.")
+        else:
+            Rx, Ry = resistance_fn(
+                [r.Rxx0 for r in resistance_params],
+                [r.Rxy0 for r in resistance_params],
+                [r.Ramr for r in resistance_params],
+                [r.Rahe for r in resistance_params],
+                [r.Rsmr for r in resistance_params],
+                m_traj,
+                l=[r.l for r in resistance_params],
+                w=[r.w for r in resistance_params],
+            )
+            if Rtype == "Rx":
+                R = Rx
+            elif Rtype == "Ry":
+                R = Ry
+            else:
+                raise ValueError("Rtype must be either Rx or Ry or Rz")
+        dynamicI = np.sin(2 * math.pi * frequency * np.asarray(log["time"]))
+        vmix = compute_sd(R, dynamicI, int_step)
+        return vmix
+
+    spectrum = np.zeros((len(Hvecs), len(frequencies)))
+    for hindx, H in enumerate(
+            tqdm(Hvecs, "Computing VSD", disable=disable_tqdm)):
+        for findx, f in enumerate(frequencies):
+            spectrum[hindx, findx] = simulate_VSD(H, f, resistance_params)
+    return spectrum
```

## cmtj/utils/resistance.py

 * *Ordering differences only*

```diff
@@ -1,82 +1,82 @@
-from typing import List, Union
-
-import numpy as np
-
-from .filters import Filters
-
-
-def compute_sd(dynamic_r: np.ndarray, dynamic_i: np.ndarray,
-               integration_step: float) -> np.ndarray:
-    """Computes the SD voltage.
-    :param dynamic_r: magnetoresistance from log
-    :param dynamic_i: excitation current
-    :param integration_step: integration paramemter from run_simulation
-    """
-    SD = -dynamic_i * dynamic_r
-    fs = 1.0 / integration_step
-    SD_dc = Filters.butter_lowpass_filter(SD, cutoff=10e6, fs=fs, order=3)
-    return np.mean(SD_dc)
-
-
-def compute_resistance(Rx0: List[float], Ry0: List[float], AMR: List[float],
-                       AHE: List[float], SMR: List[float],
-                       m: Union[List[float],
-                                np.ndarray], l: List[float], w: List[float]):
-    """Computes the resistance of the system."""
-    number_of_layers = len(Rx0)
-    if not isinstance(m, np.ndarray):
-        m = np.asarray(m)
-    if m.ndim == 2:
-        SxAll = np.zeros((number_of_layers, ))
-        SyAll = np.zeros((number_of_layers, ))
-
-    elif m.ndim == 3:
-        SxAll = np.zeros((number_of_layers, m.shape[2]))
-        SyAll = np.zeros((number_of_layers, m.shape[2]))
-
-    for i in range(0, number_of_layers):
-        w_l = w[i] / l[i]
-        SxAll[i] = (Rx0[i] + (AMR[i] * m[i, 0]**2 + SMR[i] * m[i, 1]**2))
-        SyAll[i] = (Ry0[i] + 0.5 * AHE[i] * m[i, 2] + (w_l) *
-                    (SMR[i] - AMR[i]) * m[i, 0] * m[i, 1])
-    return SxAll, SyAll
-
-
-def calculate_magnetoresistance(Rp: float, Rap: float, m: np.ndarray):
-    """Computes the magnetoresistance using parallel and antiparallel resistance.
-    :param Rp: parallel resistance
-    :param Rap: antiparallel resistance
-    :param m: magnetisation, 2 layers of shape [2, 3, T] where T is the time component"""
-    if not isinstance(m, np.ndarray):
-        m = np.asarray(m)
-    if m.shape[0] != 2:
-        raise ValueError(
-            "The magnetoresistance can only be computed for 2 layers"
-            f". Current shape {m.shape}")
-    return Rp + 0.5 * (Rap - Rp) * np.sum(m[0] * m[1], axis=0)
-
-
-def calculate_resistance_parallel(Rx0: List[float], Ry0: List[float],
-                                  AMR: List[float], AHE: List[float],
-                                  SMR: List[float], m: List[float],
-                                  l: List[float], w: List[float]):
-    """Calculates the resistance of the system in parallel.
-    Uses Kim's formula from the paper:
-    https://link.aps.org/doi/10.1103/PhysRevLett.116.097201"""
-    SxAll, SyAll = compute_resistance(Rx0, Ry0, AMR, AHE, SMR, m, l, w)
-    Rx = 1 / np.sum(1. / SxAll, axis=0)
-    Ry = 1 / np.sum(1. / SyAll, axis=0)
-    return Rx, Ry
-
-
-def calculate_resistance_series(Rx0: List[float], Ry0: List[float],
-                                AMR: List[float], AHE: List[float],
-                                SMR: List[float], m: List[float],
-                                l: List[float], w: List[float]):
-    """Calculates the resistance of the system in series.
-    Uses Kim's formula from the paper:
-    https://link.aps.org/doi/10.1103/PhysRevLett.116.097201"""
-    SxAll, SyAll = compute_resistance(Rx0, Ry0, AMR, AHE, SMR, m, l, w)
-    Rx = np.sum(SxAll, axis=0)
-    Ry = np.sum(SyAll, axis=0)
-    return Rx, Ry
+from typing import List, Union
+
+import numpy as np
+
+from .filters import Filters
+
+
+def compute_sd(dynamic_r: np.ndarray, dynamic_i: np.ndarray,
+               integration_step: float) -> np.ndarray:
+    """Computes the SD voltage.
+    :param dynamic_r: magnetoresistance from log
+    :param dynamic_i: excitation current
+    :param integration_step: integration paramemter from run_simulation
+    """
+    SD = -dynamic_i * dynamic_r
+    fs = 1.0 / integration_step
+    SD_dc = Filters.butter_lowpass_filter(SD, cutoff=10e6, fs=fs, order=3)
+    return np.mean(SD_dc)
+
+
+def compute_resistance(Rx0: List[float], Ry0: List[float], AMR: List[float],
+                       AHE: List[float], SMR: List[float],
+                       m: Union[List[float],
+                                np.ndarray], l: List[float], w: List[float]):
+    """Computes the resistance of the system."""
+    number_of_layers = len(Rx0)
+    if not isinstance(m, np.ndarray):
+        m = np.asarray(m)
+    if m.ndim == 2:
+        SxAll = np.zeros((number_of_layers, ))
+        SyAll = np.zeros((number_of_layers, ))
+
+    elif m.ndim == 3:
+        SxAll = np.zeros((number_of_layers, m.shape[2]))
+        SyAll = np.zeros((number_of_layers, m.shape[2]))
+
+    for i in range(0, number_of_layers):
+        w_l = w[i] / l[i]
+        SxAll[i] = (Rx0[i] + (AMR[i] * m[i, 0]**2 + SMR[i] * m[i, 1]**2))
+        SyAll[i] = (Ry0[i] + 0.5 * AHE[i] * m[i, 2] + (w_l) *
+                    (SMR[i] - AMR[i]) * m[i, 0] * m[i, 1])
+    return SxAll, SyAll
+
+
+def calculate_magnetoresistance(Rp: float, Rap: float, m: np.ndarray):
+    """Computes the magnetoresistance using parallel and antiparallel resistance.
+    :param Rp: parallel resistance
+    :param Rap: antiparallel resistance
+    :param m: magnetisation, 2 layers of shape [2, 3, T] where T is the time component"""
+    if not isinstance(m, np.ndarray):
+        m = np.asarray(m)
+    if m.shape[0] != 2:
+        raise ValueError(
+            "The magnetoresistance can only be computed for 2 layers"
+            f". Current shape {m.shape}")
+    return Rp + 0.5 * (Rap - Rp) * np.sum(m[0] * m[1], axis=0)
+
+
+def calculate_resistance_parallel(Rx0: List[float], Ry0: List[float],
+                                  AMR: List[float], AHE: List[float],
+                                  SMR: List[float], m: List[float],
+                                  l: List[float], w: List[float]):
+    """Calculates the resistance of the system in parallel.
+    Uses Kim's formula from the paper:
+    https://link.aps.org/doi/10.1103/PhysRevLett.116.097201"""
+    SxAll, SyAll = compute_resistance(Rx0, Ry0, AMR, AHE, SMR, m, l, w)
+    Rx = 1 / np.sum(1. / SxAll, axis=0)
+    Ry = 1 / np.sum(1. / SyAll, axis=0)
+    return Rx, Ry
+
+
+def calculate_resistance_series(Rx0: List[float], Ry0: List[float],
+                                AMR: List[float], AHE: List[float],
+                                SMR: List[float], m: List[float],
+                                l: List[float], w: List[float]):
+    """Calculates the resistance of the system in series.
+    Uses Kim's formula from the paper:
+    https://link.aps.org/doi/10.1103/PhysRevLett.116.097201"""
+    SxAll, SyAll = compute_resistance(Rx0, Ry0, AMR, AHE, SMR, m, l, w)
+    Rx = np.sum(SxAll, axis=0)
+    Ry = np.sum(SyAll, axis=0)
+    return Rx, Ry
```

## cmtj/utils/solvers.py

 * *Ordering differences only*

```diff
@@ -1,46 +1,46 @@
-import numpy as np
-from scipy.optimize import fsolve, root
-
-
-class RootFinder:
-    """Adopted from: https://stackoverflow.com/a/65185377/3588442"""
-
-    def __init__(self,
-                 start,
-                 stop,
-                 step=0.01,
-                 root_dtype="float32",
-                 xtol=1e-9):
-
-        self.start = start
-        self.stop = stop
-        self.step = step
-        self.xtol = xtol
-        self.roots = np.array([], dtype=root_dtype)
-
-    def add_to_roots(self, x):
-
-        if (x < self.start) or (x > self.stop):
-            return  # outside range
-        if any(abs(self.roots - x) < self.xtol):
-            return  # root already found.
-
-        self.roots = np.append(self.roots, x)
-
-    def find(self, f, *args, **kwargs):
-        current = self.start
-        nsteps = int((self.stop - self.start) / self.step)
-        for x0 in np.linspace(self.start, self.stop + self.step, nsteps):
-            if x0 < current:
-                continue
-            x = self.find_root(f, x0, *args, **kwargs)
-            if x is None:  # no root found.
-                continue
-            current = x
-            self.add_to_roots(x)
-
-        return self.roots
-
-    def find_root(self, f, x0, *args, fprime=None):
-        sol = root(f, x0, args=args, jac=fprime, method="hybr")
-        return sol.x[0] if sol.success else None
+import numpy as np
+from scipy.optimize import fsolve, root
+
+
+class RootFinder:
+    """Adopted from: https://stackoverflow.com/a/65185377/3588442"""
+
+    def __init__(self,
+                 start,
+                 stop,
+                 step=0.01,
+                 root_dtype="float32",
+                 xtol=1e-9):
+
+        self.start = start
+        self.stop = stop
+        self.step = step
+        self.xtol = xtol
+        self.roots = np.array([], dtype=root_dtype)
+
+    def add_to_roots(self, x):
+
+        if (x < self.start) or (x > self.stop):
+            return  # outside range
+        if any(abs(self.roots - x) < self.xtol):
+            return  # root already found.
+
+        self.roots = np.append(self.roots, x)
+
+    def find(self, f, *args, **kwargs):
+        current = self.start
+        nsteps = int((self.stop - self.start) / self.step)
+        for x0 in np.linspace(self.start, self.stop + self.step, nsteps):
+            if x0 < current:
+                continue
+            x = self.find_root(f, x0, *args, **kwargs)
+            if x is None:  # no root found.
+                continue
+            current = x
+            self.add_to_roots(x)
+
+        return self.roots
+
+    def find_root(self, f, x0, *args, fprime=None):
+        sol = root(f, x0, args=args, jac=fprime, method="hybr")
+        return sol.x[0] if sol.success else None
```

## Comparing `cmtj-1.4.1.dist-info/LICENSE` & `cmtj-1.5.0.dist-info/LICENSE`

 * *Ordering differences only*

 * *Files 4% similar despite different names*

```diff
@@ -1,339 +1,339 @@
-                    GNU GENERAL PUBLIC LICENSE
-                       Version 2, June 1991
-
- Copyright (C) 1989, 1991 Free Software Foundation, Inc.,
- 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
- Everyone is permitted to copy and distribute verbatim copies
- of this license document, but changing it is not allowed.
-
-                            Preamble
-
-  The licenses for most software are designed to take away your
-freedom to share and change it.  By contrast, the GNU General Public
-License is intended to guarantee your freedom to share and change free
-software--to make sure the software is free for all its users.  This
-General Public License applies to most of the Free Software
-Foundation's software and to any other program whose authors commit to
-using it.  (Some other Free Software Foundation software is covered by
-the GNU Lesser General Public License instead.)  You can apply it to
-your programs, too.
-
-  When we speak of free software, we are referring to freedom, not
-price.  Our General Public Licenses are designed to make sure that you
-have the freedom to distribute copies of free software (and charge for
-this service if you wish), that you receive source code or can get it
-if you want it, that you can change the software or use pieces of it
-in new free programs; and that you know you can do these things.
-
-  To protect your rights, we need to make restrictions that forbid
-anyone to deny you these rights or to ask you to surrender the rights.
-These restrictions translate to certain responsibilities for you if you
-distribute copies of the software, or if you modify it.
-
-  For example, if you distribute copies of such a program, whether
-gratis or for a fee, you must give the recipients all the rights that
-you have.  You must make sure that they, too, receive or can get the
-source code.  And you must show them these terms so they know their
-rights.
-
-  We protect your rights with two steps: (1) copyright the software, and
-(2) offer you this license which gives you legal permission to copy,
-distribute and/or modify the software.
-
-  Also, for each author's protection and ours, we want to make certain
-that everyone understands that there is no warranty for this free
-software.  If the software is modified by someone else and passed on, we
-want its recipients to know that what they have is not the original, so
-that any problems introduced by others will not reflect on the original
-authors' reputations.
-
-  Finally, any free program is threatened constantly by software
-patents.  We wish to avoid the danger that redistributors of a free
-program will individually obtain patent licenses, in effect making the
-program proprietary.  To prevent this, we have made it clear that any
-patent must be licensed for everyone's free use or not licensed at all.
-
-  The precise terms and conditions for copying, distribution and
-modification follow.
-
-                    GNU GENERAL PUBLIC LICENSE
-   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
-
-  0. This License applies to any program or other work which contains
-a notice placed by the copyright holder saying it may be distributed
-under the terms of this General Public License.  The "Program", below,
-refers to any such program or work, and a "work based on the Program"
-means either the Program or any derivative work under copyright law:
-that is to say, a work containing the Program or a portion of it,
-either verbatim or with modifications and/or translated into another
-language.  (Hereinafter, translation is included without limitation in
-the term "modification".)  Each licensee is addressed as "you".
-
-Activities other than copying, distribution and modification are not
-covered by this License; they are outside its scope.  The act of
-running the Program is not restricted, and the output from the Program
-is covered only if its contents constitute a work based on the
-Program (independent of having been made by running the Program).
-Whether that is true depends on what the Program does.
-
-  1. You may copy and distribute verbatim copies of the Program's
-source code as you receive it, in any medium, provided that you
-conspicuously and appropriately publish on each copy an appropriate
-copyright notice and disclaimer of warranty; keep intact all the
-notices that refer to this License and to the absence of any warranty;
-and give any other recipients of the Program a copy of this License
-along with the Program.
-
-You may charge a fee for the physical act of transferring a copy, and
-you may at your option offer warranty protection in exchange for a fee.
-
-  2. You may modify your copy or copies of the Program or any portion
-of it, thus forming a work based on the Program, and copy and
-distribute such modifications or work under the terms of Section 1
-above, provided that you also meet all of these conditions:
-
-    a) You must cause the modified files to carry prominent notices
-    stating that you changed the files and the date of any change.
-
-    b) You must cause any work that you distribute or publish, that in
-    whole or in part contains or is derived from the Program or any
-    part thereof, to be licensed as a whole at no charge to all third
-    parties under the terms of this License.
-
-    c) If the modified program normally reads commands interactively
-    when run, you must cause it, when started running for such
-    interactive use in the most ordinary way, to print or display an
-    announcement including an appropriate copyright notice and a
-    notice that there is no warranty (or else, saying that you provide
-    a warranty) and that users may redistribute the program under
-    these conditions, and telling the user how to view a copy of this
-    License.  (Exception: if the Program itself is interactive but
-    does not normally print such an announcement, your work based on
-    the Program is not required to print an announcement.)
-
-These requirements apply to the modified work as a whole.  If
-identifiable sections of that work are not derived from the Program,
-and can be reasonably considered independent and separate works in
-themselves, then this License, and its terms, do not apply to those
-sections when you distribute them as separate works.  But when you
-distribute the same sections as part of a whole which is a work based
-on the Program, the distribution of the whole must be on the terms of
-this License, whose permissions for other licensees extend to the
-entire whole, and thus to each and every part regardless of who wrote it.
-
-Thus, it is not the intent of this section to claim rights or contest
-your rights to work written entirely by you; rather, the intent is to
-exercise the right to control the distribution of derivative or
-collective works based on the Program.
-
-In addition, mere aggregation of another work not based on the Program
-with the Program (or with a work based on the Program) on a volume of
-a storage or distribution medium does not bring the other work under
-the scope of this License.
-
-  3. You may copy and distribute the Program (or a work based on it,
-under Section 2) in object code or executable form under the terms of
-Sections 1 and 2 above provided that you also do one of the following:
-
-    a) Accompany it with the complete corresponding machine-readable
-    source code, which must be distributed under the terms of Sections
-    1 and 2 above on a medium customarily used for software interchange; or,
-
-    b) Accompany it with a written offer, valid for at least three
-    years, to give any third party, for a charge no more than your
-    cost of physically performing source distribution, a complete
-    machine-readable copy of the corresponding source code, to be
-    distributed under the terms of Sections 1 and 2 above on a medium
-    customarily used for software interchange; or,
-
-    c) Accompany it with the information you received as to the offer
-    to distribute corresponding source code.  (This alternative is
-    allowed only for noncommercial distribution and only if you
-    received the program in object code or executable form with such
-    an offer, in accord with Subsection b above.)
-
-The source code for a work means the preferred form of the work for
-making modifications to it.  For an executable work, complete source
-code means all the source code for all modules it contains, plus any
-associated interface definition files, plus the scripts used to
-control compilation and installation of the executable.  However, as a
-special exception, the source code distributed need not include
-anything that is normally distributed (in either source or binary
-form) with the major components (compiler, kernel, and so on) of the
-operating system on which the executable runs, unless that component
-itself accompanies the executable.
-
-If distribution of executable or object code is made by offering
-access to copy from a designated place, then offering equivalent
-access to copy the source code from the same place counts as
-distribution of the source code, even though third parties are not
-compelled to copy the source along with the object code.
-
-  4. You may not copy, modify, sublicense, or distribute the Program
-except as expressly provided under this License.  Any attempt
-otherwise to copy, modify, sublicense or distribute the Program is
-void, and will automatically terminate your rights under this License.
-However, parties who have received copies, or rights, from you under
-this License will not have their licenses terminated so long as such
-parties remain in full compliance.
-
-  5. You are not required to accept this License, since you have not
-signed it.  However, nothing else grants you permission to modify or
-distribute the Program or its derivative works.  These actions are
-prohibited by law if you do not accept this License.  Therefore, by
-modifying or distributing the Program (or any work based on the
-Program), you indicate your acceptance of this License to do so, and
-all its terms and conditions for copying, distributing or modifying
-the Program or works based on it.
-
-  6. Each time you redistribute the Program (or any work based on the
-Program), the recipient automatically receives a license from the
-original licensor to copy, distribute or modify the Program subject to
-these terms and conditions.  You may not impose any further
-restrictions on the recipients' exercise of the rights granted herein.
-You are not responsible for enforcing compliance by third parties to
-this License.
-
-  7. If, as a consequence of a court judgment or allegation of patent
-infringement or for any other reason (not limited to patent issues),
-conditions are imposed on you (whether by court order, agreement or
-otherwise) that contradict the conditions of this License, they do not
-excuse you from the conditions of this License.  If you cannot
-distribute so as to satisfy simultaneously your obligations under this
-License and any other pertinent obligations, then as a consequence you
-may not distribute the Program at all.  For example, if a patent
-license would not permit royalty-free redistribution of the Program by
-all those who receive copies directly or indirectly through you, then
-the only way you could satisfy both it and this License would be to
-refrain entirely from distribution of the Program.
-
-If any portion of this section is held invalid or unenforceable under
-any particular circumstance, the balance of the section is intended to
-apply and the section as a whole is intended to apply in other
-circumstances.
-
-It is not the purpose of this section to induce you to infringe any
-patents or other property right claims or to contest validity of any
-such claims; this section has the sole purpose of protecting the
-integrity of the free software distribution system, which is
-implemented by public license practices.  Many people have made
-generous contributions to the wide range of software distributed
-through that system in reliance on consistent application of that
-system; it is up to the author/donor to decide if he or she is willing
-to distribute software through any other system and a licensee cannot
-impose that choice.
-
-This section is intended to make thoroughly clear what is believed to
-be a consequence of the rest of this License.
-
-  8. If the distribution and/or use of the Program is restricted in
-certain countries either by patents or by copyrighted interfaces, the
-original copyright holder who places the Program under this License
-may add an explicit geographical distribution limitation excluding
-those countries, so that distribution is permitted only in or among
-countries not thus excluded.  In such case, this License incorporates
-the limitation as if written in the body of this License.
-
-  9. The Free Software Foundation may publish revised and/or new versions
-of the General Public License from time to time.  Such new versions will
-be similar in spirit to the present version, but may differ in detail to
-address new problems or concerns.
-
-Each version is given a distinguishing version number.  If the Program
-specifies a version number of this License which applies to it and "any
-later version", you have the option of following the terms and conditions
-either of that version or of any later version published by the Free
-Software Foundation.  If the Program does not specify a version number of
-this License, you may choose any version ever published by the Free Software
-Foundation.
-
-  10. If you wish to incorporate parts of the Program into other free
-programs whose distribution conditions are different, write to the author
-to ask for permission.  For software which is copyrighted by the Free
-Software Foundation, write to the Free Software Foundation; we sometimes
-make exceptions for this.  Our decision will be guided by the two goals
-of preserving the free status of all derivatives of our free software and
-of promoting the sharing and reuse of software generally.
-
-                            NO WARRANTY
-
-  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY
-FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN
-OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES
-PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED
-OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
-MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS
-TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE
-PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,
-REPAIR OR CORRECTION.
-
-  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
-WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR
-REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,
-INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING
-OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED
-TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY
-YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER
-PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE
-POSSIBILITY OF SUCH DAMAGES.
-
-                     END OF TERMS AND CONDITIONS
-
-            How to Apply These Terms to Your New Programs
-
-  If you develop a new program, and you want it to be of the greatest
-possible use to the public, the best way to achieve this is to make it
-free software which everyone can redistribute and change under these terms.
-
-  To do so, attach the following notices to the program.  It is safest
-to attach them to the start of each source file to most effectively
-convey the exclusion of warranty; and each file should have at least
-the "copyright" line and a pointer to where the full notice is found.
-
-    <one line to give the program's name and a brief idea of what it does.>
-    Copyright (C) <year>  <name of author>
-
-    This program is free software; you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation; either version 2 of the License, or
-    (at your option) any later version.
-
-    This program is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License along
-    with this program; if not, write to the Free Software Foundation, Inc.,
-    51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
-
-Also add information on how to contact you by electronic and paper mail.
-
-If the program is interactive, make it output a short notice like this
-when it starts in an interactive mode:
-
-    Gnomovision version 69, Copyright (C) year name of author
-    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
-    This is free software, and you are welcome to redistribute it
-    under certain conditions; type `show c' for details.
-
-The hypothetical commands `show w' and `show c' should show the appropriate
-parts of the General Public License.  Of course, the commands you use may
-be called something other than `show w' and `show c'; they could even be
-mouse-clicks or menu items--whatever suits your program.
-
-You should also get your employer (if you work as a programmer) or your
-school, if any, to sign a "copyright disclaimer" for the program, if
-necessary.  Here is a sample; alter the names:
-
-  Yoyodyne, Inc., hereby disclaims all copyright interest in the program
-  `Gnomovision' (which makes passes at compilers) written by James Hacker.
-
-  <signature of Ty Coon>, 1 April 1989
-  Ty Coon, President of Vice
-
-This General Public License does not permit incorporating your program into
-proprietary programs.  If your program is a subroutine library, you may
-consider it more useful to permit linking proprietary applications with the
-library.  If this is what you want to do, use the GNU Lesser General
-Public License instead of this License.
+                    GNU GENERAL PUBLIC LICENSE
+                       Version 2, June 1991
+
+ Copyright (C) 1989, 1991 Free Software Foundation, Inc.,
+ 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ Everyone is permitted to copy and distribute verbatim copies
+ of this license document, but changing it is not allowed.
+
+                            Preamble
+
+  The licenses for most software are designed to take away your
+freedom to share and change it.  By contrast, the GNU General Public
+License is intended to guarantee your freedom to share and change free
+software--to make sure the software is free for all its users.  This
+General Public License applies to most of the Free Software
+Foundation's software and to any other program whose authors commit to
+using it.  (Some other Free Software Foundation software is covered by
+the GNU Lesser General Public License instead.)  You can apply it to
+your programs, too.
+
+  When we speak of free software, we are referring to freedom, not
+price.  Our General Public Licenses are designed to make sure that you
+have the freedom to distribute copies of free software (and charge for
+this service if you wish), that you receive source code or can get it
+if you want it, that you can change the software or use pieces of it
+in new free programs; and that you know you can do these things.
+
+  To protect your rights, we need to make restrictions that forbid
+anyone to deny you these rights or to ask you to surrender the rights.
+These restrictions translate to certain responsibilities for you if you
+distribute copies of the software, or if you modify it.
+
+  For example, if you distribute copies of such a program, whether
+gratis or for a fee, you must give the recipients all the rights that
+you have.  You must make sure that they, too, receive or can get the
+source code.  And you must show them these terms so they know their
+rights.
+
+  We protect your rights with two steps: (1) copyright the software, and
+(2) offer you this license which gives you legal permission to copy,
+distribute and/or modify the software.
+
+  Also, for each author's protection and ours, we want to make certain
+that everyone understands that there is no warranty for this free
+software.  If the software is modified by someone else and passed on, we
+want its recipients to know that what they have is not the original, so
+that any problems introduced by others will not reflect on the original
+authors' reputations.
+
+  Finally, any free program is threatened constantly by software
+patents.  We wish to avoid the danger that redistributors of a free
+program will individually obtain patent licenses, in effect making the
+program proprietary.  To prevent this, we have made it clear that any
+patent must be licensed for everyone's free use or not licensed at all.
+
+  The precise terms and conditions for copying, distribution and
+modification follow.
+
+                    GNU GENERAL PUBLIC LICENSE
+   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
+
+  0. This License applies to any program or other work which contains
+a notice placed by the copyright holder saying it may be distributed
+under the terms of this General Public License.  The "Program", below,
+refers to any such program or work, and a "work based on the Program"
+means either the Program or any derivative work under copyright law:
+that is to say, a work containing the Program or a portion of it,
+either verbatim or with modifications and/or translated into another
+language.  (Hereinafter, translation is included without limitation in
+the term "modification".)  Each licensee is addressed as "you".
+
+Activities other than copying, distribution and modification are not
+covered by this License; they are outside its scope.  The act of
+running the Program is not restricted, and the output from the Program
+is covered only if its contents constitute a work based on the
+Program (independent of having been made by running the Program).
+Whether that is true depends on what the Program does.
+
+  1. You may copy and distribute verbatim copies of the Program's
+source code as you receive it, in any medium, provided that you
+conspicuously and appropriately publish on each copy an appropriate
+copyright notice and disclaimer of warranty; keep intact all the
+notices that refer to this License and to the absence of any warranty;
+and give any other recipients of the Program a copy of this License
+along with the Program.
+
+You may charge a fee for the physical act of transferring a copy, and
+you may at your option offer warranty protection in exchange for a fee.
+
+  2. You may modify your copy or copies of the Program or any portion
+of it, thus forming a work based on the Program, and copy and
+distribute such modifications or work under the terms of Section 1
+above, provided that you also meet all of these conditions:
+
+    a) You must cause the modified files to carry prominent notices
+    stating that you changed the files and the date of any change.
+
+    b) You must cause any work that you distribute or publish, that in
+    whole or in part contains or is derived from the Program or any
+    part thereof, to be licensed as a whole at no charge to all third
+    parties under the terms of this License.
+
+    c) If the modified program normally reads commands interactively
+    when run, you must cause it, when started running for such
+    interactive use in the most ordinary way, to print or display an
+    announcement including an appropriate copyright notice and a
+    notice that there is no warranty (or else, saying that you provide
+    a warranty) and that users may redistribute the program under
+    these conditions, and telling the user how to view a copy of this
+    License.  (Exception: if the Program itself is interactive but
+    does not normally print such an announcement, your work based on
+    the Program is not required to print an announcement.)
+
+These requirements apply to the modified work as a whole.  If
+identifiable sections of that work are not derived from the Program,
+and can be reasonably considered independent and separate works in
+themselves, then this License, and its terms, do not apply to those
+sections when you distribute them as separate works.  But when you
+distribute the same sections as part of a whole which is a work based
+on the Program, the distribution of the whole must be on the terms of
+this License, whose permissions for other licensees extend to the
+entire whole, and thus to each and every part regardless of who wrote it.
+
+Thus, it is not the intent of this section to claim rights or contest
+your rights to work written entirely by you; rather, the intent is to
+exercise the right to control the distribution of derivative or
+collective works based on the Program.
+
+In addition, mere aggregation of another work not based on the Program
+with the Program (or with a work based on the Program) on a volume of
+a storage or distribution medium does not bring the other work under
+the scope of this License.
+
+  3. You may copy and distribute the Program (or a work based on it,
+under Section 2) in object code or executable form under the terms of
+Sections 1 and 2 above provided that you also do one of the following:
+
+    a) Accompany it with the complete corresponding machine-readable
+    source code, which must be distributed under the terms of Sections
+    1 and 2 above on a medium customarily used for software interchange; or,
+
+    b) Accompany it with a written offer, valid for at least three
+    years, to give any third party, for a charge no more than your
+    cost of physically performing source distribution, a complete
+    machine-readable copy of the corresponding source code, to be
+    distributed under the terms of Sections 1 and 2 above on a medium
+    customarily used for software interchange; or,
+
+    c) Accompany it with the information you received as to the offer
+    to distribute corresponding source code.  (This alternative is
+    allowed only for noncommercial distribution and only if you
+    received the program in object code or executable form with such
+    an offer, in accord with Subsection b above.)
+
+The source code for a work means the preferred form of the work for
+making modifications to it.  For an executable work, complete source
+code means all the source code for all modules it contains, plus any
+associated interface definition files, plus the scripts used to
+control compilation and installation of the executable.  However, as a
+special exception, the source code distributed need not include
+anything that is normally distributed (in either source or binary
+form) with the major components (compiler, kernel, and so on) of the
+operating system on which the executable runs, unless that component
+itself accompanies the executable.
+
+If distribution of executable or object code is made by offering
+access to copy from a designated place, then offering equivalent
+access to copy the source code from the same place counts as
+distribution of the source code, even though third parties are not
+compelled to copy the source along with the object code.
+
+  4. You may not copy, modify, sublicense, or distribute the Program
+except as expressly provided under this License.  Any attempt
+otherwise to copy, modify, sublicense or distribute the Program is
+void, and will automatically terminate your rights under this License.
+However, parties who have received copies, or rights, from you under
+this License will not have their licenses terminated so long as such
+parties remain in full compliance.
+
+  5. You are not required to accept this License, since you have not
+signed it.  However, nothing else grants you permission to modify or
+distribute the Program or its derivative works.  These actions are
+prohibited by law if you do not accept this License.  Therefore, by
+modifying or distributing the Program (or any work based on the
+Program), you indicate your acceptance of this License to do so, and
+all its terms and conditions for copying, distributing or modifying
+the Program or works based on it.
+
+  6. Each time you redistribute the Program (or any work based on the
+Program), the recipient automatically receives a license from the
+original licensor to copy, distribute or modify the Program subject to
+these terms and conditions.  You may not impose any further
+restrictions on the recipients' exercise of the rights granted herein.
+You are not responsible for enforcing compliance by third parties to
+this License.
+
+  7. If, as a consequence of a court judgment or allegation of patent
+infringement or for any other reason (not limited to patent issues),
+conditions are imposed on you (whether by court order, agreement or
+otherwise) that contradict the conditions of this License, they do not
+excuse you from the conditions of this License.  If you cannot
+distribute so as to satisfy simultaneously your obligations under this
+License and any other pertinent obligations, then as a consequence you
+may not distribute the Program at all.  For example, if a patent
+license would not permit royalty-free redistribution of the Program by
+all those who receive copies directly or indirectly through you, then
+the only way you could satisfy both it and this License would be to
+refrain entirely from distribution of the Program.
+
+If any portion of this section is held invalid or unenforceable under
+any particular circumstance, the balance of the section is intended to
+apply and the section as a whole is intended to apply in other
+circumstances.
+
+It is not the purpose of this section to induce you to infringe any
+patents or other property right claims or to contest validity of any
+such claims; this section has the sole purpose of protecting the
+integrity of the free software distribution system, which is
+implemented by public license practices.  Many people have made
+generous contributions to the wide range of software distributed
+through that system in reliance on consistent application of that
+system; it is up to the author/donor to decide if he or she is willing
+to distribute software through any other system and a licensee cannot
+impose that choice.
+
+This section is intended to make thoroughly clear what is believed to
+be a consequence of the rest of this License.
+
+  8. If the distribution and/or use of the Program is restricted in
+certain countries either by patents or by copyrighted interfaces, the
+original copyright holder who places the Program under this License
+may add an explicit geographical distribution limitation excluding
+those countries, so that distribution is permitted only in or among
+countries not thus excluded.  In such case, this License incorporates
+the limitation as if written in the body of this License.
+
+  9. The Free Software Foundation may publish revised and/or new versions
+of the General Public License from time to time.  Such new versions will
+be similar in spirit to the present version, but may differ in detail to
+address new problems or concerns.
+
+Each version is given a distinguishing version number.  If the Program
+specifies a version number of this License which applies to it and "any
+later version", you have the option of following the terms and conditions
+either of that version or of any later version published by the Free
+Software Foundation.  If the Program does not specify a version number of
+this License, you may choose any version ever published by the Free Software
+Foundation.
+
+  10. If you wish to incorporate parts of the Program into other free
+programs whose distribution conditions are different, write to the author
+to ask for permission.  For software which is copyrighted by the Free
+Software Foundation, write to the Free Software Foundation; we sometimes
+make exceptions for this.  Our decision will be guided by the two goals
+of preserving the free status of all derivatives of our free software and
+of promoting the sharing and reuse of software generally.
+
+                            NO WARRANTY
+
+  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY
+FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN
+OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES
+PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED
+OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS
+TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE
+PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,
+REPAIR OR CORRECTION.
+
+  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
+WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR
+REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,
+INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING
+OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED
+TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY
+YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER
+PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE
+POSSIBILITY OF SUCH DAMAGES.
+
+                     END OF TERMS AND CONDITIONS
+
+            How to Apply These Terms to Your New Programs
+
+  If you develop a new program, and you want it to be of the greatest
+possible use to the public, the best way to achieve this is to make it
+free software which everyone can redistribute and change under these terms.
+
+  To do so, attach the following notices to the program.  It is safest
+to attach them to the start of each source file to most effectively
+convey the exclusion of warranty; and each file should have at least
+the "copyright" line and a pointer to where the full notice is found.
+
+    <one line to give the program's name and a brief idea of what it does.>
+    Copyright (C) <year>  <name of author>
+
+    This program is free software; you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation; either version 2 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License along
+    with this program; if not, write to the Free Software Foundation, Inc.,
+    51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
+
+Also add information on how to contact you by electronic and paper mail.
+
+If the program is interactive, make it output a short notice like this
+when it starts in an interactive mode:
+
+    Gnomovision version 69, Copyright (C) year name of author
+    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
+    This is free software, and you are welcome to redistribute it
+    under certain conditions; type `show c' for details.
+
+The hypothetical commands `show w' and `show c' should show the appropriate
+parts of the General Public License.  Of course, the commands you use may
+be called something other than `show w' and `show c'; they could even be
+mouse-clicks or menu items--whatever suits your program.
+
+You should also get your employer (if you work as a programmer) or your
+school, if any, to sign a "copyright disclaimer" for the program, if
+necessary.  Here is a sample; alter the names:
+
+  Yoyodyne, Inc., hereby disclaims all copyright interest in the program
+  `Gnomovision' (which makes passes at compilers) written by James Hacker.
+
+  <signature of Ty Coon>, 1 April 1989
+  Ty Coon, President of Vice
+
+This General Public License does not permit incorporating your program into
+proprietary programs.  If your program is a subroutine library, you may
+consider it more useful to permit linking proprietary applications with the
+library.  If this is what you want to do, use the GNU Lesser General
+Public License instead of this License.
```

## Comparing `cmtj-1.4.1.dist-info/RECORD` & `cmtj-1.5.0.dist-info/RECORD`

 * *Files 21% similar despite different names*

```diff
@@ -1,25 +1,28 @@
-cmtj-1.4.1-py3.9-nspkg.pth,sha256=5rU9BlO3duKkEclH9Cqen59cR7vi-WGP1rPo5CSmgh4,530
-cmtj.cp39-win_amd64.pyd,sha256=m-l4BlsUwOSxQNHaLizIXnXiLkoaT5GC1QHmnLo0OOU,437248
-cmtj/models/__init__.py,sha256=OrdXRWsr4GwR94Gdu4HteCwj94PiBXqPRK7-AmsE6Io,154
-cmtj/models/domain_dynamics.py,sha256=DRC0rAlu94odkCA1hi3arqwGA2BbLkCsffPeU1Et8CA,11366
-cmtj/models/drivers.py,sha256=tIwAQsrrMxnR_PfR-6o6V-VqCOrDf28jEXoeHrm2xSo,357
-cmtj/models/ensemble.py,sha256=3iMx_BnqSy1pA4_QkdaXZojNkhfhwLeIp30-jVqNmKY,1613
-cmtj/models/general_sb.py,sha256=19z6fWXp9bFj9yu69Ofy8ZRmRAEM-iBbs_rOV23mVE8,29249
-cmtj/models/oersted.py,sha256=C5jKSqtgn_g2Ul2MyKdWNuoFdU8Mgv-BmdulVcyg4Ag,8040
-cmtj/utils/__init__.py,sha256=0WiaM8qGXAersNvCqPp9epdwhDr4kzhphYUhzE1awlc,739
-cmtj/utils/energy.py,sha256=MHLs5zXQyNGOBktNyHzEiV_ooTbCSEtjbi_fN0LEmkg,2726
-cmtj/utils/filters.py,sha256=4XEQxWaT17bx47BDB3LgkxZXt1Hjr_kymTAmb6CgE_Y,2396
-cmtj/utils/general.py,sha256=ShHYZsOtnWoVeqLvb0V3NnV9y3Nnj8BUhOK80ZdhGwY,3768
-cmtj/utils/linear.py,sha256=VUocjWmu9fn8TzXwPnD6xGvqF3EsgsvRkt0AqaH5ft0,4689
-cmtj/utils/optimization.py,sha256=CjaYPltMdOXk8Y-IkhpwTS8NZykMjwhbOD6elaqj5Vw,3688
-cmtj/utils/parallel.py,sha256=L76RNEeV60TJ7HNcz8zSU6W0W6orKEaVsARlgeiT_ZE,1608
-cmtj/utils/plotting.py,sha256=zCgaNsgWLDUro7hsZXUXG8b86T8Aq8PwvHt9-hi3j6s,11365
-cmtj/utils/procedures.py,sha256=uRUz9T5S0LQKI4VdUpD2HLdJuhFwtEayaz7kmIJSIt4,13671
-cmtj/utils/resistance.py,sha256=IfS1tbAtcniWx_4YgqKTnrfJsZFAThI7-DHMieYKHb4,3391
-cmtj/utils/solvers.py,sha256=yRLXkE0NUeJMZBkjpyfG0Dr1MCK2WAvEOqr56YoCZiA,1402
-cmtj-1.4.1.dist-info/LICENSE,sha256=GJsa-V1mEVHgVM6hDJGz11Tk3k0_7PsHTB-ylHb3Fns,18431
-cmtj-1.4.1.dist-info/METADATA,sha256=sSBmirpx85A8SlM9MxpkcNG48ACHh7BwbIXxgci6ZCQ,6565
-cmtj-1.4.1.dist-info/WHEEL,sha256=GZFS91_ufm4WrNPBaFVPB9MvOXR6bMZQhPcZRRTN5YM,100
-cmtj-1.4.1.dist-info/namespace_packages.txt,sha256=tdHMVh6eYeOaJJ6PiTcEihvYuKm12Vr9LjhNMGbEDBQ,5
-cmtj-1.4.1.dist-info/top_level.txt,sha256=tdHMVh6eYeOaJJ6PiTcEihvYuKm12Vr9LjhNMGbEDBQ,5
-cmtj-1.4.1.dist-info/RECORD,,
+cmtj-1.5.0-py3.12-nspkg.pth,sha256=Ue4Smqu1TeL0Lc8Jqt8i5lC4_rjkoqbnB-KOmVBykVU,457
+cmtj.cpython-312-darwin.so,sha256=u0EdyNlVZLX1FTZXygMW-x4I0aKSJiQImATqGXLfw4E,2118512
+cmtj/models/__init__.py,sha256=JsvMWflsDtHQYPTakKildRXzfJa8sg7j0ZDuBU48jVI,146
+cmtj/models/domain_dynamics.py,sha256=Fj3Us1cU9p3Uc_kvCBrJohlcluT3HAaCo_CGugfR39U,11041
+cmtj/models/drivers.py,sha256=rP3BU2lR4D-PMt3HbjSm8_OtzNSm_uOfC5wbjPylS4Q,335
+cmtj/models/ensemble.py,sha256=Ua_1bRfHl0mbLYlsl_Zd6bif7ouBKbxh2POW4E4hDBY,1562
+cmtj/models/general_sb.py,sha256=pmz6eVNuI2EehVgaIQ_fT5s0RzZ8VpfFRfn0lFhCyoU,30154
+cmtj/models/noise.py,sha256=ov6-HaUpn1YLfXBvlRBbSKSMxRNzgINPcmhcGB7Eq28,11343
+cmtj/models/oersted.py,sha256=fEF_wX0wyEKPKxiOl2RYMs-N9TKiJGIxHKlD6kzyYtw,7819
+cmtj/noise/__init__.pyi,sha256=qBuhgecBcyE-T4GZdQ2i_X3dVFt-v6RZOm3LooNDLGo,1104
+cmtj/stack/__init__.pyi,sha256=8kIfMNaWBzAR3Mlx_Ga33NuOYMxLSWYuuW1i8I6WX1Q,5408
+cmtj/utils/__init__.py,sha256=OxSFANX_ViJpizWAzyHNRO8BvvSTkoAhdyS2W5lN61I,711
+cmtj/utils/energy.py,sha256=xo5uQpxInuyvqPwQodqHSUD5d39mhKEGjbOO1u5PFDo,2655
+cmtj/utils/filters.py,sha256=yngT7QcBSOcJHO537-8oKHkSfCMxDBWqFKSfRjNfn6M,2332
+cmtj/utils/general.py,sha256=5IuFsGPxC1Vt9uXqOLGEx7g5HBe4ycE67OT3A9Fk2Sw,3660
+cmtj/utils/linear.py,sha256=TwBSL5fmm2yOGPBggkhJMKyD2AUJcww2AaXJkWN-vFU,4565
+cmtj/utils/optimization.py,sha256=fQEXB8Ox_XSZmll4uJK0_CSjiNzhMNAlhZETjFtbB0A,3581
+cmtj/utils/parallel.py,sha256=dtwyRe_7shp3rvb2SiWVWuRS4nla6daxREo8GDHpdhg,1560
+cmtj/utils/plotting.py,sha256=8NM4SjGXufy6dl8ByGfKZ4cr_d0Gma8eeQYA4voK8OE,11067
+cmtj/utils/procedures.py,sha256=dINXuPZDnT-JZIdyDWOutyI6RNjQq3bPuWD3rUgDf88,13342
+cmtj/utils/resistance.py,sha256=CizusFo1J--RrhlCXDHJLIrQzqHLGqnV8zp9MT1Gl6E,3309
+cmtj/utils/solvers.py,sha256=TOSHfSU4QD7RkX3rxjvYJ85VPMbEqQWVyxkHn_XvIjs,1356
+cmtj-1.5.0.dist-info/LICENSE,sha256=gXf5dRMhNSbfLPYYTY_5hsZ1r7UU1OaKQEAQUhuIBkM,18092
+cmtj-1.5.0.dist-info/METADATA,sha256=irn18juPo7nRjeuNXXBZm9H5befGfYnx3K7QuIPzzlo,7169
+cmtj-1.5.0.dist-info/WHEEL,sha256=aK27B_a3TQKBFhN_ATCfuFR4pBRqHlzwr7HpZ6iA79M,115
+cmtj-1.5.0.dist-info/namespace_packages.txt,sha256=tdHMVh6eYeOaJJ6PiTcEihvYuKm12Vr9LjhNMGbEDBQ,5
+cmtj-1.5.0.dist-info/top_level.txt,sha256=tdHMVh6eYeOaJJ6PiTcEihvYuKm12Vr9LjhNMGbEDBQ,5
+cmtj-1.5.0.dist-info/RECORD,,
```

