# Comparing `tmp/speechmlpipeline-1.0.0-py3-none-any.whl.zip` & `tmp/speechmlpipeline-1.1.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,34 +1,34 @@
-Zip file size: 28884 bytes, number of entries: 32
+Zip file size: 30871 bytes, number of entries: 32
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-22 17:49 speechmlpipeline/__init__.py
--rw-r--r--  2.0 unx    12095 b- defN 24-Feb-23 22:25 speechmlpipeline/main_pipeline_local_function.py
--rw-r--r--  2.0 unx     4897 b- defN 24-Feb-26 20:08 speechmlpipeline/sample_run.py
--rw-r--r--  2.0 unx     4680 b- defN 24-Feb-26 17:42 speechmlpipeline/sample_run_existingllama2output.py
+-rw-r--r--  2.0 unx    12164 b- defN 24-Apr-24 18:28 speechmlpipeline/main_pipeline_local_function.py
+-rw-r--r--  2.0 unx     4894 b- defN 24-Apr-24 17:48 speechmlpipeline/sample_run.py
+-rw-r--r--  2.0 unx     4677 b- defN 24-Apr-24 17:48 speechmlpipeline/sample_run_existingllama2output.py
 -rw-r--r--  2.0 unx     1542 b- defN 24-Jan-30 23:07 speechmlpipeline/AudioToTextTranscription/Whisper.py
 -rw-r--r--  2.0 unx     4399 b- defN 24-Feb-19 20:12 speechmlpipeline/AudioToTextTranscription/Whispertimestamped.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-17 19:14 speechmlpipeline/AudioToTextTranscription/__init__.py
 -rw-r--r--  2.0 unx      475 b- defN 24-Jan-22 17:52 speechmlpipeline/DownloadModels/Download_Llama_Model.py
--rw-r--r--  2.0 unx      466 b- defN 24-Jan-17 21:55 speechmlpipeline/DownloadModels/Download_Speechbrain_Model.py
--rw-r--r--  2.0 unx      376 b- defN 24-Jan-30 22:22 speechmlpipeline/DownloadModels/Download_Whisper_Model.py
+-rw-r--r--  2.0 unx      363 b- defN 24-Apr-25 15:31 speechmlpipeline/DownloadModels/Download_Speechbrain_Model.py
+-rw-r--r--  2.0 unx      278 b- defN 24-Apr-25 15:31 speechmlpipeline/DownloadModels/Download_Whisper_Model.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-22 17:38 speechmlpipeline/DownloadModels/__init__.py
--rw-r--r--  2.0 unx     1340 b- defN 24-Feb-19 20:25 speechmlpipeline/DownloadModels/download_models_main_function.py
+-rw-r--r--  2.0 unx     1595 b- defN 24-Apr-25 15:35 speechmlpipeline/DownloadModels/download_models_main_function.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Feb-23 22:13 speechmlpipeline/EnsembleSpeakerChangeDetection/__init__.py
 -rw-r--r--  2.0 unx     1496 b- defN 24-Feb-26 17:27 speechmlpipeline/EnsembleSpeakerChangeDetection/ensemble_detection.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-17 19:14 speechmlpipeline/Evaluation/__init__.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Feb-12 20:35 speechmlpipeline/Evaluation/SpeakerChangeDetection/__init__.py
 -rw-r--r--  2.0 unx     1845 b- defN 24-Apr-03 21:40 speechmlpipeline/Evaluation/SpeakerChangeDetection/examine_pyannote_metrics.py
 -rw-r--r--  2.0 unx     9970 b- defN 24-Apr-03 22:43 speechmlpipeline/Evaluation/SpeakerChangeDetection/metrics_main_function.py
 -rw-r--r--  2.0 unx     1942 b- defN 24-Apr-03 19:02 speechmlpipeline/Evaluation/SpeakerChangeDetection/metrics_main_function_revised.py
 -rw-r--r--  2.0 unx     1926 b- defN 24-Feb-23 22:19 speechmlpipeline/Helpers/helpers.py
 -rw-r--r--  2.0 unx     3694 b- defN 24-Jan-30 21:42 speechmlpipeline/PreprocessData/Run_VideoAudioPreprocessing.py
 -rw-r--r--  2.0 unx     5338 b- defN 24-Jan-30 21:42 speechmlpipeline/PreprocessData/VideoAudioPreprocessing.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-17 19:14 speechmlpipeline/PreprocessData/__init__.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Feb-23 22:13 speechmlpipeline/SpeakerChangeDetection/__init__.py
 -rw-r--r--  2.0 unx     3353 b- defN 24-Feb-26 17:27 speechmlpipeline/SpeakerChangeDetection/speaker_change_detection_main_function.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-15 23:45 speechmlpipeline/SpeakerIdentification/__init__.py
--rw-r--r--  2.0 unx     6549 b- defN 24-Feb-23 22:25 speechmlpipeline/SpeakerIdentification/speaker_identification_main_function.py
--rw-r--r--  2.0 unx     1092 b- defN 24-Apr-24 16:23 speechmlpipeline-1.0.0.dist-info/LICENSE
--rw-r--r--  2.0 unx     7861 b- defN 24-Apr-24 16:23 speechmlpipeline-1.0.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-24 16:23 speechmlpipeline-1.0.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       17 b- defN 24-Apr-24 16:23 speechmlpipeline-1.0.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     3469 b- defN 24-Apr-24 16:23 speechmlpipeline-1.0.0.dist-info/RECORD
-32 files, 78914 bytes uncompressed, 22966 bytes compressed:  70.9%
+-rw-r--r--  2.0 unx     6549 b- defN 24-Apr-25 16:58 speechmlpipeline/SpeakerIdentification/speaker_identification_main_function.py
+-rw-r--r--  2.0 unx     1092 b- defN 24-Apr-30 16:19 speechmlpipeline-1.1.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx    15771 b- defN 24-Apr-30 16:19 speechmlpipeline-1.1.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-30 16:19 speechmlpipeline-1.1.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       17 b- defN 24-Apr-30 16:19 speechmlpipeline-1.1.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     3470 b- defN 24-Apr-30 16:19 speechmlpipeline-1.1.0.dist-info/RECORD
+32 files, 86942 bytes uncompressed, 24953 bytes compressed:  71.3%
```

## zipnote {}

```diff
@@ -75,23 +75,23 @@
 
 Filename: speechmlpipeline/SpeakerIdentification/__init__.py
 Comment: 
 
 Filename: speechmlpipeline/SpeakerIdentification/speaker_identification_main_function.py
 Comment: 
 
-Filename: speechmlpipeline-1.0.0.dist-info/LICENSE
+Filename: speechmlpipeline-1.1.0.dist-info/LICENSE
 Comment: 
 
-Filename: speechmlpipeline-1.0.0.dist-info/METADATA
+Filename: speechmlpipeline-1.1.0.dist-info/METADATA
 Comment: 
 
-Filename: speechmlpipeline-1.0.0.dist-info/WHEEL
+Filename: speechmlpipeline-1.1.0.dist-info/WHEEL
 Comment: 
 
-Filename: speechmlpipeline-1.0.0.dist-info/top_level.txt
+Filename: speechmlpipeline-1.1.0.dist-info/top_level.txt
 Comment: 
 
-Filename: speechmlpipeline-1.0.0.dist-info/RECORD
+Filename: speechmlpipeline-1.1.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## speechmlpipeline/main_pipeline_local_function.py

```diff
@@ -31,15 +31,15 @@
     :type audio_file_input_path: str
     :param audio_file_input_name: A audio file name containing the file type
     :type audio_file_input_name: str
     :param whisper_model_path: A path where the Whisper model files are saved
     :type whisper_model_path: str
     :param whisper_output_path: A path to save the csv file of transcription outputs
     :type whisper_output_path: str
-    :param device: Device type to run the model; If the type is None, GPU would be automatically used if it is available
+    :param device: Torch device type to run the model; If device is set as None, GPU would be automatically used if it is available.
     :type: str or torch.device or None
     :param only_run_in_english: True or False to Indicate if Whisper would only be run when
     the identified langauge in the audio file is English
     :type: bool
     '''
     audio_file_input_path: str
     audio_file_input_name: str
@@ -70,16 +70,15 @@
     :type detection_output_path: str
     :param hf_access_token: Access token to HuggingFace
     :type hf_access_token: str
     :param llama2_model_path: A path where the Llama2 model files are saved
     :type llama2_model_path: str
     :param pyannote_model_path: A path where the Pyannote model files are saved
     :type pyannote_model_path: str or None
-    :param device: Device type to run the model
-    used if it is available
+    :param device: Torch device type to run the model; If device is set as None, GPU would be automatically used if it is available.
     :type: str or torch.device or None
     :param detection_llama2_output_path: A path where the pre-run Llama2 speaker change detection output in csv file
     is saved if exists
     :type detection_llama2_output_path: str or None
     :param temp_output_path: A path to save the current run of Llama2 speaker change detection output
     to avoid future rerunning
     :type temp_output_path: str or None
```

## speechmlpipeline/sample_run.py

```diff
@@ -1,16 +1,16 @@
 '''
 Sample File to Run the Whole SpeechMLPipeline Without Existing Llama2 output
 '''
 
-from main_pipeline_local_function import TranscriptionInputs, SpeakerChangeDetectionInputs, \
+from speechmlpipeline.main_pipeline_local_function import TranscriptionInputs, SpeakerChangeDetectionInputs, \
     EnsembleDetectionInputs, SpeakerIdentificationInputs, run_speech_ml_pipeline
 
 # Shared Inputs
-hf_access_token = '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'
+hf_access_token = '<hf_access_token>'
 device = None  # if set device = None, by default would use gpu if cuda is available, otherwise use gpu
 audio_file_input_path = '/scratch/gpfs/jf3375/modern_family/audio/sample_data'
 audio_file_input_name =  'sample_data.WAV'
 csv_file_input_name = audio_file_input_name.split('.')[0] + '.csv'
 whisper_output_path = '/scratch/gpfs/jf3375/test/output'
 detection_output_path = '/scratch/gpfs/jf3375/test/output'
```

## speechmlpipeline/sample_run_existingllama2output.py

```diff
@@ -1,16 +1,16 @@
 '''
 Sample File to Run the Whole SpeechMLPipeline Without Existing Llama2 output
 '''
 
-from main_pipeline_local_function import TranscriptionInputs, SpeakerChangeDetectionInputs, \
+from speechmlpipeline.main_pipeline_local_function import TranscriptionInputs, SpeakerChangeDetectionInputs, \
     EnsembleDetectionInputs, SpeakerIdentificationInputs, run_speech_ml_pipeline
 
 # Shared Inputs
-hf_access_token = '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'
+hf_access_token = '<hf_access_token>'
 device = None  # if set device = None, by default would use gpu if cuda is available, otherwise use gpu
 audio_file_input_path =  '/scratch/gpfs/jf3375/modern_family/audio/sample_data'
 audio_file_input_name =  'sample_data.WAV'
 csv_file_input_name = audio_file_input_name.split('.')[0] + '.csv'
 whisper_output_path = '/scratch/gpfs/jf3375/test/output'
 detection_output_path = '/scratch/gpfs/jf3375/test/output'
```

## speechmlpipeline/DownloadModels/Download_Speechbrain_Model.py

```diff
@@ -1,12 +1,9 @@
 import os
 
 from speechbrain.pretrained import SpeakerRecognition
 
-download_model_path = '/Users/jf3375/Dropbox (Princeton)/speechmlmodels'
-model_folder = 'Speechbrain'
-
 def download_speechbrain_model(download_model_path, model_folder= 'speechbrain'):
     verification_model = SpeakerRecognition.from_hparams(source="speechbrain/spkrec-ecapa-voxceleb",
                                                      savedir = os.path.join(download_model_path, model_folder))
```

## speechmlpipeline/DownloadModels/Download_Whisper_Model.py

```diff
@@ -1,9 +1,7 @@
 import os
 import ssl
 import whisper
 
-download_model_path = '/Users/jf3375/Dropbox (Princeton)/speechmlmodels'
-model_folder = 'Whisper'
 def download_whisper_model(download_model_path, model_folder='whisper'):
     ssl._create_default_https_context = ssl._create_unverified_context
     whisper.load_model("large-v2", download_root=os.path.join(download_model_path, model_folder))
```

## speechmlpipeline/DownloadModels/download_models_main_function.py

```diff
@@ -1,12 +1,12 @@
 from .Download_Whisper_Model import download_whisper_model
 from .Download_Llama_Model import download_llama_model
 from .Download_Speechbrain_Model import download_speechbrain_model
 
-def download_models_main_function(download_model_path, models_list, hf_access_token):
+def download_models_main_function(download_model_path, models_list, hf_access_token=None):
     '''
     The main function to download models and save them on the local path
 
     :param download_model_path: A path to save all the downloaded models files
     :type download_model_path: str
     :param models_list: A list of the names of the models to be downloaded
     :type models_list: str
@@ -16,12 +16,16 @@
     :rtype: None
     '''
     if 'whisper' in models_list:
         download_whisper_model(download_model_path, model_folder='whisper')
     if 'speechbrain' in models_list:
         download_speechbrain_model(download_model_path, model_folder = 'speechbrain')
     if 'llama2-13b' in models_list:
+        if not hf_access_token:
+            raise Exception('HuggingFace Access Token is needed for download Llama2 models')
         download_llama_model(download_model_path, hf_access_token, model_folder = 'llama',
                          llama_model_repo_id='meta-llama/Llama-2-13b-chat-hf')
     if 'llama2-70b' in models_list:
+        if not hf_access_token:
+            raise Exception('HuggingFace Access Token is needed for download Llama2 models')
         download_llama_model(download_model_path, hf_access_token, model_folder = 'llama',
                          llama_model_repo_id='meta-llama/Llama-2-70b-chat-hf')
```

## speechmlpipeline/SpeakerIdentification/speaker_identification_main_function.py

```diff
@@ -52,15 +52,15 @@
     # Import speaker identification models
     if os.path.exists(verification_model_path):
         verification_model = SpeakerRecognition.from_hparams(source = verification_model_path)
     else:
         raise Exception('Please download the model first by following readme')
 
     # Import full_audio
-    full_audio = AudioSegment.from_wav(os.path.join(audio_file_input_path, '{}.WAV'.format(filename_noftype)))
+    full_audio = AudioSegment.from_wav(os.path.join(audio_file_input_path, '{}.wav'.format(filename_noftype)))
 
     # Speaker Identification for each audio segment
     speaker_identify_allsegments = []
     start_segment = detection_csv.iloc[0]['start']
     end_segment = detection_csv.iloc[0]['end']
     start_row_idx = 0
     end_row_idx = 0
```

## Comparing `speechmlpipeline-1.0.0.dist-info/LICENSE` & `speechmlpipeline-1.1.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `speechmlpipeline-1.0.0.dist-info/RECORD` & `speechmlpipeline-1.1.0.dist-info/RECORD`

 * *Files 5% similar despite different names*

```diff
@@ -1,32 +1,32 @@
 speechmlpipeline/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-speechmlpipeline/main_pipeline_local_function.py,sha256=WGy68ygyek5_0h5O6XCVAHUx4BVqW1_MXsmEfKh7l8Q,12095
-speechmlpipeline/sample_run.py,sha256=cbpugcI5abIwGBgeY8SsUFDtaf8Z1czQxoQhWduoOVc,4897
-speechmlpipeline/sample_run_existingllama2output.py,sha256=nbXd8kmDRr9Zbtc5p1nwtpJox3Xc3zevZldCEn1bLUE,4680
+speechmlpipeline/main_pipeline_local_function.py,sha256=ZbpzfceliaPN2Fawck268HXy1Xn1RctXtT5UnKfLJzM,12164
+speechmlpipeline/sample_run.py,sha256=rDXOnrBQ5pdNjD8QyCg3kiJIt-D76JfiEL7HLAd-LBI,4894
+speechmlpipeline/sample_run_existingllama2output.py,sha256=QoiP-P3UsyUwwV0muB5JJCXFlj4yqbAi-AVpsgpjsvQ,4677
 speechmlpipeline/AudioToTextTranscription/Whisper.py,sha256=zV4mVJOh875RA70UbsUMk8bIBPWpyj2yjMdqnyUubAI,1542
 speechmlpipeline/AudioToTextTranscription/Whispertimestamped.py,sha256=2ajXKtlr9zWiRJI60J2d2PMixwq-10YatY3An9Pgzqs,4399
 speechmlpipeline/AudioToTextTranscription/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 speechmlpipeline/DownloadModels/Download_Llama_Model.py,sha256=qKAnIWkA7EBHiUe-R3dFT8SxiB4S_mWnfyFF7epC2TE,475
-speechmlpipeline/DownloadModels/Download_Speechbrain_Model.py,sha256=7hAgytd4frfyzRn0FuO7IR-BM3bp5pHnpjzOLWaEhns,466
-speechmlpipeline/DownloadModels/Download_Whisper_Model.py,sha256=rwjGOLFSvhWMB4ePd0feJRtNRLGx6rgySdhKoeVxV4s,376
+speechmlpipeline/DownloadModels/Download_Speechbrain_Model.py,sha256=KmvLmz1nQwY60T_VxW8j7gruFpI-v5ZjIiR0W0yjBmY,363
+speechmlpipeline/DownloadModels/Download_Whisper_Model.py,sha256=lAEbVagdcvtNjD3lMqhkvgq573ubIrH2TTTOD6_4rL8,278
 speechmlpipeline/DownloadModels/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-speechmlpipeline/DownloadModels/download_models_main_function.py,sha256=FB0J1lVRUuelCiMBiqfRDZs9Tmnby8XrmOsGXO6sip0,1340
+speechmlpipeline/DownloadModels/download_models_main_function.py,sha256=1m4PcUu3jtaezJQ8vTOvN1LKQ_U273-W7EID_udPdfA,1595
 speechmlpipeline/EnsembleSpeakerChangeDetection/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 speechmlpipeline/EnsembleSpeakerChangeDetection/ensemble_detection.py,sha256=y1OnlUHendjc4mbW_VApB4DjibD83NC7yvbz5AiGpY4,1496
 speechmlpipeline/Evaluation/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 speechmlpipeline/Evaluation/SpeakerChangeDetection/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 speechmlpipeline/Evaluation/SpeakerChangeDetection/examine_pyannote_metrics.py,sha256=DYLP43JNUHW49tSLdNkeGIjh2IndHOPMD78ltaTXCBY,1845
 speechmlpipeline/Evaluation/SpeakerChangeDetection/metrics_main_function.py,sha256=nkTilySGkMyuO_4Ej7UeOUwI3w40zE69-SuDbUX0okU,9970
 speechmlpipeline/Evaluation/SpeakerChangeDetection/metrics_main_function_revised.py,sha256=k4xDmVcqyrvzdyTjpdYiUdzDId1tSaAwTtPGsGiZRmI,1942
 speechmlpipeline/Helpers/helpers.py,sha256=Ri0zGq-cQAwyq0F_KP8kzGRbLHtIy3BD7aMv-V-syT4,1926
 speechmlpipeline/PreprocessData/Run_VideoAudioPreprocessing.py,sha256=llmQC4oQQm3v5w1DPb2MVJG7yS3wJP7T9gZMuyTh7V4,3694
 speechmlpipeline/PreprocessData/VideoAudioPreprocessing.py,sha256=U7w8Gr7y4FsWtQO-QQi8EmPO6j78CnnmT8B8H0opWQQ,5338
 speechmlpipeline/PreprocessData/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 speechmlpipeline/SpeakerChangeDetection/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 speechmlpipeline/SpeakerChangeDetection/speaker_change_detection_main_function.py,sha256=5j_0h3ixauaPtHWaaly_2aSSawnqWFDQ2MzAllA-_Q0,3353
 speechmlpipeline/SpeakerIdentification/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-speechmlpipeline/SpeakerIdentification/speaker_identification_main_function.py,sha256=QT9vooigD8mKSHYH3X_I9O6dHsRkhuijSkJb73aN6ic,6549
-speechmlpipeline-1.0.0.dist-info/LICENSE,sha256=y0FxS72Yc01R5i36fN2g0JCldQzKCdCZ_H6h3RtttGw,1092
-speechmlpipeline-1.0.0.dist-info/METADATA,sha256=4YqdrOBAsQgVeTKXsDARxbdb2MW8C6ZFSrT7eJOs7l0,7861
-speechmlpipeline-1.0.0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-speechmlpipeline-1.0.0.dist-info/top_level.txt,sha256=4Kk8KkBAxPT_aAf2AwN4oMFOtorAwB1MqdFM-sd3sp0,17
-speechmlpipeline-1.0.0.dist-info/RECORD,,
+speechmlpipeline/SpeakerIdentification/speaker_identification_main_function.py,sha256=rjMLzPzPtdp9A6sx42yO521NE_AXKwvy9xsplcPjDFQ,6549
+speechmlpipeline-1.1.0.dist-info/LICENSE,sha256=y0FxS72Yc01R5i36fN2g0JCldQzKCdCZ_H6h3RtttGw,1092
+speechmlpipeline-1.1.0.dist-info/METADATA,sha256=UtwyFp0MCBb-leHwPN6fgljP0xdb8BnLeppa2C9w7bk,15771
+speechmlpipeline-1.1.0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+speechmlpipeline-1.1.0.dist-info/top_level.txt,sha256=4Kk8KkBAxPT_aAf2AwN4oMFOtorAwB1MqdFM-sd3sp0,17
+speechmlpipeline-1.1.0.dist-info/RECORD,,
```

